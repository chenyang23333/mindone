import argparse

import torch
from safetensors.torch import load_file, save_file

vae = {'decoder.conv_in.bias': 'decoder.conv_in.bias', 'decoder.conv_in.weight': 'decoder.conv_in.weight',
       'decoder.conv_norm_out.bias': 'decoder.norm_out.bias', 'decoder.conv_norm_out.weight': 'decoder.norm_out.weight',
       'decoder.conv_out.bias': 'decoder.conv_out.bias', 'decoder.conv_out.weight': 'decoder.conv_out.weight',
       'decoder.mid_block.attentions.0.group_norm.bias': 'decoder.mid.attn_1.norm.bias',
       'decoder.mid_block.attentions.0.group_norm.weight': 'decoder.mid.attn_1.norm.weight',
       'decoder.mid_block.attentions.0.to_k.bias': 'decoder.mid.attn_1.k.bias',
       'decoder.mid_block.attentions.0.to_k.weight': 'decoder.mid.attn_1.k.weight',
       'decoder.mid_block.attentions.0.to_out.0.bias': 'decoder.mid.attn_1.proj_out.bias',
       'decoder.mid_block.attentions.0.to_out.0.weight': 'decoder.mid.attn_1.proj_out.weight',
       'decoder.mid_block.attentions.0.to_q.bias': 'decoder.mid.attn_1.q.bias',
       'decoder.mid_block.attentions.0.to_q.weight': 'decoder.mid.attn_1.q.weight',
       'decoder.mid_block.attentions.0.to_v.bias': 'decoder.mid.attn_1.v.bias',
       'decoder.mid_block.attentions.0.to_v.weight': 'decoder.mid.attn_1.v.weight',
       'decoder.mid_block.resnets.0.conv1.bias': 'decoder.mid.block_1.conv1.bias',
       'decoder.mid_block.resnets.0.conv1.weight': 'decoder.mid.block_1.conv1.weight',
       'decoder.mid_block.resnets.0.conv2.bias': 'decoder.mid.block_1.conv2.bias',
       'decoder.mid_block.resnets.0.conv2.weight': 'decoder.mid.block_1.conv2.weight',
       'decoder.mid_block.resnets.0.norm1.bias': 'decoder.mid.block_1.norm1.bias',
       'decoder.mid_block.resnets.0.norm1.weight': 'decoder.mid.block_1.norm1.weight',
       'decoder.mid_block.resnets.0.norm2.bias': 'decoder.mid.block_1.norm2.bias',
       'decoder.mid_block.resnets.0.norm2.weight': 'decoder.mid.block_1.norm2.weight',
       'decoder.mid_block.resnets.1.conv1.bias': 'decoder.mid.block_2.conv1.bias',
       'decoder.mid_block.resnets.1.conv1.weight': 'decoder.mid.block_2.conv1.weight',
       'decoder.mid_block.resnets.1.conv2.bias': 'decoder.mid.block_2.conv2.bias',
       'decoder.mid_block.resnets.1.conv2.weight': 'decoder.mid.block_2.conv2.weight',
       'decoder.mid_block.resnets.1.norm1.bias': 'decoder.mid.block_2.norm1.bias',
       'decoder.mid_block.resnets.1.norm1.weight': 'decoder.mid.block_2.norm1.weight',
       'decoder.mid_block.resnets.1.norm2.bias': 'decoder.mid.block_2.norm2.bias',
       'decoder.mid_block.resnets.1.norm2.weight': 'decoder.mid.block_2.norm2.weight',
       'decoder.up_blocks.0.resnets.0.conv1.bias': 'decoder.up.3.block.0.conv1.bias',
       'decoder.up_blocks.0.resnets.0.conv1.weight': 'decoder.up.3.block.0.conv1.weight',
       'decoder.up_blocks.0.resnets.0.conv2.bias': 'decoder.up.3.block.0.conv2.bias',
       'decoder.up_blocks.0.resnets.0.conv2.weight': 'decoder.up.3.block.0.conv2.weight',
       'decoder.up_blocks.0.resnets.0.norm1.bias': 'decoder.up.3.block.0.norm1.bias',
       'decoder.up_blocks.0.resnets.0.norm1.weight': 'decoder.up.3.block.0.norm1.weight',
       'decoder.up_blocks.0.resnets.0.norm2.bias': 'decoder.up.3.block.0.norm2.bias',
       'decoder.up_blocks.0.resnets.0.norm2.weight': 'decoder.up.3.block.0.norm2.weight',
       'decoder.up_blocks.0.resnets.1.conv1.bias': 'decoder.up.3.block.1.conv1.bias',
       'decoder.up_blocks.0.resnets.1.conv1.weight': 'decoder.up.3.block.1.conv1.weight',
       'decoder.up_blocks.0.resnets.1.conv2.bias': 'decoder.up.3.block.1.conv2.bias',
       'decoder.up_blocks.0.resnets.1.conv2.weight': 'decoder.up.3.block.1.conv2.weight',
       'decoder.up_blocks.0.resnets.1.norm1.bias': 'decoder.up.3.block.1.norm1.bias',
       'decoder.up_blocks.0.resnets.1.norm1.weight': 'decoder.up.3.block.1.norm1.weight',
       'decoder.up_blocks.0.resnets.1.norm2.bias': 'decoder.up.3.block.1.norm2.bias',
       'decoder.up_blocks.0.resnets.1.norm2.weight': 'decoder.up.3.block.1.norm2.weight',
       'decoder.up_blocks.0.resnets.2.conv1.bias': 'decoder.up.3.block.2.conv1.bias',
       'decoder.up_blocks.0.resnets.2.conv1.weight': 'decoder.up.3.block.2.conv1.weight',
       'decoder.up_blocks.0.resnets.2.conv2.bias': 'decoder.up.3.block.2.conv2.bias',
       'decoder.up_blocks.0.resnets.2.conv2.weight': 'decoder.up.3.block.2.conv2.weight',
       'decoder.up_blocks.0.resnets.2.norm1.bias': 'decoder.up.3.block.2.norm1.bias',
       'decoder.up_blocks.0.resnets.2.norm1.weight': 'decoder.up.3.block.2.norm1.weight',
       'decoder.up_blocks.0.resnets.2.norm2.bias': 'decoder.up.3.block.2.norm2.bias',
       'decoder.up_blocks.0.resnets.2.norm2.weight': 'decoder.up.3.block.2.norm2.weight',
       'decoder.up_blocks.0.upsamplers.0.conv.bias': 'decoder.up.3.upsample.conv.bias',
       'decoder.up_blocks.0.upsamplers.0.conv.weight': 'decoder.up.3.upsample.conv.weight',
       'decoder.up_blocks.1.resnets.0.conv1.bias': 'decoder.up.2.block.0.conv1.bias',
       'decoder.up_blocks.1.resnets.0.conv1.weight': 'decoder.up.2.block.0.conv1.weight',
       'decoder.up_blocks.1.resnets.0.conv2.bias': 'decoder.up.2.block.0.conv2.bias',
       'decoder.up_blocks.1.resnets.0.conv2.weight': 'decoder.up.2.block.0.conv2.weight',
       'decoder.up_blocks.1.resnets.0.norm1.bias': 'decoder.up.2.block.0.norm1.bias',
       'decoder.up_blocks.1.resnets.0.norm1.weight': 'decoder.up.2.block.0.norm1.weight',
       'decoder.up_blocks.1.resnets.0.norm2.bias': 'decoder.up.2.block.0.norm2.bias',
       'decoder.up_blocks.1.resnets.0.norm2.weight': 'decoder.up.2.block.0.norm2.weight',
       'decoder.up_blocks.1.resnets.1.conv1.bias': 'decoder.up.2.block.1.conv1.bias',
       'decoder.up_blocks.1.resnets.1.conv1.weight': 'decoder.up.2.block.1.conv1.weight',
       'decoder.up_blocks.1.resnets.1.conv2.bias': 'decoder.up.2.block.1.conv2.bias',
       'decoder.up_blocks.1.resnets.1.conv2.weight': 'decoder.up.2.block.1.conv2.weight',
       'decoder.up_blocks.1.resnets.1.norm1.bias': 'decoder.up.2.block.1.norm1.bias',
       'decoder.up_blocks.1.resnets.1.norm1.weight': 'decoder.up.2.block.1.norm1.weight',
       'decoder.up_blocks.1.resnets.1.norm2.bias': 'decoder.up.2.block.1.norm2.bias',
       'decoder.up_blocks.1.resnets.1.norm2.weight': 'decoder.up.2.block.1.norm2.weight',
       'decoder.up_blocks.1.resnets.2.conv1.bias': 'decoder.up.2.block.2.conv1.bias',
       'decoder.up_blocks.1.resnets.2.conv1.weight': 'decoder.up.2.block.2.conv1.weight',
       'decoder.up_blocks.1.resnets.2.conv2.bias': 'decoder.up.2.block.2.conv2.bias',
       'decoder.up_blocks.1.resnets.2.conv2.weight': 'decoder.up.2.block.2.conv2.weight',
       'decoder.up_blocks.1.resnets.2.norm1.bias': 'decoder.up.2.block.2.norm1.bias',
       'decoder.up_blocks.1.resnets.2.norm1.weight': 'decoder.up.2.block.2.norm1.weight',
       'decoder.up_blocks.1.resnets.2.norm2.bias': 'decoder.up.2.block.2.norm2.bias',
       'decoder.up_blocks.1.resnets.2.norm2.weight': 'decoder.up.2.block.2.norm2.weight',
       'decoder.up_blocks.1.upsamplers.0.conv.bias': 'decoder.up.2.upsample.conv.bias',
       'decoder.up_blocks.1.upsamplers.0.conv.weight': 'decoder.up.2.upsample.conv.weight',
       'decoder.up_blocks.2.resnets.0.conv1.bias': 'decoder.up.1.block.0.conv1.bias',
       'decoder.up_blocks.2.resnets.0.conv1.weight': 'decoder.up.1.block.0.conv1.weight',
       'decoder.up_blocks.2.resnets.0.conv2.bias': 'decoder.up.1.block.0.conv2.bias',
       'decoder.up_blocks.2.resnets.0.conv2.weight': 'decoder.up.1.block.0.conv2.weight',
       'decoder.up_blocks.2.resnets.0.conv_shortcut.bias': 'decoder.up.1.block.0.nin_shortcut.bias',
       'decoder.up_blocks.2.resnets.0.conv_shortcut.weight': 'decoder.up.1.block.0.nin_shortcut.weight',
       'decoder.up_blocks.2.resnets.0.norm1.bias': 'decoder.up.1.block.0.norm1.bias',
       'decoder.up_blocks.2.resnets.0.norm1.weight': 'decoder.up.1.block.0.norm1.weight',
       'decoder.up_blocks.2.resnets.0.norm2.bias': 'decoder.up.1.block.0.norm2.bias',
       'decoder.up_blocks.2.resnets.0.norm2.weight': 'decoder.up.1.block.0.norm2.weight',
       'decoder.up_blocks.2.resnets.1.conv1.bias': 'decoder.up.1.block.1.conv1.bias',
       'decoder.up_blocks.2.resnets.1.conv1.weight': 'decoder.up.1.block.1.conv1.weight',
       'decoder.up_blocks.2.resnets.1.conv2.bias': 'decoder.up.1.block.1.conv2.bias',
       'decoder.up_blocks.2.resnets.1.conv2.weight': 'decoder.up.1.block.1.conv2.weight',
       'decoder.up_blocks.2.resnets.1.norm1.bias': 'decoder.up.1.block.1.norm1.bias',
       'decoder.up_blocks.2.resnets.1.norm1.weight': 'decoder.up.1.block.1.norm1.weight',
       'decoder.up_blocks.2.resnets.1.norm2.bias': 'decoder.up.1.block.1.norm2.bias',
       'decoder.up_blocks.2.resnets.1.norm2.weight': 'decoder.up.1.block.1.norm2.weight',
       'decoder.up_blocks.2.resnets.2.conv1.bias': 'decoder.up.1.block.2.conv1.bias',
       'decoder.up_blocks.2.resnets.2.conv1.weight': 'decoder.up.1.block.2.conv1.weight',
       'decoder.up_blocks.2.resnets.2.conv2.bias': 'decoder.up.1.block.2.conv2.bias',
       'decoder.up_blocks.2.resnets.2.conv2.weight': 'decoder.up.1.block.2.conv2.weight',
       'decoder.up_blocks.2.resnets.2.norm1.bias': 'decoder.up.1.block.2.norm1.bias',
       'decoder.up_blocks.2.resnets.2.norm1.weight': 'decoder.up.1.block.2.norm1.weight',
       'decoder.up_blocks.2.resnets.2.norm2.bias': 'decoder.up.1.block.2.norm2.bias',
       'decoder.up_blocks.2.resnets.2.norm2.weight': 'decoder.up.1.block.2.norm2.weight',
       'decoder.up_blocks.2.upsamplers.0.conv.bias': 'decoder.up.1.upsample.conv.bias',
       'decoder.up_blocks.2.upsamplers.0.conv.weight': 'decoder.up.1.upsample.conv.weight',
       'decoder.up_blocks.3.resnets.0.conv1.bias': 'decoder.up.0.block.0.conv1.bias',
       'decoder.up_blocks.3.resnets.0.conv1.weight': 'decoder.up.0.block.0.conv1.weight',
       'decoder.up_blocks.3.resnets.0.conv2.bias': 'decoder.up.0.block.0.conv2.bias',
       'decoder.up_blocks.3.resnets.0.conv2.weight': 'decoder.up.0.block.0.conv2.weight',
       'decoder.up_blocks.3.resnets.0.conv_shortcut.bias': 'decoder.up.0.block.0.nin_shortcut.bias',
       'decoder.up_blocks.3.resnets.0.conv_shortcut.weight': 'decoder.up.0.block.0.nin_shortcut.weight',
       'decoder.up_blocks.3.resnets.0.norm1.bias': 'decoder.up.0.block.0.norm1.bias',
       'decoder.up_blocks.3.resnets.0.norm1.weight': 'decoder.up.0.block.0.norm1.weight',
       'decoder.up_blocks.3.resnets.0.norm2.bias': 'decoder.up.0.block.0.norm2.bias',
       'decoder.up_blocks.3.resnets.0.norm2.weight': 'decoder.up.0.block.0.norm2.weight',
       'decoder.up_blocks.3.resnets.1.conv1.bias': 'decoder.up.0.block.1.conv1.bias',
       'decoder.up_blocks.3.resnets.1.conv1.weight': 'decoder.up.0.block.1.conv1.weight',
       'decoder.up_blocks.3.resnets.1.conv2.bias': 'decoder.up.0.block.1.conv2.bias',
       'decoder.up_blocks.3.resnets.1.conv2.weight': 'decoder.up.0.block.1.conv2.weight',
       'decoder.up_blocks.3.resnets.1.norm1.bias': 'decoder.up.0.block.1.norm1.bias',
       'decoder.up_blocks.3.resnets.1.norm1.weight': 'decoder.up.0.block.1.norm1.weight',
       'decoder.up_blocks.3.resnets.1.norm2.bias': 'decoder.up.0.block.1.norm2.bias',
       'decoder.up_blocks.3.resnets.1.norm2.weight': 'decoder.up.0.block.1.norm2.weight',
       'decoder.up_blocks.3.resnets.2.conv1.bias': 'decoder.up.0.block.2.conv1.bias',
       'decoder.up_blocks.3.resnets.2.conv1.weight': 'decoder.up.0.block.2.conv1.weight',
       'decoder.up_blocks.3.resnets.2.conv2.bias': 'decoder.up.0.block.2.conv2.bias',
       'decoder.up_blocks.3.resnets.2.conv2.weight': 'decoder.up.0.block.2.conv2.weight',
       'decoder.up_blocks.3.resnets.2.norm1.bias': 'decoder.up.0.block.2.norm1.bias',
       'decoder.up_blocks.3.resnets.2.norm1.weight': 'decoder.up.0.block.2.norm1.weight',
       'decoder.up_blocks.3.resnets.2.norm2.bias': 'decoder.up.0.block.2.norm2.bias',
       'decoder.up_blocks.3.resnets.2.norm2.weight': 'decoder.up.0.block.2.norm2.weight',
       'encoder.conv_in.bias': 'encoder.conv_in.bias', 'encoder.conv_in.weight': 'encoder.conv_in.weight',
       'encoder.conv_norm_out.bias': 'encoder.norm_out.bias', 'encoder.conv_norm_out.weight': 'encoder.norm_out.weight',
       'encoder.conv_out.bias': 'encoder.conv_out.bias', 'encoder.conv_out.weight': 'encoder.conv_out.weight',
       'encoder.down_blocks.0.downsamplers.0.conv.bias': 'encoder.down.0.downsample.conv.bias',
       'encoder.down_blocks.0.downsamplers.0.conv.weight': 'encoder.down.0.downsample.conv.weight',
       'encoder.down_blocks.0.resnets.0.conv1.bias': 'encoder.down.0.block.0.conv1.bias',
       'encoder.down_blocks.0.resnets.0.conv1.weight': 'encoder.down.0.block.0.conv1.weight',
       'encoder.down_blocks.0.resnets.0.conv2.bias': 'encoder.down.0.block.0.conv2.bias',
       'encoder.down_blocks.0.resnets.0.conv2.weight': 'encoder.down.0.block.0.conv2.weight',
       'encoder.down_blocks.0.resnets.0.norm1.bias': 'encoder.down.0.block.0.norm1.bias',
       'encoder.down_blocks.0.resnets.0.norm1.weight': 'encoder.down.0.block.0.norm1.weight',
       'encoder.down_blocks.0.resnets.0.norm2.bias': 'encoder.down.0.block.0.norm2.bias',
       'encoder.down_blocks.0.resnets.0.norm2.weight': 'encoder.down.0.block.0.norm2.weight',
       'encoder.down_blocks.0.resnets.1.conv1.bias': 'encoder.down.0.block.1.conv1.bias',
       'encoder.down_blocks.0.resnets.1.conv1.weight': 'encoder.down.0.block.1.conv1.weight',
       'encoder.down_blocks.0.resnets.1.conv2.bias': 'encoder.down.0.block.1.conv2.bias',
       'encoder.down_blocks.0.resnets.1.conv2.weight': 'encoder.down.0.block.1.conv2.weight',
       'encoder.down_blocks.0.resnets.1.norm1.bias': 'encoder.down.0.block.1.norm1.bias',
       'encoder.down_blocks.0.resnets.1.norm1.weight': 'encoder.down.0.block.1.norm1.weight',
       'encoder.down_blocks.0.resnets.1.norm2.bias': 'encoder.down.0.block.1.norm2.bias',
       'encoder.down_blocks.0.resnets.1.norm2.weight': 'encoder.down.0.block.1.norm2.weight',
       'encoder.down_blocks.1.downsamplers.0.conv.bias': 'encoder.down.1.downsample.conv.bias',
       'encoder.down_blocks.1.downsamplers.0.conv.weight': 'encoder.down.1.downsample.conv.weight',
       'encoder.down_blocks.1.resnets.0.conv1.bias': 'encoder.down.1.block.0.conv1.bias',
       'encoder.down_blocks.1.resnets.0.conv1.weight': 'encoder.down.1.block.0.conv1.weight',
       'encoder.down_blocks.1.resnets.0.conv2.bias': 'encoder.down.1.block.0.conv2.bias',
       'encoder.down_blocks.1.resnets.0.conv2.weight': 'encoder.down.1.block.0.conv2.weight',
       'encoder.down_blocks.1.resnets.0.conv_shortcut.bias': 'encoder.down.1.block.0.nin_shortcut.bias',
       'encoder.down_blocks.1.resnets.0.conv_shortcut.weight': 'encoder.down.1.block.0.nin_shortcut.weight',
       'encoder.down_blocks.1.resnets.0.norm1.bias': 'encoder.down.1.block.0.norm1.bias',
       'encoder.down_blocks.1.resnets.0.norm1.weight': 'encoder.down.1.block.0.norm1.weight',
       'encoder.down_blocks.1.resnets.0.norm2.bias': 'encoder.down.1.block.0.norm2.bias',
       'encoder.down_blocks.1.resnets.0.norm2.weight': 'encoder.down.1.block.0.norm2.weight',
       'encoder.down_blocks.1.resnets.1.conv1.bias': 'encoder.down.1.block.1.conv1.bias',
       'encoder.down_blocks.1.resnets.1.conv1.weight': 'encoder.down.1.block.1.conv1.weight',
       'encoder.down_blocks.1.resnets.1.conv2.bias': 'encoder.down.1.block.1.conv2.bias',
       'encoder.down_blocks.1.resnets.1.conv2.weight': 'encoder.down.1.block.1.conv2.weight',
       'encoder.down_blocks.1.resnets.1.norm1.bias': 'encoder.down.1.block.1.norm1.bias',
       'encoder.down_blocks.1.resnets.1.norm1.weight': 'encoder.down.1.block.1.norm1.weight',
       'encoder.down_blocks.1.resnets.1.norm2.bias': 'encoder.down.1.block.1.norm2.bias',
       'encoder.down_blocks.1.resnets.1.norm2.weight': 'encoder.down.1.block.1.norm2.weight',
       'encoder.down_blocks.2.downsamplers.0.conv.bias': 'encoder.down.2.downsample.conv.bias',
       'encoder.down_blocks.2.downsamplers.0.conv.weight': 'encoder.down.2.downsample.conv.weight',
       'encoder.down_blocks.2.resnets.0.conv1.bias': 'encoder.down.2.block.0.conv1.bias',
       'encoder.down_blocks.2.resnets.0.conv1.weight': 'encoder.down.2.block.0.conv1.weight',
       'encoder.down_blocks.2.resnets.0.conv2.bias': 'encoder.down.2.block.0.conv2.bias',
       'encoder.down_blocks.2.resnets.0.conv2.weight': 'encoder.down.2.block.0.conv2.weight',
       'encoder.down_blocks.2.resnets.0.conv_shortcut.bias': 'encoder.down.2.block.0.nin_shortcut.bias',
       'encoder.down_blocks.2.resnets.0.conv_shortcut.weight': 'encoder.down.2.block.0.nin_shortcut.weight',
       'encoder.down_blocks.2.resnets.0.norm1.bias': 'encoder.down.2.block.0.norm1.bias',
       'encoder.down_blocks.2.resnets.0.norm1.weight': 'encoder.down.2.block.0.norm1.weight',
       'encoder.down_blocks.2.resnets.0.norm2.bias': 'encoder.down.2.block.0.norm2.bias',
       'encoder.down_blocks.2.resnets.0.norm2.weight': 'encoder.down.2.block.0.norm2.weight',
       'encoder.down_blocks.2.resnets.1.conv1.bias': 'encoder.down.2.block.1.conv1.bias',
       'encoder.down_blocks.2.resnets.1.conv1.weight': 'encoder.down.2.block.1.conv1.weight',
       'encoder.down_blocks.2.resnets.1.conv2.bias': 'encoder.down.2.block.1.conv2.bias',
       'encoder.down_blocks.2.resnets.1.conv2.weight': 'encoder.down.2.block.1.conv2.weight',
       'encoder.down_blocks.2.resnets.1.norm1.bias': 'encoder.down.2.block.1.norm1.bias',
       'encoder.down_blocks.2.resnets.1.norm1.weight': 'encoder.down.2.block.1.norm1.weight',
       'encoder.down_blocks.2.resnets.1.norm2.bias': 'encoder.down.2.block.1.norm2.bias',
       'encoder.down_blocks.2.resnets.1.norm2.weight': 'encoder.down.2.block.1.norm2.weight',
       'encoder.down_blocks.3.resnets.0.conv1.bias': 'encoder.down.3.block.0.conv1.bias',
       'encoder.down_blocks.3.resnets.0.conv1.weight': 'encoder.down.3.block.0.conv1.weight',
       'encoder.down_blocks.3.resnets.0.conv2.bias': 'encoder.down.3.block.0.conv2.bias',
       'encoder.down_blocks.3.resnets.0.conv2.weight': 'encoder.down.3.block.0.conv2.weight',
       'encoder.down_blocks.3.resnets.0.norm1.bias': 'encoder.down.3.block.0.norm1.bias',
       'encoder.down_blocks.3.resnets.0.norm1.weight': 'encoder.down.3.block.0.norm1.weight',
       'encoder.down_blocks.3.resnets.0.norm2.bias': 'encoder.down.3.block.0.norm2.bias',
       'encoder.down_blocks.3.resnets.0.norm2.weight': 'encoder.down.3.block.0.norm2.weight',
       'encoder.down_blocks.3.resnets.1.conv1.bias': 'encoder.down.3.block.1.conv1.bias',
       'encoder.down_blocks.3.resnets.1.conv1.weight': 'encoder.down.3.block.1.conv1.weight',
       'encoder.down_blocks.3.resnets.1.conv2.bias': 'encoder.down.3.block.1.conv2.bias',
       'encoder.down_blocks.3.resnets.1.conv2.weight': 'encoder.down.3.block.1.conv2.weight',
       'encoder.down_blocks.3.resnets.1.norm1.bias': 'encoder.down.3.block.1.norm1.bias',
       'encoder.down_blocks.3.resnets.1.norm1.weight': 'encoder.down.3.block.1.norm1.weight',
       'encoder.down_blocks.3.resnets.1.norm2.bias': 'encoder.down.3.block.1.norm2.bias',
       'encoder.down_blocks.3.resnets.1.norm2.weight': 'encoder.down.3.block.1.norm2.weight',
       'encoder.mid_block.attentions.0.group_norm.bias': 'encoder.mid.attn_1.norm.bias',
       'encoder.mid_block.attentions.0.group_norm.weight': 'encoder.mid.attn_1.norm.weight',
       'encoder.mid_block.attentions.0.to_k.bias': 'encoder.mid.attn_1.k.bias',
       'encoder.mid_block.attentions.0.to_k.weight': 'encoder.mid.attn_1.k.weight',
       'encoder.mid_block.attentions.0.to_out.0.bias': 'encoder.mid.attn_1.proj_out.bias',
       'encoder.mid_block.attentions.0.to_out.0.weight': 'encoder.mid.attn_1.proj_out.weight',
       'encoder.mid_block.attentions.0.to_q.bias': 'encoder.mid.attn_1.q.bias',
       'encoder.mid_block.attentions.0.to_q.weight': 'encoder.mid.attn_1.q.weight',
       'encoder.mid_block.attentions.0.to_v.bias': 'encoder.mid.attn_1.v.bias',
       'encoder.mid_block.attentions.0.to_v.weight': 'encoder.mid.attn_1.v.weight',
       'encoder.mid_block.resnets.0.conv1.bias': 'encoder.mid.block_1.conv1.bias',
       'encoder.mid_block.resnets.0.conv1.weight': 'encoder.mid.block_1.conv1.weight',
       'encoder.mid_block.resnets.0.conv2.bias': 'encoder.mid.block_1.conv2.bias',
       'encoder.mid_block.resnets.0.conv2.weight': 'encoder.mid.block_1.conv2.weight',
       'encoder.mid_block.resnets.0.norm1.bias': 'encoder.mid.block_1.norm1.bias',
       'encoder.mid_block.resnets.0.norm1.weight': 'encoder.mid.block_1.norm1.weight',
       'encoder.mid_block.resnets.0.norm2.bias': 'encoder.mid.block_1.norm2.bias',
       'encoder.mid_block.resnets.0.norm2.weight': 'encoder.mid.block_1.norm2.weight',
       'encoder.mid_block.resnets.1.conv1.bias': 'encoder.mid.block_2.conv1.bias',
       'encoder.mid_block.resnets.1.conv1.weight': 'encoder.mid.block_2.conv1.weight',
       'encoder.mid_block.resnets.1.conv2.bias': 'encoder.mid.block_2.conv2.bias',
       'encoder.mid_block.resnets.1.conv2.weight': 'encoder.mid.block_2.conv2.weight',
       'encoder.mid_block.resnets.1.norm1.bias': 'encoder.mid.block_2.norm1.bias',
       'encoder.mid_block.resnets.1.norm1.weight': 'encoder.mid.block_2.norm1.weight',
       'encoder.mid_block.resnets.1.norm2.bias': 'encoder.mid.block_2.norm2.bias',
       'encoder.mid_block.resnets.1.norm2.weight': 'encoder.mid.block_2.norm2.weight',
       'post_quant_conv.bias': 'post_quant_conv.bias', 'post_quant_conv.weight': 'post_quant_conv.weight',
       'quant_conv.bias': 'quant_conv.bias', 'quant_conv.weight': 'quant_conv.weight'}
unet = {'add_embedding.linear_1.bias': 'label_emb.0.0.bias', 'add_embedding.linear_1.weight': 'label_emb.0.0.weight',
        'add_embedding.linear_2.bias': 'label_emb.0.2.bias', 'add_embedding.linear_2.weight': 'label_emb.0.2.weight',
        'conv_in.bias': 'input_blocks.0.0.bias', 'conv_in.weight': 'input_blocks.0.0.weight',
        'conv_norm_out.bias': 'out.0.bias', 'conv_norm_out.weight': 'out.0.weight', 'conv_out.bias': 'out.2.bias',
        'conv_out.weight': 'out.2.weight', 'down_blocks.0.downsamplers.0.conv.bias': 'input_blocks.3.0.op.bias',
        'down_blocks.0.downsamplers.0.conv.weight': 'input_blocks.3.0.op.weight',
        'down_blocks.0.resnets.0.conv1.bias': 'input_blocks.1.0.in_layers.2.bias',
        'down_blocks.0.resnets.0.conv1.weight': 'input_blocks.1.0.in_layers.2.weight',
        'down_blocks.0.resnets.0.conv2.bias': 'input_blocks.1.0.out_layers.3.bias',
        'down_blocks.0.resnets.0.conv2.weight': 'input_blocks.1.0.out_layers.3.weight',
        'down_blocks.0.resnets.0.norm1.bias': 'input_blocks.1.0.in_layers.0.bias',
        'down_blocks.0.resnets.0.norm1.weight': 'input_blocks.1.0.in_layers.0.weight',
        'down_blocks.0.resnets.0.norm2.bias': 'input_blocks.1.0.out_layers.0.bias',
        'down_blocks.0.resnets.0.norm2.weight': 'input_blocks.1.0.out_layers.0.weight',
        'down_blocks.0.resnets.0.time_emb_proj.bias': 'input_blocks.1.0.emb_layers.1.bias',
        'down_blocks.0.resnets.0.time_emb_proj.weight': 'input_blocks.1.0.emb_layers.1.weight',
        'down_blocks.0.resnets.1.conv1.bias': 'input_blocks.2.0.in_layers.2.bias',
        'down_blocks.0.resnets.1.conv1.weight': 'input_blocks.2.0.in_layers.2.weight',
        'down_blocks.0.resnets.1.conv2.bias': 'input_blocks.2.0.out_layers.3.bias',
        'down_blocks.0.resnets.1.conv2.weight': 'input_blocks.2.0.out_layers.3.weight',
        'down_blocks.0.resnets.1.norm1.bias': 'input_blocks.2.0.in_layers.0.bias',
        'down_blocks.0.resnets.1.norm1.weight': 'input_blocks.2.0.in_layers.0.weight',
        'down_blocks.0.resnets.1.norm2.bias': 'input_blocks.2.0.out_layers.0.bias',
        'down_blocks.0.resnets.1.norm2.weight': 'input_blocks.2.0.out_layers.0.weight',
        'down_blocks.0.resnets.1.time_emb_proj.bias': 'input_blocks.2.0.emb_layers.1.bias',
        'down_blocks.0.resnets.1.time_emb_proj.weight': 'input_blocks.2.0.emb_layers.1.weight',
        'down_blocks.1.attentions.0.norm.bias': 'input_blocks.4.1.norm.bias',
        'down_blocks.1.attentions.0.norm.weight': 'input_blocks.4.1.norm.weight',
        'down_blocks.1.attentions.0.proj_in.bias': 'input_blocks.4.1.proj_in.bias',
        'down_blocks.1.attentions.0.proj_in.weight': 'input_blocks.4.1.proj_in.weight',
        'down_blocks.1.attentions.0.proj_out.bias': 'input_blocks.4.1.proj_out.bias',
        'down_blocks.1.attentions.0.proj_out.weight': 'input_blocks.4.1.proj_out.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.4.1.transformer_blocks.0.norm1.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.4.1.transformer_blocks.0.norm1.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.4.1.transformer_blocks.0.norm2.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.4.1.transformer_blocks.0.norm2.weight',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.4.1.transformer_blocks.0.norm3.bias',
        'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.4.1.transformer_blocks.0.norm3.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_k.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_q.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_v.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_k.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_q.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_v.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.bias': 'input_blocks.4.1.transformer_blocks.1.ff.net.2.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight': 'input_blocks.4.1.transformer_blocks.1.ff.net.2.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm1.bias': 'input_blocks.4.1.transformer_blocks.1.norm1.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm1.weight': 'input_blocks.4.1.transformer_blocks.1.norm1.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm2.bias': 'input_blocks.4.1.transformer_blocks.1.norm2.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm2.weight': 'input_blocks.4.1.transformer_blocks.1.norm2.weight',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm3.bias': 'input_blocks.4.1.transformer_blocks.1.norm3.bias',
        'down_blocks.1.attentions.0.transformer_blocks.1.norm3.weight': 'input_blocks.4.1.transformer_blocks.1.norm3.weight',
        'down_blocks.1.attentions.1.norm.bias': 'input_blocks.5.1.norm.bias',
        'down_blocks.1.attentions.1.norm.weight': 'input_blocks.5.1.norm.weight',
        'down_blocks.1.attentions.1.proj_in.bias': 'input_blocks.5.1.proj_in.bias',
        'down_blocks.1.attentions.1.proj_in.weight': 'input_blocks.5.1.proj_in.weight',
        'down_blocks.1.attentions.1.proj_out.bias': 'input_blocks.5.1.proj_out.bias',
        'down_blocks.1.attentions.1.proj_out.weight': 'input_blocks.5.1.proj_out.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.5.1.transformer_blocks.0.norm1.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.5.1.transformer_blocks.0.norm1.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.5.1.transformer_blocks.0.norm2.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.5.1.transformer_blocks.0.norm2.weight',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.5.1.transformer_blocks.0.norm3.bias',
        'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.5.1.transformer_blocks.0.norm3.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_k.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_q.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_v.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_k.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_q.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_v.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.bias': 'input_blocks.5.1.transformer_blocks.1.ff.net.2.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight': 'input_blocks.5.1.transformer_blocks.1.ff.net.2.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm1.bias': 'input_blocks.5.1.transformer_blocks.1.norm1.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm1.weight': 'input_blocks.5.1.transformer_blocks.1.norm1.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm2.bias': 'input_blocks.5.1.transformer_blocks.1.norm2.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm2.weight': 'input_blocks.5.1.transformer_blocks.1.norm2.weight',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm3.bias': 'input_blocks.5.1.transformer_blocks.1.norm3.bias',
        'down_blocks.1.attentions.1.transformer_blocks.1.norm3.weight': 'input_blocks.5.1.transformer_blocks.1.norm3.weight',
        'down_blocks.1.downsamplers.0.conv.bias': 'input_blocks.6.0.op.bias',
        'down_blocks.1.downsamplers.0.conv.weight': 'input_blocks.6.0.op.weight',
        'down_blocks.1.resnets.0.conv1.bias': 'input_blocks.4.0.in_layers.2.bias',
        'down_blocks.1.resnets.0.conv1.weight': 'input_blocks.4.0.in_layers.2.weight',
        'down_blocks.1.resnets.0.conv2.bias': 'input_blocks.4.0.out_layers.3.bias',
        'down_blocks.1.resnets.0.conv2.weight': 'input_blocks.4.0.out_layers.3.weight',
        'down_blocks.1.resnets.0.conv_shortcut.bias': 'input_blocks.4.0.skip_connection.bias',
        'down_blocks.1.resnets.0.conv_shortcut.weight': 'input_blocks.4.0.skip_connection.weight',
        'down_blocks.1.resnets.0.norm1.bias': 'input_blocks.4.0.in_layers.0.bias',
        'down_blocks.1.resnets.0.norm1.weight': 'input_blocks.4.0.in_layers.0.weight',
        'down_blocks.1.resnets.0.norm2.bias': 'input_blocks.4.0.out_layers.0.bias',
        'down_blocks.1.resnets.0.norm2.weight': 'input_blocks.4.0.out_layers.0.weight',
        'down_blocks.1.resnets.0.time_emb_proj.bias': 'input_blocks.4.0.emb_layers.1.bias',
        'down_blocks.1.resnets.0.time_emb_proj.weight': 'input_blocks.4.0.emb_layers.1.weight',
        'down_blocks.1.resnets.1.conv1.bias': 'input_blocks.5.0.in_layers.2.bias',
        'down_blocks.1.resnets.1.conv1.weight': 'input_blocks.5.0.in_layers.2.weight',
        'down_blocks.1.resnets.1.conv2.bias': 'input_blocks.5.0.out_layers.3.bias',
        'down_blocks.1.resnets.1.conv2.weight': 'input_blocks.5.0.out_layers.3.weight',
        'down_blocks.1.resnets.1.norm1.bias': 'input_blocks.5.0.in_layers.0.bias',
        'down_blocks.1.resnets.1.norm1.weight': 'input_blocks.5.0.in_layers.0.weight',
        'down_blocks.1.resnets.1.norm2.bias': 'input_blocks.5.0.out_layers.0.bias',
        'down_blocks.1.resnets.1.norm2.weight': 'input_blocks.5.0.out_layers.0.weight',
        'down_blocks.1.resnets.1.time_emb_proj.bias': 'input_blocks.5.0.emb_layers.1.bias',
        'down_blocks.1.resnets.1.time_emb_proj.weight': 'input_blocks.5.0.emb_layers.1.weight',
        'down_blocks.2.attentions.0.norm.bias': 'input_blocks.7.1.norm.bias',
        'down_blocks.2.attentions.0.norm.weight': 'input_blocks.7.1.norm.weight',
        'down_blocks.2.attentions.0.proj_in.bias': 'input_blocks.7.1.proj_in.bias',
        'down_blocks.2.attentions.0.proj_in.weight': 'input_blocks.7.1.proj_in.weight',
        'down_blocks.2.attentions.0.proj_out.bias': 'input_blocks.7.1.proj_out.bias',
        'down_blocks.2.attentions.0.proj_out.weight': 'input_blocks.7.1.proj_out.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.7.1.transformer_blocks.0.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.7.1.transformer_blocks.0.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.7.1.transformer_blocks.0.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.7.1.transformer_blocks.0.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.7.1.transformer_blocks.0.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.7.1.transformer_blocks.0.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.1.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.1.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm1.bias': 'input_blocks.7.1.transformer_blocks.1.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm1.weight': 'input_blocks.7.1.transformer_blocks.1.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm2.bias': 'input_blocks.7.1.transformer_blocks.1.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm2.weight': 'input_blocks.7.1.transformer_blocks.1.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm3.bias': 'input_blocks.7.1.transformer_blocks.1.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.1.norm3.weight': 'input_blocks.7.1.transformer_blocks.1.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.2.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.2.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm1.bias': 'input_blocks.7.1.transformer_blocks.2.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm1.weight': 'input_blocks.7.1.transformer_blocks.2.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm2.bias': 'input_blocks.7.1.transformer_blocks.2.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm2.weight': 'input_blocks.7.1.transformer_blocks.2.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm3.bias': 'input_blocks.7.1.transformer_blocks.2.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.2.norm3.weight': 'input_blocks.7.1.transformer_blocks.2.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.3.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.3.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm1.bias': 'input_blocks.7.1.transformer_blocks.3.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm1.weight': 'input_blocks.7.1.transformer_blocks.3.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm2.bias': 'input_blocks.7.1.transformer_blocks.3.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm2.weight': 'input_blocks.7.1.transformer_blocks.3.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm3.bias': 'input_blocks.7.1.transformer_blocks.3.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.3.norm3.weight': 'input_blocks.7.1.transformer_blocks.3.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.4.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.4.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.4.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.4.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.4.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.4.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm1.bias': 'input_blocks.7.1.transformer_blocks.4.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm1.weight': 'input_blocks.7.1.transformer_blocks.4.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm2.bias': 'input_blocks.7.1.transformer_blocks.4.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm2.weight': 'input_blocks.7.1.transformer_blocks.4.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm3.bias': 'input_blocks.7.1.transformer_blocks.4.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.4.norm3.weight': 'input_blocks.7.1.transformer_blocks.4.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.5.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.5.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.5.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.5.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.5.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.5.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm1.bias': 'input_blocks.7.1.transformer_blocks.5.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm1.weight': 'input_blocks.7.1.transformer_blocks.5.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm2.bias': 'input_blocks.7.1.transformer_blocks.5.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm2.weight': 'input_blocks.7.1.transformer_blocks.5.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm3.bias': 'input_blocks.7.1.transformer_blocks.5.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.5.norm3.weight': 'input_blocks.7.1.transformer_blocks.5.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.6.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.6.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.6.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.6.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.6.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.6.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm1.bias': 'input_blocks.7.1.transformer_blocks.6.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm1.weight': 'input_blocks.7.1.transformer_blocks.6.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm2.bias': 'input_blocks.7.1.transformer_blocks.6.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm2.weight': 'input_blocks.7.1.transformer_blocks.6.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm3.bias': 'input_blocks.7.1.transformer_blocks.6.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.6.norm3.weight': 'input_blocks.7.1.transformer_blocks.6.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.7.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.7.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.7.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.7.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.7.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.7.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm1.bias': 'input_blocks.7.1.transformer_blocks.7.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm1.weight': 'input_blocks.7.1.transformer_blocks.7.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm2.bias': 'input_blocks.7.1.transformer_blocks.7.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm2.weight': 'input_blocks.7.1.transformer_blocks.7.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm3.bias': 'input_blocks.7.1.transformer_blocks.7.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.7.norm3.weight': 'input_blocks.7.1.transformer_blocks.7.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.8.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.8.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.8.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.8.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.8.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.8.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm1.bias': 'input_blocks.7.1.transformer_blocks.8.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm1.weight': 'input_blocks.7.1.transformer_blocks.8.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm2.bias': 'input_blocks.7.1.transformer_blocks.8.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm2.weight': 'input_blocks.7.1.transformer_blocks.8.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm3.bias': 'input_blocks.7.1.transformer_blocks.8.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.8.norm3.weight': 'input_blocks.7.1.transformer_blocks.8.norm3.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.9.attn1.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_k.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.9.attn2.to_out.0.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_out.0.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_q.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_v.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.9.ff.net.0.proj.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.9.ff.net.0.proj.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.9.ff.net.2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.9.ff.net.2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm1.bias': 'input_blocks.7.1.transformer_blocks.9.norm1.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm1.weight': 'input_blocks.7.1.transformer_blocks.9.norm1.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm2.bias': 'input_blocks.7.1.transformer_blocks.9.norm2.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm2.weight': 'input_blocks.7.1.transformer_blocks.9.norm2.weight',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm3.bias': 'input_blocks.7.1.transformer_blocks.9.norm3.bias',
        'down_blocks.2.attentions.0.transformer_blocks.9.norm3.weight': 'input_blocks.7.1.transformer_blocks.9.norm3.weight',
        'down_blocks.2.attentions.1.norm.bias': 'input_blocks.8.1.norm.bias',
        'down_blocks.2.attentions.1.norm.weight': 'input_blocks.8.1.norm.weight',
        'down_blocks.2.attentions.1.proj_in.bias': 'input_blocks.8.1.proj_in.bias',
        'down_blocks.2.attentions.1.proj_in.weight': 'input_blocks.8.1.proj_in.weight',
        'down_blocks.2.attentions.1.proj_out.bias': 'input_blocks.8.1.proj_out.bias',
        'down_blocks.2.attentions.1.proj_out.weight': 'input_blocks.8.1.proj_out.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.8.1.transformer_blocks.0.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.8.1.transformer_blocks.0.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.8.1.transformer_blocks.0.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.8.1.transformer_blocks.0.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.8.1.transformer_blocks.0.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.8.1.transformer_blocks.0.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.1.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.1.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm1.bias': 'input_blocks.8.1.transformer_blocks.1.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm1.weight': 'input_blocks.8.1.transformer_blocks.1.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm2.bias': 'input_blocks.8.1.transformer_blocks.1.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm2.weight': 'input_blocks.8.1.transformer_blocks.1.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm3.bias': 'input_blocks.8.1.transformer_blocks.1.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.1.norm3.weight': 'input_blocks.8.1.transformer_blocks.1.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.2.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.2.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm1.bias': 'input_blocks.8.1.transformer_blocks.2.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm1.weight': 'input_blocks.8.1.transformer_blocks.2.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm2.bias': 'input_blocks.8.1.transformer_blocks.2.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm2.weight': 'input_blocks.8.1.transformer_blocks.2.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm3.bias': 'input_blocks.8.1.transformer_blocks.2.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.2.norm3.weight': 'input_blocks.8.1.transformer_blocks.2.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.3.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.3.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm1.bias': 'input_blocks.8.1.transformer_blocks.3.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm1.weight': 'input_blocks.8.1.transformer_blocks.3.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm2.bias': 'input_blocks.8.1.transformer_blocks.3.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm2.weight': 'input_blocks.8.1.transformer_blocks.3.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm3.bias': 'input_blocks.8.1.transformer_blocks.3.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.3.norm3.weight': 'input_blocks.8.1.transformer_blocks.3.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.4.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.4.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.4.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.4.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.4.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.4.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm1.bias': 'input_blocks.8.1.transformer_blocks.4.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm1.weight': 'input_blocks.8.1.transformer_blocks.4.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm2.bias': 'input_blocks.8.1.transformer_blocks.4.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm2.weight': 'input_blocks.8.1.transformer_blocks.4.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm3.bias': 'input_blocks.8.1.transformer_blocks.4.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.4.norm3.weight': 'input_blocks.8.1.transformer_blocks.4.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.5.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.5.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.5.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.5.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.5.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.5.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm1.bias': 'input_blocks.8.1.transformer_blocks.5.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm1.weight': 'input_blocks.8.1.transformer_blocks.5.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm2.bias': 'input_blocks.8.1.transformer_blocks.5.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm2.weight': 'input_blocks.8.1.transformer_blocks.5.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm3.bias': 'input_blocks.8.1.transformer_blocks.5.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.5.norm3.weight': 'input_blocks.8.1.transformer_blocks.5.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.6.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.6.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.6.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.6.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.6.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.6.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm1.bias': 'input_blocks.8.1.transformer_blocks.6.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm1.weight': 'input_blocks.8.1.transformer_blocks.6.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm2.bias': 'input_blocks.8.1.transformer_blocks.6.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm2.weight': 'input_blocks.8.1.transformer_blocks.6.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm3.bias': 'input_blocks.8.1.transformer_blocks.6.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.6.norm3.weight': 'input_blocks.8.1.transformer_blocks.6.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.7.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.7.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.7.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.7.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.7.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.7.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm1.bias': 'input_blocks.8.1.transformer_blocks.7.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm1.weight': 'input_blocks.8.1.transformer_blocks.7.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm2.bias': 'input_blocks.8.1.transformer_blocks.7.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm2.weight': 'input_blocks.8.1.transformer_blocks.7.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm3.bias': 'input_blocks.8.1.transformer_blocks.7.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.7.norm3.weight': 'input_blocks.8.1.transformer_blocks.7.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.8.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.8.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.8.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.8.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.8.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.8.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm1.bias': 'input_blocks.8.1.transformer_blocks.8.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm1.weight': 'input_blocks.8.1.transformer_blocks.8.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm2.bias': 'input_blocks.8.1.transformer_blocks.8.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm2.weight': 'input_blocks.8.1.transformer_blocks.8.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm3.bias': 'input_blocks.8.1.transformer_blocks.8.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.8.norm3.weight': 'input_blocks.8.1.transformer_blocks.8.norm3.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.9.attn1.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_k.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.9.attn2.to_out.0.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_out.0.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_q.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_v.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.9.ff.net.0.proj.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.9.ff.net.0.proj.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.9.ff.net.2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.9.ff.net.2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm1.bias': 'input_blocks.8.1.transformer_blocks.9.norm1.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm1.weight': 'input_blocks.8.1.transformer_blocks.9.norm1.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm2.bias': 'input_blocks.8.1.transformer_blocks.9.norm2.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm2.weight': 'input_blocks.8.1.transformer_blocks.9.norm2.weight',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm3.bias': 'input_blocks.8.1.transformer_blocks.9.norm3.bias',
        'down_blocks.2.attentions.1.transformer_blocks.9.norm3.weight': 'input_blocks.8.1.transformer_blocks.9.norm3.weight',
        'down_blocks.2.resnets.0.conv1.bias': 'input_blocks.7.0.in_layers.2.bias',
        'down_blocks.2.resnets.0.conv1.weight': 'input_blocks.7.0.in_layers.2.weight',
        'down_blocks.2.resnets.0.conv2.bias': 'input_blocks.7.0.out_layers.3.bias',
        'down_blocks.2.resnets.0.conv2.weight': 'input_blocks.7.0.out_layers.3.weight',
        'down_blocks.2.resnets.0.conv_shortcut.bias': 'input_blocks.7.0.skip_connection.bias',
        'down_blocks.2.resnets.0.conv_shortcut.weight': 'input_blocks.7.0.skip_connection.weight',
        'down_blocks.2.resnets.0.norm1.bias': 'input_blocks.7.0.in_layers.0.bias',
        'down_blocks.2.resnets.0.norm1.weight': 'input_blocks.7.0.in_layers.0.weight',
        'down_blocks.2.resnets.0.norm2.bias': 'input_blocks.7.0.out_layers.0.bias',
        'down_blocks.2.resnets.0.norm2.weight': 'input_blocks.7.0.out_layers.0.weight',
        'down_blocks.2.resnets.0.time_emb_proj.bias': 'input_blocks.7.0.emb_layers.1.bias',
        'down_blocks.2.resnets.0.time_emb_proj.weight': 'input_blocks.7.0.emb_layers.1.weight',
        'down_blocks.2.resnets.1.conv1.bias': 'input_blocks.8.0.in_layers.2.bias',
        'down_blocks.2.resnets.1.conv1.weight': 'input_blocks.8.0.in_layers.2.weight',
        'down_blocks.2.resnets.1.conv2.bias': 'input_blocks.8.0.out_layers.3.bias',
        'down_blocks.2.resnets.1.conv2.weight': 'input_blocks.8.0.out_layers.3.weight',
        'down_blocks.2.resnets.1.norm1.bias': 'input_blocks.8.0.in_layers.0.bias',
        'down_blocks.2.resnets.1.norm1.weight': 'input_blocks.8.0.in_layers.0.weight',
        'down_blocks.2.resnets.1.norm2.bias': 'input_blocks.8.0.out_layers.0.bias',
        'down_blocks.2.resnets.1.norm2.weight': 'input_blocks.8.0.out_layers.0.weight',
        'down_blocks.2.resnets.1.time_emb_proj.bias': 'input_blocks.8.0.emb_layers.1.bias',
        'down_blocks.2.resnets.1.time_emb_proj.weight': 'input_blocks.8.0.emb_layers.1.weight',
        'mid_block.attentions.0.norm.bias': 'middle_block.1.norm.bias',
        'mid_block.attentions.0.norm.weight': 'middle_block.1.norm.weight',
        'mid_block.attentions.0.proj_in.bias': 'middle_block.1.proj_in.bias',
        'mid_block.attentions.0.proj_in.weight': 'middle_block.1.proj_in.weight',
        'mid_block.attentions.0.proj_out.bias': 'middle_block.1.proj_out.bias',
        'mid_block.attentions.0.proj_out.weight': 'middle_block.1.proj_out.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'middle_block.1.transformer_blocks.0.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.0.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.0.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'middle_block.1.transformer_blocks.0.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'middle_block.1.transformer_blocks.0.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'middle_block.1.transformer_blocks.0.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.0.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.0.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'middle_block.1.transformer_blocks.0.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'middle_block.1.transformer_blocks.0.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.0.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.0.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias': 'middle_block.1.transformer_blocks.0.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight': 'middle_block.1.transformer_blocks.0.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.0.norm1.bias': 'middle_block.1.transformer_blocks.0.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.0.norm1.weight': 'middle_block.1.transformer_blocks.0.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.0.norm2.bias': 'middle_block.1.transformer_blocks.0.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.0.norm2.weight': 'middle_block.1.transformer_blocks.0.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.0.norm3.bias': 'middle_block.1.transformer_blocks.0.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.0.norm3.weight': 'middle_block.1.transformer_blocks.0.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'middle_block.1.transformer_blocks.1.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.1.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.1.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'middle_block.1.transformer_blocks.1.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'middle_block.1.transformer_blocks.1.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'middle_block.1.transformer_blocks.1.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.1.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.1.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'middle_block.1.transformer_blocks.1.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'middle_block.1.transformer_blocks.1.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.1.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.1.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.1.ff.net.2.bias': 'middle_block.1.transformer_blocks.1.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.1.ff.net.2.weight': 'middle_block.1.transformer_blocks.1.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.1.norm1.bias': 'middle_block.1.transformer_blocks.1.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.1.norm1.weight': 'middle_block.1.transformer_blocks.1.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.1.norm2.bias': 'middle_block.1.transformer_blocks.1.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.1.norm2.weight': 'middle_block.1.transformer_blocks.1.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.1.norm3.bias': 'middle_block.1.transformer_blocks.1.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.1.norm3.weight': 'middle_block.1.transformer_blocks.1.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn1.to_k.weight': 'middle_block.1.transformer_blocks.2.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.2.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.2.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.2.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn1.to_q.weight': 'middle_block.1.transformer_blocks.2.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn1.to_v.weight': 'middle_block.1.transformer_blocks.2.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn2.to_k.weight': 'middle_block.1.transformer_blocks.2.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.2.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.2.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.2.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn2.to_q.weight': 'middle_block.1.transformer_blocks.2.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.2.attn2.to_v.weight': 'middle_block.1.transformer_blocks.2.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.2.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.2.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.2.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.2.ff.net.2.bias': 'middle_block.1.transformer_blocks.2.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.2.ff.net.2.weight': 'middle_block.1.transformer_blocks.2.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.2.norm1.bias': 'middle_block.1.transformer_blocks.2.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.2.norm1.weight': 'middle_block.1.transformer_blocks.2.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.2.norm2.bias': 'middle_block.1.transformer_blocks.2.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.2.norm2.weight': 'middle_block.1.transformer_blocks.2.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.2.norm3.bias': 'middle_block.1.transformer_blocks.2.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.2.norm3.weight': 'middle_block.1.transformer_blocks.2.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn1.to_k.weight': 'middle_block.1.transformer_blocks.3.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.3.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.3.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.3.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn1.to_q.weight': 'middle_block.1.transformer_blocks.3.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn1.to_v.weight': 'middle_block.1.transformer_blocks.3.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn2.to_k.weight': 'middle_block.1.transformer_blocks.3.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.3.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.3.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.3.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn2.to_q.weight': 'middle_block.1.transformer_blocks.3.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.3.attn2.to_v.weight': 'middle_block.1.transformer_blocks.3.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.3.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.3.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.3.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.3.ff.net.2.bias': 'middle_block.1.transformer_blocks.3.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.3.ff.net.2.weight': 'middle_block.1.transformer_blocks.3.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.3.norm1.bias': 'middle_block.1.transformer_blocks.3.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.3.norm1.weight': 'middle_block.1.transformer_blocks.3.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.3.norm2.bias': 'middle_block.1.transformer_blocks.3.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.3.norm2.weight': 'middle_block.1.transformer_blocks.3.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.3.norm3.bias': 'middle_block.1.transformer_blocks.3.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.3.norm3.weight': 'middle_block.1.transformer_blocks.3.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn1.to_k.weight': 'middle_block.1.transformer_blocks.4.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.4.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.4.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.4.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn1.to_q.weight': 'middle_block.1.transformer_blocks.4.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn1.to_v.weight': 'middle_block.1.transformer_blocks.4.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn2.to_k.weight': 'middle_block.1.transformer_blocks.4.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.4.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.4.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.4.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn2.to_q.weight': 'middle_block.1.transformer_blocks.4.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.4.attn2.to_v.weight': 'middle_block.1.transformer_blocks.4.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.4.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.4.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.4.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.4.ff.net.2.bias': 'middle_block.1.transformer_blocks.4.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.4.ff.net.2.weight': 'middle_block.1.transformer_blocks.4.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.4.norm1.bias': 'middle_block.1.transformer_blocks.4.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.4.norm1.weight': 'middle_block.1.transformer_blocks.4.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.4.norm2.bias': 'middle_block.1.transformer_blocks.4.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.4.norm2.weight': 'middle_block.1.transformer_blocks.4.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.4.norm3.bias': 'middle_block.1.transformer_blocks.4.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.4.norm3.weight': 'middle_block.1.transformer_blocks.4.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn1.to_k.weight': 'middle_block.1.transformer_blocks.5.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.5.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.5.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.5.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn1.to_q.weight': 'middle_block.1.transformer_blocks.5.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn1.to_v.weight': 'middle_block.1.transformer_blocks.5.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn2.to_k.weight': 'middle_block.1.transformer_blocks.5.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.5.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.5.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.5.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn2.to_q.weight': 'middle_block.1.transformer_blocks.5.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.5.attn2.to_v.weight': 'middle_block.1.transformer_blocks.5.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.5.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.5.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.5.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.5.ff.net.2.bias': 'middle_block.1.transformer_blocks.5.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.5.ff.net.2.weight': 'middle_block.1.transformer_blocks.5.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.5.norm1.bias': 'middle_block.1.transformer_blocks.5.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.5.norm1.weight': 'middle_block.1.transformer_blocks.5.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.5.norm2.bias': 'middle_block.1.transformer_blocks.5.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.5.norm2.weight': 'middle_block.1.transformer_blocks.5.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.5.norm3.bias': 'middle_block.1.transformer_blocks.5.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.5.norm3.weight': 'middle_block.1.transformer_blocks.5.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn1.to_k.weight': 'middle_block.1.transformer_blocks.6.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.6.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.6.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.6.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn1.to_q.weight': 'middle_block.1.transformer_blocks.6.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn1.to_v.weight': 'middle_block.1.transformer_blocks.6.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn2.to_k.weight': 'middle_block.1.transformer_blocks.6.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.6.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.6.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.6.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn2.to_q.weight': 'middle_block.1.transformer_blocks.6.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.6.attn2.to_v.weight': 'middle_block.1.transformer_blocks.6.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.6.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.6.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.6.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.6.ff.net.2.bias': 'middle_block.1.transformer_blocks.6.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.6.ff.net.2.weight': 'middle_block.1.transformer_blocks.6.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.6.norm1.bias': 'middle_block.1.transformer_blocks.6.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.6.norm1.weight': 'middle_block.1.transformer_blocks.6.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.6.norm2.bias': 'middle_block.1.transformer_blocks.6.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.6.norm2.weight': 'middle_block.1.transformer_blocks.6.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.6.norm3.bias': 'middle_block.1.transformer_blocks.6.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.6.norm3.weight': 'middle_block.1.transformer_blocks.6.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn1.to_k.weight': 'middle_block.1.transformer_blocks.7.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.7.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.7.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.7.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn1.to_q.weight': 'middle_block.1.transformer_blocks.7.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn1.to_v.weight': 'middle_block.1.transformer_blocks.7.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn2.to_k.weight': 'middle_block.1.transformer_blocks.7.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.7.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.7.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.7.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn2.to_q.weight': 'middle_block.1.transformer_blocks.7.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.7.attn2.to_v.weight': 'middle_block.1.transformer_blocks.7.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.7.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.7.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.7.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.7.ff.net.2.bias': 'middle_block.1.transformer_blocks.7.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.7.ff.net.2.weight': 'middle_block.1.transformer_blocks.7.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.7.norm1.bias': 'middle_block.1.transformer_blocks.7.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.7.norm1.weight': 'middle_block.1.transformer_blocks.7.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.7.norm2.bias': 'middle_block.1.transformer_blocks.7.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.7.norm2.weight': 'middle_block.1.transformer_blocks.7.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.7.norm3.bias': 'middle_block.1.transformer_blocks.7.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.7.norm3.weight': 'middle_block.1.transformer_blocks.7.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn1.to_k.weight': 'middle_block.1.transformer_blocks.8.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.8.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.8.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.8.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn1.to_q.weight': 'middle_block.1.transformer_blocks.8.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn1.to_v.weight': 'middle_block.1.transformer_blocks.8.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn2.to_k.weight': 'middle_block.1.transformer_blocks.8.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.8.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.8.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.8.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn2.to_q.weight': 'middle_block.1.transformer_blocks.8.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.8.attn2.to_v.weight': 'middle_block.1.transformer_blocks.8.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.8.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.8.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.8.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.8.ff.net.2.bias': 'middle_block.1.transformer_blocks.8.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.8.ff.net.2.weight': 'middle_block.1.transformer_blocks.8.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.8.norm1.bias': 'middle_block.1.transformer_blocks.8.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.8.norm1.weight': 'middle_block.1.transformer_blocks.8.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.8.norm2.bias': 'middle_block.1.transformer_blocks.8.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.8.norm2.weight': 'middle_block.1.transformer_blocks.8.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.8.norm3.bias': 'middle_block.1.transformer_blocks.8.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.8.norm3.weight': 'middle_block.1.transformer_blocks.8.norm3.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn1.to_k.weight': 'middle_block.1.transformer_blocks.9.attn1.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.9.attn1.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.9.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.9.attn1.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn1.to_q.weight': 'middle_block.1.transformer_blocks.9.attn1.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn1.to_v.weight': 'middle_block.1.transformer_blocks.9.attn1.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn2.to_k.weight': 'middle_block.1.transformer_blocks.9.attn2.to_k.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.9.attn2.to_out.0.bias',
        'mid_block.attentions.0.transformer_blocks.9.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.9.attn2.to_out.0.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn2.to_q.weight': 'middle_block.1.transformer_blocks.9.attn2.to_q.weight',
        'mid_block.attentions.0.transformer_blocks.9.attn2.to_v.weight': 'middle_block.1.transformer_blocks.9.attn2.to_v.weight',
        'mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.9.ff.net.0.proj.bias',
        'mid_block.attentions.0.transformer_blocks.9.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.9.ff.net.0.proj.weight',
        'mid_block.attentions.0.transformer_blocks.9.ff.net.2.bias': 'middle_block.1.transformer_blocks.9.ff.net.2.bias',
        'mid_block.attentions.0.transformer_blocks.9.ff.net.2.weight': 'middle_block.1.transformer_blocks.9.ff.net.2.weight',
        'mid_block.attentions.0.transformer_blocks.9.norm1.bias': 'middle_block.1.transformer_blocks.9.norm1.bias',
        'mid_block.attentions.0.transformer_blocks.9.norm1.weight': 'middle_block.1.transformer_blocks.9.norm1.weight',
        'mid_block.attentions.0.transformer_blocks.9.norm2.bias': 'middle_block.1.transformer_blocks.9.norm2.bias',
        'mid_block.attentions.0.transformer_blocks.9.norm2.weight': 'middle_block.1.transformer_blocks.9.norm2.weight',
        'mid_block.attentions.0.transformer_blocks.9.norm3.bias': 'middle_block.1.transformer_blocks.9.norm3.bias',
        'mid_block.attentions.0.transformer_blocks.9.norm3.weight': 'middle_block.1.transformer_blocks.9.norm3.weight',
        'mid_block.resnets.0.conv1.bias': 'middle_block.0.in_layers.2.bias',
        'mid_block.resnets.0.conv1.weight': 'middle_block.0.in_layers.2.weight',
        'mid_block.resnets.0.conv2.bias': 'middle_block.0.out_layers.3.bias',
        'mid_block.resnets.0.conv2.weight': 'middle_block.0.out_layers.3.weight',
        'mid_block.resnets.0.norm1.bias': 'middle_block.0.in_layers.0.bias',
        'mid_block.resnets.0.norm1.weight': 'middle_block.0.in_layers.0.weight',
        'mid_block.resnets.0.norm2.bias': 'middle_block.0.out_layers.0.bias',
        'mid_block.resnets.0.norm2.weight': 'middle_block.0.out_layers.0.weight',
        'mid_block.resnets.0.time_emb_proj.bias': 'middle_block.0.emb_layers.1.bias',
        'mid_block.resnets.0.time_emb_proj.weight': 'middle_block.0.emb_layers.1.weight',
        'mid_block.resnets.1.conv1.bias': 'middle_block.2.in_layers.2.bias',
        'mid_block.resnets.1.conv1.weight': 'middle_block.2.in_layers.2.weight',
        'mid_block.resnets.1.conv2.bias': 'middle_block.2.out_layers.3.bias',
        'mid_block.resnets.1.conv2.weight': 'middle_block.2.out_layers.3.weight',
        'mid_block.resnets.1.norm1.bias': 'middle_block.2.in_layers.0.bias',
        'mid_block.resnets.1.norm1.weight': 'middle_block.2.in_layers.0.weight',
        'mid_block.resnets.1.norm2.bias': 'middle_block.2.out_layers.0.bias',
        'mid_block.resnets.1.norm2.weight': 'middle_block.2.out_layers.0.weight',
        'mid_block.resnets.1.time_emb_proj.bias': 'middle_block.2.emb_layers.1.bias',
        'mid_block.resnets.1.time_emb_proj.weight': 'middle_block.2.emb_layers.1.weight',
        'time_embedding.linear_1.bias': 'time_embed.0.bias', 'time_embedding.linear_1.weight': 'time_embed.0.weight',
        'time_embedding.linear_2.bias': 'time_embed.2.bias', 'time_embedding.linear_2.weight': 'time_embed.2.weight',
        'up_blocks.0.attentions.0.norm.bias': 'output_blocks.0.1.norm.bias',
        'up_blocks.0.attentions.0.norm.weight': 'output_blocks.0.1.norm.weight',
        'up_blocks.0.attentions.0.proj_in.bias': 'output_blocks.0.1.proj_in.bias',
        'up_blocks.0.attentions.0.proj_in.weight': 'output_blocks.0.1.proj_in.weight',
        'up_blocks.0.attentions.0.proj_out.bias': 'output_blocks.0.1.proj_out.bias',
        'up_blocks.0.attentions.0.proj_out.weight': 'output_blocks.0.1.proj_out.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias': 'output_blocks.0.1.transformer_blocks.0.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight': 'output_blocks.0.1.transformer_blocks.0.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias': 'output_blocks.0.1.transformer_blocks.0.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight': 'output_blocks.0.1.transformer_blocks.0.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias': 'output_blocks.0.1.transformer_blocks.0.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight': 'output_blocks.0.1.transformer_blocks.0.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm1.bias': 'output_blocks.0.1.transformer_blocks.1.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm1.weight': 'output_blocks.0.1.transformer_blocks.1.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm2.bias': 'output_blocks.0.1.transformer_blocks.1.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm2.weight': 'output_blocks.0.1.transformer_blocks.1.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm3.bias': 'output_blocks.0.1.transformer_blocks.1.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.1.norm3.weight': 'output_blocks.0.1.transformer_blocks.1.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.2.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.2.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm1.bias': 'output_blocks.0.1.transformer_blocks.2.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm1.weight': 'output_blocks.0.1.transformer_blocks.2.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm2.bias': 'output_blocks.0.1.transformer_blocks.2.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm2.weight': 'output_blocks.0.1.transformer_blocks.2.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm3.bias': 'output_blocks.0.1.transformer_blocks.2.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.2.norm3.weight': 'output_blocks.0.1.transformer_blocks.2.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.3.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.3.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm1.bias': 'output_blocks.0.1.transformer_blocks.3.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm1.weight': 'output_blocks.0.1.transformer_blocks.3.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm2.bias': 'output_blocks.0.1.transformer_blocks.3.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm2.weight': 'output_blocks.0.1.transformer_blocks.3.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm3.bias': 'output_blocks.0.1.transformer_blocks.3.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.3.norm3.weight': 'output_blocks.0.1.transformer_blocks.3.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.4.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.4.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.4.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.4.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.4.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.4.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm1.bias': 'output_blocks.0.1.transformer_blocks.4.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm1.weight': 'output_blocks.0.1.transformer_blocks.4.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm2.bias': 'output_blocks.0.1.transformer_blocks.4.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm2.weight': 'output_blocks.0.1.transformer_blocks.4.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm3.bias': 'output_blocks.0.1.transformer_blocks.4.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.4.norm3.weight': 'output_blocks.0.1.transformer_blocks.4.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.5.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.5.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.5.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.5.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.5.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.5.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm1.bias': 'output_blocks.0.1.transformer_blocks.5.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm1.weight': 'output_blocks.0.1.transformer_blocks.5.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm2.bias': 'output_blocks.0.1.transformer_blocks.5.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm2.weight': 'output_blocks.0.1.transformer_blocks.5.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm3.bias': 'output_blocks.0.1.transformer_blocks.5.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.5.norm3.weight': 'output_blocks.0.1.transformer_blocks.5.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.6.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.6.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.6.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.6.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.6.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.6.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm1.bias': 'output_blocks.0.1.transformer_blocks.6.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm1.weight': 'output_blocks.0.1.transformer_blocks.6.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm2.bias': 'output_blocks.0.1.transformer_blocks.6.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm2.weight': 'output_blocks.0.1.transformer_blocks.6.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm3.bias': 'output_blocks.0.1.transformer_blocks.6.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.6.norm3.weight': 'output_blocks.0.1.transformer_blocks.6.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.7.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.7.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.7.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.7.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.7.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.7.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm1.bias': 'output_blocks.0.1.transformer_blocks.7.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm1.weight': 'output_blocks.0.1.transformer_blocks.7.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm2.bias': 'output_blocks.0.1.transformer_blocks.7.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm2.weight': 'output_blocks.0.1.transformer_blocks.7.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm3.bias': 'output_blocks.0.1.transformer_blocks.7.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.7.norm3.weight': 'output_blocks.0.1.transformer_blocks.7.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.8.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.8.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.8.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.8.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.8.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.8.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm1.bias': 'output_blocks.0.1.transformer_blocks.8.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm1.weight': 'output_blocks.0.1.transformer_blocks.8.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm2.bias': 'output_blocks.0.1.transformer_blocks.8.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm2.weight': 'output_blocks.0.1.transformer_blocks.8.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm3.bias': 'output_blocks.0.1.transformer_blocks.8.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.8.norm3.weight': 'output_blocks.0.1.transformer_blocks.8.norm3.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.9.attn1.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_k.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.9.attn2.to_out.0.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_out.0.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_q.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_v.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.9.ff.net.0.proj.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.9.ff.net.0.proj.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.9.ff.net.2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.9.ff.net.2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm1.bias': 'output_blocks.0.1.transformer_blocks.9.norm1.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm1.weight': 'output_blocks.0.1.transformer_blocks.9.norm1.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm2.bias': 'output_blocks.0.1.transformer_blocks.9.norm2.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm2.weight': 'output_blocks.0.1.transformer_blocks.9.norm2.weight',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm3.bias': 'output_blocks.0.1.transformer_blocks.9.norm3.bias',
        'up_blocks.0.attentions.0.transformer_blocks.9.norm3.weight': 'output_blocks.0.1.transformer_blocks.9.norm3.weight',
        'up_blocks.0.attentions.1.norm.bias': 'output_blocks.1.1.norm.bias',
        'up_blocks.0.attentions.1.norm.weight': 'output_blocks.1.1.norm.weight',
        'up_blocks.0.attentions.1.proj_in.bias': 'output_blocks.1.1.proj_in.bias',
        'up_blocks.0.attentions.1.proj_in.weight': 'output_blocks.1.1.proj_in.weight',
        'up_blocks.0.attentions.1.proj_out.bias': 'output_blocks.1.1.proj_out.bias',
        'up_blocks.0.attentions.1.proj_out.weight': 'output_blocks.1.1.proj_out.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias': 'output_blocks.1.1.transformer_blocks.0.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight': 'output_blocks.1.1.transformer_blocks.0.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm2.bias': 'output_blocks.1.1.transformer_blocks.0.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm2.weight': 'output_blocks.1.1.transformer_blocks.0.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm3.bias': 'output_blocks.1.1.transformer_blocks.0.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.0.norm3.weight': 'output_blocks.1.1.transformer_blocks.0.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm1.bias': 'output_blocks.1.1.transformer_blocks.1.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm1.weight': 'output_blocks.1.1.transformer_blocks.1.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm2.bias': 'output_blocks.1.1.transformer_blocks.1.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm2.weight': 'output_blocks.1.1.transformer_blocks.1.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm3.bias': 'output_blocks.1.1.transformer_blocks.1.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.1.norm3.weight': 'output_blocks.1.1.transformer_blocks.1.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.2.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.2.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.2.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.2.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.2.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.2.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.2.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.2.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.2.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.2.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.2.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm1.bias': 'output_blocks.1.1.transformer_blocks.2.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm1.weight': 'output_blocks.1.1.transformer_blocks.2.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm2.bias': 'output_blocks.1.1.transformer_blocks.2.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm2.weight': 'output_blocks.1.1.transformer_blocks.2.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm3.bias': 'output_blocks.1.1.transformer_blocks.2.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.2.norm3.weight': 'output_blocks.1.1.transformer_blocks.2.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.3.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.3.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.3.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.3.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.3.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.3.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.3.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.3.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.3.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.3.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.3.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm1.bias': 'output_blocks.1.1.transformer_blocks.3.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm1.weight': 'output_blocks.1.1.transformer_blocks.3.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm2.bias': 'output_blocks.1.1.transformer_blocks.3.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm2.weight': 'output_blocks.1.1.transformer_blocks.3.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm3.bias': 'output_blocks.1.1.transformer_blocks.3.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.3.norm3.weight': 'output_blocks.1.1.transformer_blocks.3.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.4.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.4.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.4.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.4.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.4.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.4.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.4.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.4.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.4.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.4.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.4.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.4.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.4.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.4.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm1.bias': 'output_blocks.1.1.transformer_blocks.4.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm1.weight': 'output_blocks.1.1.transformer_blocks.4.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm2.bias': 'output_blocks.1.1.transformer_blocks.4.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm2.weight': 'output_blocks.1.1.transformer_blocks.4.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm3.bias': 'output_blocks.1.1.transformer_blocks.4.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.4.norm3.weight': 'output_blocks.1.1.transformer_blocks.4.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.5.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.5.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.5.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.5.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.5.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.5.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.5.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.5.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.5.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.5.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.5.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.5.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.5.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.5.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm1.bias': 'output_blocks.1.1.transformer_blocks.5.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm1.weight': 'output_blocks.1.1.transformer_blocks.5.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm2.bias': 'output_blocks.1.1.transformer_blocks.5.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm2.weight': 'output_blocks.1.1.transformer_blocks.5.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm3.bias': 'output_blocks.1.1.transformer_blocks.5.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.5.norm3.weight': 'output_blocks.1.1.transformer_blocks.5.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.6.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.6.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.6.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.6.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.6.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.6.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.6.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.6.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.6.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.6.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.6.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.6.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.6.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.6.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm1.bias': 'output_blocks.1.1.transformer_blocks.6.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm1.weight': 'output_blocks.1.1.transformer_blocks.6.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm2.bias': 'output_blocks.1.1.transformer_blocks.6.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm2.weight': 'output_blocks.1.1.transformer_blocks.6.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm3.bias': 'output_blocks.1.1.transformer_blocks.6.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.6.norm3.weight': 'output_blocks.1.1.transformer_blocks.6.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.7.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.7.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.7.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.7.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.7.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.7.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.7.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.7.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.7.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.7.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.7.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.7.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.7.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.7.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm1.bias': 'output_blocks.1.1.transformer_blocks.7.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm1.weight': 'output_blocks.1.1.transformer_blocks.7.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm2.bias': 'output_blocks.1.1.transformer_blocks.7.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm2.weight': 'output_blocks.1.1.transformer_blocks.7.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm3.bias': 'output_blocks.1.1.transformer_blocks.7.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.7.norm3.weight': 'output_blocks.1.1.transformer_blocks.7.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.8.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.8.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.8.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.8.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.8.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.8.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.8.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.8.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.8.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.8.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.8.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.8.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.8.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.8.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm1.bias': 'output_blocks.1.1.transformer_blocks.8.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm1.weight': 'output_blocks.1.1.transformer_blocks.8.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm2.bias': 'output_blocks.1.1.transformer_blocks.8.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm2.weight': 'output_blocks.1.1.transformer_blocks.8.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm3.bias': 'output_blocks.1.1.transformer_blocks.8.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.8.norm3.weight': 'output_blocks.1.1.transformer_blocks.8.norm3.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_k.weight': 'output_blocks.1.1.transformer_blocks.9.attn1.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.9.attn1.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.9.attn1.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.9.attn1.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn1.to_v.weight': 'output_blocks.1.1.transformer_blocks.9.attn1.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_k.weight': 'output_blocks.1.1.transformer_blocks.9.attn2.to_k.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.bias': 'output_blocks.1.1.transformer_blocks.9.attn2.to_out.0.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_out.0.weight': 'output_blocks.1.1.transformer_blocks.9.attn2.to_out.0.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_q.weight': 'output_blocks.1.1.transformer_blocks.9.attn2.to_q.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.attn2.to_v.weight': 'output_blocks.1.1.transformer_blocks.9.attn2.to_v.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.bias': 'output_blocks.1.1.transformer_blocks.9.ff.net.0.proj.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.ff.net.0.proj.weight': 'output_blocks.1.1.transformer_blocks.9.ff.net.0.proj.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.bias': 'output_blocks.1.1.transformer_blocks.9.ff.net.2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.ff.net.2.weight': 'output_blocks.1.1.transformer_blocks.9.ff.net.2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm1.bias': 'output_blocks.1.1.transformer_blocks.9.norm1.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm1.weight': 'output_blocks.1.1.transformer_blocks.9.norm1.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm2.bias': 'output_blocks.1.1.transformer_blocks.9.norm2.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm2.weight': 'output_blocks.1.1.transformer_blocks.9.norm2.weight',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm3.bias': 'output_blocks.1.1.transformer_blocks.9.norm3.bias',
        'up_blocks.0.attentions.1.transformer_blocks.9.norm3.weight': 'output_blocks.1.1.transformer_blocks.9.norm3.weight',
        'up_blocks.0.attentions.2.norm.bias': 'output_blocks.2.1.norm.bias',
        'up_blocks.0.attentions.2.norm.weight': 'output_blocks.2.1.norm.weight',
        'up_blocks.0.attentions.2.proj_in.bias': 'output_blocks.2.1.proj_in.bias',
        'up_blocks.0.attentions.2.proj_in.weight': 'output_blocks.2.1.proj_in.weight',
        'up_blocks.0.attentions.2.proj_out.bias': 'output_blocks.2.1.proj_out.bias',
        'up_blocks.0.attentions.2.proj_out.weight': 'output_blocks.2.1.proj_out.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm1.bias': 'output_blocks.2.1.transformer_blocks.0.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm1.weight': 'output_blocks.2.1.transformer_blocks.0.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm2.bias': 'output_blocks.2.1.transformer_blocks.0.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm2.weight': 'output_blocks.2.1.transformer_blocks.0.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm3.bias': 'output_blocks.2.1.transformer_blocks.0.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.0.norm3.weight': 'output_blocks.2.1.transformer_blocks.0.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm1.bias': 'output_blocks.2.1.transformer_blocks.1.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm1.weight': 'output_blocks.2.1.transformer_blocks.1.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm2.bias': 'output_blocks.2.1.transformer_blocks.1.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm2.weight': 'output_blocks.2.1.transformer_blocks.1.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm3.bias': 'output_blocks.2.1.transformer_blocks.1.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.1.norm3.weight': 'output_blocks.2.1.transformer_blocks.1.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.2.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.2.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.2.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.2.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.2.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.2.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.2.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.2.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.2.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.2.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.2.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm1.bias': 'output_blocks.2.1.transformer_blocks.2.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm1.weight': 'output_blocks.2.1.transformer_blocks.2.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm2.bias': 'output_blocks.2.1.transformer_blocks.2.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm2.weight': 'output_blocks.2.1.transformer_blocks.2.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm3.bias': 'output_blocks.2.1.transformer_blocks.2.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.2.norm3.weight': 'output_blocks.2.1.transformer_blocks.2.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.3.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.3.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.3.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.3.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.3.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.3.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.3.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.3.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.3.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.3.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.3.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm1.bias': 'output_blocks.2.1.transformer_blocks.3.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm1.weight': 'output_blocks.2.1.transformer_blocks.3.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm2.bias': 'output_blocks.2.1.transformer_blocks.3.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm2.weight': 'output_blocks.2.1.transformer_blocks.3.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm3.bias': 'output_blocks.2.1.transformer_blocks.3.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.3.norm3.weight': 'output_blocks.2.1.transformer_blocks.3.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.4.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.4.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.4.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.4.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.4.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.4.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.4.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.4.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.4.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.4.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.4.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.4.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.4.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.4.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm1.bias': 'output_blocks.2.1.transformer_blocks.4.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm1.weight': 'output_blocks.2.1.transformer_blocks.4.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm2.bias': 'output_blocks.2.1.transformer_blocks.4.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm2.weight': 'output_blocks.2.1.transformer_blocks.4.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm3.bias': 'output_blocks.2.1.transformer_blocks.4.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.4.norm3.weight': 'output_blocks.2.1.transformer_blocks.4.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.5.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.5.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.5.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.5.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.5.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.5.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.5.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.5.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.5.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.5.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.5.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.5.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.5.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.5.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm1.bias': 'output_blocks.2.1.transformer_blocks.5.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm1.weight': 'output_blocks.2.1.transformer_blocks.5.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm2.bias': 'output_blocks.2.1.transformer_blocks.5.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm2.weight': 'output_blocks.2.1.transformer_blocks.5.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm3.bias': 'output_blocks.2.1.transformer_blocks.5.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.5.norm3.weight': 'output_blocks.2.1.transformer_blocks.5.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.6.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.6.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.6.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.6.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.6.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.6.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.6.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.6.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.6.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.6.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.6.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.6.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.6.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.6.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm1.bias': 'output_blocks.2.1.transformer_blocks.6.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm1.weight': 'output_blocks.2.1.transformer_blocks.6.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm2.bias': 'output_blocks.2.1.transformer_blocks.6.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm2.weight': 'output_blocks.2.1.transformer_blocks.6.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm3.bias': 'output_blocks.2.1.transformer_blocks.6.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.6.norm3.weight': 'output_blocks.2.1.transformer_blocks.6.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.7.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.7.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.7.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.7.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.7.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.7.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.7.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.7.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.7.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.7.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.7.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.7.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.7.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.7.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm1.bias': 'output_blocks.2.1.transformer_blocks.7.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm1.weight': 'output_blocks.2.1.transformer_blocks.7.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm2.bias': 'output_blocks.2.1.transformer_blocks.7.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm2.weight': 'output_blocks.2.1.transformer_blocks.7.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm3.bias': 'output_blocks.2.1.transformer_blocks.7.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.7.norm3.weight': 'output_blocks.2.1.transformer_blocks.7.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.8.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.8.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.8.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.8.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.8.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.8.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.8.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.8.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.8.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.8.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.8.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.8.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.8.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.8.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm1.bias': 'output_blocks.2.1.transformer_blocks.8.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm1.weight': 'output_blocks.2.1.transformer_blocks.8.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm2.bias': 'output_blocks.2.1.transformer_blocks.8.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm2.weight': 'output_blocks.2.1.transformer_blocks.8.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm3.bias': 'output_blocks.2.1.transformer_blocks.8.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.8.norm3.weight': 'output_blocks.2.1.transformer_blocks.8.norm3.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_k.weight': 'output_blocks.2.1.transformer_blocks.9.attn1.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.9.attn1.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.9.attn1.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_q.weight': 'output_blocks.2.1.transformer_blocks.9.attn1.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn1.to_v.weight': 'output_blocks.2.1.transformer_blocks.9.attn1.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_k.weight': 'output_blocks.2.1.transformer_blocks.9.attn2.to_k.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.bias': 'output_blocks.2.1.transformer_blocks.9.attn2.to_out.0.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_out.0.weight': 'output_blocks.2.1.transformer_blocks.9.attn2.to_out.0.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_q.weight': 'output_blocks.2.1.transformer_blocks.9.attn2.to_q.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.attn2.to_v.weight': 'output_blocks.2.1.transformer_blocks.9.attn2.to_v.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.bias': 'output_blocks.2.1.transformer_blocks.9.ff.net.0.proj.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.ff.net.0.proj.weight': 'output_blocks.2.1.transformer_blocks.9.ff.net.0.proj.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.bias': 'output_blocks.2.1.transformer_blocks.9.ff.net.2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.ff.net.2.weight': 'output_blocks.2.1.transformer_blocks.9.ff.net.2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm1.bias': 'output_blocks.2.1.transformer_blocks.9.norm1.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm1.weight': 'output_blocks.2.1.transformer_blocks.9.norm1.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm2.bias': 'output_blocks.2.1.transformer_blocks.9.norm2.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm2.weight': 'output_blocks.2.1.transformer_blocks.9.norm2.weight',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm3.bias': 'output_blocks.2.1.transformer_blocks.9.norm3.bias',
        'up_blocks.0.attentions.2.transformer_blocks.9.norm3.weight': 'output_blocks.2.1.transformer_blocks.9.norm3.weight',
        'up_blocks.0.resnets.0.conv1.bias': 'output_blocks.0.0.in_layers.2.bias',
        'up_blocks.0.resnets.0.conv1.weight': 'output_blocks.0.0.in_layers.2.weight',
        'up_blocks.0.resnets.0.conv2.bias': 'output_blocks.0.0.out_layers.3.bias',
        'up_blocks.0.resnets.0.conv2.weight': 'output_blocks.0.0.out_layers.3.weight',
        'up_blocks.0.resnets.0.conv_shortcut.bias': 'output_blocks.0.0.skip_connection.bias',
        'up_blocks.0.resnets.0.conv_shortcut.weight': 'output_blocks.0.0.skip_connection.weight',
        'up_blocks.0.resnets.0.norm1.bias': 'output_blocks.0.0.in_layers.0.bias',
        'up_blocks.0.resnets.0.norm1.weight': 'output_blocks.0.0.in_layers.0.weight',
        'up_blocks.0.resnets.0.norm2.bias': 'output_blocks.0.0.out_layers.0.bias',
        'up_blocks.0.resnets.0.norm2.weight': 'output_blocks.0.0.out_layers.0.weight',
        'up_blocks.0.resnets.0.time_emb_proj.bias': 'output_blocks.0.0.emb_layers.1.bias',
        'up_blocks.0.resnets.0.time_emb_proj.weight': 'output_blocks.0.0.emb_layers.1.weight',
        'up_blocks.0.resnets.1.conv1.bias': 'output_blocks.1.0.in_layers.2.bias',
        'up_blocks.0.resnets.1.conv1.weight': 'output_blocks.1.0.in_layers.2.weight',
        'up_blocks.0.resnets.1.conv2.bias': 'output_blocks.1.0.out_layers.3.bias',
        'up_blocks.0.resnets.1.conv2.weight': 'output_blocks.1.0.out_layers.3.weight',
        'up_blocks.0.resnets.1.conv_shortcut.bias': 'output_blocks.1.0.skip_connection.bias',
        'up_blocks.0.resnets.1.conv_shortcut.weight': 'output_blocks.1.0.skip_connection.weight',
        'up_blocks.0.resnets.1.norm1.bias': 'output_blocks.1.0.in_layers.0.bias',
        'up_blocks.0.resnets.1.norm1.weight': 'output_blocks.1.0.in_layers.0.weight',
        'up_blocks.0.resnets.1.norm2.bias': 'output_blocks.1.0.out_layers.0.bias',
        'up_blocks.0.resnets.1.norm2.weight': 'output_blocks.1.0.out_layers.0.weight',
        'up_blocks.0.resnets.1.time_emb_proj.bias': 'output_blocks.1.0.emb_layers.1.bias',
        'up_blocks.0.resnets.1.time_emb_proj.weight': 'output_blocks.1.0.emb_layers.1.weight',
        'up_blocks.0.resnets.2.conv1.bias': 'output_blocks.2.0.in_layers.2.bias',
        'up_blocks.0.resnets.2.conv1.weight': 'output_blocks.2.0.in_layers.2.weight',
        'up_blocks.0.resnets.2.conv2.bias': 'output_blocks.2.0.out_layers.3.bias',
        'up_blocks.0.resnets.2.conv2.weight': 'output_blocks.2.0.out_layers.3.weight',
        'up_blocks.0.resnets.2.conv_shortcut.bias': 'output_blocks.2.0.skip_connection.bias',
        'up_blocks.0.resnets.2.conv_shortcut.weight': 'output_blocks.2.0.skip_connection.weight',
        'up_blocks.0.resnets.2.norm1.bias': 'output_blocks.2.0.in_layers.0.bias',
        'up_blocks.0.resnets.2.norm1.weight': 'output_blocks.2.0.in_layers.0.weight',
        'up_blocks.0.resnets.2.norm2.bias': 'output_blocks.2.0.out_layers.0.bias',
        'up_blocks.0.resnets.2.norm2.weight': 'output_blocks.2.0.out_layers.0.weight',
        'up_blocks.0.resnets.2.time_emb_proj.bias': 'output_blocks.2.0.emb_layers.1.bias',
        'up_blocks.0.resnets.2.time_emb_proj.weight': 'output_blocks.2.0.emb_layers.1.weight',
        'up_blocks.0.upsamplers.0.conv.bias': 'output_blocks.2.2.conv.bias',
        'up_blocks.0.upsamplers.0.conv.weight': 'output_blocks.2.2.conv.weight',
        'up_blocks.1.attentions.0.norm.bias': 'output_blocks.3.1.norm.bias',
        'up_blocks.1.attentions.0.norm.weight': 'output_blocks.3.1.norm.weight',
        'up_blocks.1.attentions.0.proj_in.bias': 'output_blocks.3.1.proj_in.bias',
        'up_blocks.1.attentions.0.proj_in.weight': 'output_blocks.3.1.proj_in.weight',
        'up_blocks.1.attentions.0.proj_out.bias': 'output_blocks.3.1.proj_out.bias',
        'up_blocks.1.attentions.0.proj_out.weight': 'output_blocks.3.1.proj_out.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias': 'output_blocks.3.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight': 'output_blocks.3.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias': 'output_blocks.3.1.transformer_blocks.0.norm1.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight': 'output_blocks.3.1.transformer_blocks.0.norm1.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias': 'output_blocks.3.1.transformer_blocks.0.norm2.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight': 'output_blocks.3.1.transformer_blocks.0.norm2.weight',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias': 'output_blocks.3.1.transformer_blocks.0.norm3.bias',
        'up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight': 'output_blocks.3.1.transformer_blocks.0.norm3.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.3.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.3.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.3.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.3.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.3.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.3.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.3.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.3.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.3.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.bias': 'output_blocks.3.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight': 'output_blocks.3.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm1.bias': 'output_blocks.3.1.transformer_blocks.1.norm1.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm1.weight': 'output_blocks.3.1.transformer_blocks.1.norm1.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm2.bias': 'output_blocks.3.1.transformer_blocks.1.norm2.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm2.weight': 'output_blocks.3.1.transformer_blocks.1.norm2.weight',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm3.bias': 'output_blocks.3.1.transformer_blocks.1.norm3.bias',
        'up_blocks.1.attentions.0.transformer_blocks.1.norm3.weight': 'output_blocks.3.1.transformer_blocks.1.norm3.weight',
        'up_blocks.1.attentions.1.norm.bias': 'output_blocks.4.1.norm.bias',
        'up_blocks.1.attentions.1.norm.weight': 'output_blocks.4.1.norm.weight',
        'up_blocks.1.attentions.1.proj_in.bias': 'output_blocks.4.1.proj_in.bias',
        'up_blocks.1.attentions.1.proj_in.weight': 'output_blocks.4.1.proj_in.weight',
        'up_blocks.1.attentions.1.proj_out.bias': 'output_blocks.4.1.proj_out.bias',
        'up_blocks.1.attentions.1.proj_out.weight': 'output_blocks.4.1.proj_out.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias': 'output_blocks.4.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight': 'output_blocks.4.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias': 'output_blocks.4.1.transformer_blocks.0.norm1.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight': 'output_blocks.4.1.transformer_blocks.0.norm1.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias': 'output_blocks.4.1.transformer_blocks.0.norm2.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight': 'output_blocks.4.1.transformer_blocks.0.norm2.weight',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias': 'output_blocks.4.1.transformer_blocks.0.norm3.bias',
        'up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight': 'output_blocks.4.1.transformer_blocks.0.norm3.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.4.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.4.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.4.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.4.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.4.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.4.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.bias': 'output_blocks.4.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight': 'output_blocks.4.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm1.bias': 'output_blocks.4.1.transformer_blocks.1.norm1.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm1.weight': 'output_blocks.4.1.transformer_blocks.1.norm1.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm2.bias': 'output_blocks.4.1.transformer_blocks.1.norm2.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm2.weight': 'output_blocks.4.1.transformer_blocks.1.norm2.weight',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm3.bias': 'output_blocks.4.1.transformer_blocks.1.norm3.bias',
        'up_blocks.1.attentions.1.transformer_blocks.1.norm3.weight': 'output_blocks.4.1.transformer_blocks.1.norm3.weight',
        'up_blocks.1.attentions.2.norm.bias': 'output_blocks.5.1.norm.bias',
        'up_blocks.1.attentions.2.norm.weight': 'output_blocks.5.1.norm.weight',
        'up_blocks.1.attentions.2.proj_in.bias': 'output_blocks.5.1.proj_in.bias',
        'up_blocks.1.attentions.2.proj_in.weight': 'output_blocks.5.1.proj_in.weight',
        'up_blocks.1.attentions.2.proj_out.bias': 'output_blocks.5.1.proj_out.bias',
        'up_blocks.1.attentions.2.proj_out.weight': 'output_blocks.5.1.proj_out.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias': 'output_blocks.5.1.transformer_blocks.0.ff.net.2.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight': 'output_blocks.5.1.transformer_blocks.0.ff.net.2.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias': 'output_blocks.5.1.transformer_blocks.0.norm1.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight': 'output_blocks.5.1.transformer_blocks.0.norm1.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias': 'output_blocks.5.1.transformer_blocks.0.norm2.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight': 'output_blocks.5.1.transformer_blocks.0.norm2.weight',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias': 'output_blocks.5.1.transformer_blocks.0.norm3.bias',
        'up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight': 'output_blocks.5.1.transformer_blocks.0.norm3.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.5.1.transformer_blocks.1.attn1.to_k.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.5.1.transformer_blocks.1.attn1.to_q.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.5.1.transformer_blocks.1.attn1.to_v.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.5.1.transformer_blocks.1.attn2.to_k.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.5.1.transformer_blocks.1.attn2.to_q.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.5.1.transformer_blocks.1.attn2.to_v.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.bias': 'output_blocks.5.1.transformer_blocks.1.ff.net.2.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.ff.net.2.weight': 'output_blocks.5.1.transformer_blocks.1.ff.net.2.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm1.bias': 'output_blocks.5.1.transformer_blocks.1.norm1.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm1.weight': 'output_blocks.5.1.transformer_blocks.1.norm1.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm2.bias': 'output_blocks.5.1.transformer_blocks.1.norm2.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm2.weight': 'output_blocks.5.1.transformer_blocks.1.norm2.weight',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm3.bias': 'output_blocks.5.1.transformer_blocks.1.norm3.bias',
        'up_blocks.1.attentions.2.transformer_blocks.1.norm3.weight': 'output_blocks.5.1.transformer_blocks.1.norm3.weight',
        'up_blocks.1.resnets.0.conv1.bias': 'output_blocks.3.0.in_layers.2.bias',
        'up_blocks.1.resnets.0.conv1.weight': 'output_blocks.3.0.in_layers.2.weight',
        'up_blocks.1.resnets.0.conv2.bias': 'output_blocks.3.0.out_layers.3.bias',
        'up_blocks.1.resnets.0.conv2.weight': 'output_blocks.3.0.out_layers.3.weight',
        'up_blocks.1.resnets.0.conv_shortcut.bias': 'output_blocks.3.0.skip_connection.bias',
        'up_blocks.1.resnets.0.conv_shortcut.weight': 'output_blocks.3.0.skip_connection.weight',
        'up_blocks.1.resnets.0.norm1.bias': 'output_blocks.3.0.in_layers.0.bias',
        'up_blocks.1.resnets.0.norm1.weight': 'output_blocks.3.0.in_layers.0.weight',
        'up_blocks.1.resnets.0.norm2.bias': 'output_blocks.3.0.out_layers.0.bias',
        'up_blocks.1.resnets.0.norm2.weight': 'output_blocks.3.0.out_layers.0.weight',
        'up_blocks.1.resnets.0.time_emb_proj.bias': 'output_blocks.3.0.emb_layers.1.bias',
        'up_blocks.1.resnets.0.time_emb_proj.weight': 'output_blocks.3.0.emb_layers.1.weight',
        'up_blocks.1.resnets.1.conv1.bias': 'output_blocks.4.0.in_layers.2.bias',
        'up_blocks.1.resnets.1.conv1.weight': 'output_blocks.4.0.in_layers.2.weight',
        'up_blocks.1.resnets.1.conv2.bias': 'output_blocks.4.0.out_layers.3.bias',
        'up_blocks.1.resnets.1.conv2.weight': 'output_blocks.4.0.out_layers.3.weight',
        'up_blocks.1.resnets.1.conv_shortcut.bias': 'output_blocks.4.0.skip_connection.bias',
        'up_blocks.1.resnets.1.conv_shortcut.weight': 'output_blocks.4.0.skip_connection.weight',
        'up_blocks.1.resnets.1.norm1.bias': 'output_blocks.4.0.in_layers.0.bias',
        'up_blocks.1.resnets.1.norm1.weight': 'output_blocks.4.0.in_layers.0.weight',
        'up_blocks.1.resnets.1.norm2.bias': 'output_blocks.4.0.out_layers.0.bias',
        'up_blocks.1.resnets.1.norm2.weight': 'output_blocks.4.0.out_layers.0.weight',
        'up_blocks.1.resnets.1.time_emb_proj.bias': 'output_blocks.4.0.emb_layers.1.bias',
        'up_blocks.1.resnets.1.time_emb_proj.weight': 'output_blocks.4.0.emb_layers.1.weight',
        'up_blocks.1.resnets.2.conv1.bias': 'output_blocks.5.0.in_layers.2.bias',
        'up_blocks.1.resnets.2.conv1.weight': 'output_blocks.5.0.in_layers.2.weight',
        'up_blocks.1.resnets.2.conv2.bias': 'output_blocks.5.0.out_layers.3.bias',
        'up_blocks.1.resnets.2.conv2.weight': 'output_blocks.5.0.out_layers.3.weight',
        'up_blocks.1.resnets.2.conv_shortcut.bias': 'output_blocks.5.0.skip_connection.bias',
        'up_blocks.1.resnets.2.conv_shortcut.weight': 'output_blocks.5.0.skip_connection.weight',
        'up_blocks.1.resnets.2.norm1.bias': 'output_blocks.5.0.in_layers.0.bias',
        'up_blocks.1.resnets.2.norm1.weight': 'output_blocks.5.0.in_layers.0.weight',
        'up_blocks.1.resnets.2.norm2.bias': 'output_blocks.5.0.out_layers.0.bias',
        'up_blocks.1.resnets.2.norm2.weight': 'output_blocks.5.0.out_layers.0.weight',
        'up_blocks.1.resnets.2.time_emb_proj.bias': 'output_blocks.5.0.emb_layers.1.bias',
        'up_blocks.1.resnets.2.time_emb_proj.weight': 'output_blocks.5.0.emb_layers.1.weight',
        'up_blocks.1.upsamplers.0.conv.bias': 'output_blocks.5.2.conv.bias',
        'up_blocks.1.upsamplers.0.conv.weight': 'output_blocks.5.2.conv.weight',
        'up_blocks.2.resnets.0.conv1.bias': 'output_blocks.6.0.in_layers.2.bias',
        'up_blocks.2.resnets.0.conv1.weight': 'output_blocks.6.0.in_layers.2.weight',
        'up_blocks.2.resnets.0.conv2.bias': 'output_blocks.6.0.out_layers.3.bias',
        'up_blocks.2.resnets.0.conv2.weight': 'output_blocks.6.0.out_layers.3.weight',
        'up_blocks.2.resnets.0.conv_shortcut.bias': 'output_blocks.6.0.skip_connection.bias',
        'up_blocks.2.resnets.0.conv_shortcut.weight': 'output_blocks.6.0.skip_connection.weight',
        'up_blocks.2.resnets.0.norm1.bias': 'output_blocks.6.0.in_layers.0.bias',
        'up_blocks.2.resnets.0.norm1.weight': 'output_blocks.6.0.in_layers.0.weight',
        'up_blocks.2.resnets.0.norm2.bias': 'output_blocks.6.0.out_layers.0.bias',
        'up_blocks.2.resnets.0.norm2.weight': 'output_blocks.6.0.out_layers.0.weight',
        'up_blocks.2.resnets.0.time_emb_proj.bias': 'output_blocks.6.0.emb_layers.1.bias',
        'up_blocks.2.resnets.0.time_emb_proj.weight': 'output_blocks.6.0.emb_layers.1.weight',
        'up_blocks.2.resnets.1.conv1.bias': 'output_blocks.7.0.in_layers.2.bias',
        'up_blocks.2.resnets.1.conv1.weight': 'output_blocks.7.0.in_layers.2.weight',
        'up_blocks.2.resnets.1.conv2.bias': 'output_blocks.7.0.out_layers.3.bias',
        'up_blocks.2.resnets.1.conv2.weight': 'output_blocks.7.0.out_layers.3.weight',
        'up_blocks.2.resnets.1.conv_shortcut.bias': 'output_blocks.7.0.skip_connection.bias',
        'up_blocks.2.resnets.1.conv_shortcut.weight': 'output_blocks.7.0.skip_connection.weight',
        'up_blocks.2.resnets.1.norm1.bias': 'output_blocks.7.0.in_layers.0.bias',
        'up_blocks.2.resnets.1.norm1.weight': 'output_blocks.7.0.in_layers.0.weight',
        'up_blocks.2.resnets.1.norm2.bias': 'output_blocks.7.0.out_layers.0.bias',
        'up_blocks.2.resnets.1.norm2.weight': 'output_blocks.7.0.out_layers.0.weight',
        'up_blocks.2.resnets.1.time_emb_proj.bias': 'output_blocks.7.0.emb_layers.1.bias',
        'up_blocks.2.resnets.1.time_emb_proj.weight': 'output_blocks.7.0.emb_layers.1.weight',
        'up_blocks.2.resnets.2.conv1.bias': 'output_blocks.8.0.in_layers.2.bias',
        'up_blocks.2.resnets.2.conv1.weight': 'output_blocks.8.0.in_layers.2.weight',
        'up_blocks.2.resnets.2.conv2.bias': 'output_blocks.8.0.out_layers.3.bias',
        'up_blocks.2.resnets.2.conv2.weight': 'output_blocks.8.0.out_layers.3.weight',
        'up_blocks.2.resnets.2.conv_shortcut.bias': 'output_blocks.8.0.skip_connection.bias',
        'up_blocks.2.resnets.2.conv_shortcut.weight': 'output_blocks.8.0.skip_connection.weight',
        'up_blocks.2.resnets.2.norm1.bias': 'output_blocks.8.0.in_layers.0.bias',
        'up_blocks.2.resnets.2.norm1.weight': 'output_blocks.8.0.in_layers.0.weight',
        'up_blocks.2.resnets.2.norm2.bias': 'output_blocks.8.0.out_layers.0.bias',
        'up_blocks.2.resnets.2.norm2.weight': 'output_blocks.8.0.out_layers.0.weight',
        'up_blocks.2.resnets.2.time_emb_proj.bias': 'output_blocks.8.0.emb_layers.1.bias',
        'up_blocks.2.resnets.2.time_emb_proj.weight': 'output_blocks.8.0.emb_layers.1.weight'}

text2 = {'text_model.embeddings.position_embedding.weight': 'positional_embedding',
         'text_model.embeddings.token_embedding.weight': 'token_embedding.weight',
         'text_model.encoder.layers.0.layer_norm1.bias': 'transformer.resblocks.0.ln_1.bias',
         'text_model.encoder.layers.0.layer_norm1.weight': 'transformer.resblocks.0.ln_1.weight',
         'text_model.encoder.layers.0.layer_norm2.bias': 'transformer.resblocks.0.ln_2.bias',
         'text_model.encoder.layers.0.layer_norm2.weight': 'transformer.resblocks.0.ln_2.weight',
         'text_model.encoder.layers.0.mlp.fc1.bias': 'transformer.resblocks.0.mlp.c_fc.bias',
         'text_model.encoder.layers.0.mlp.fc1.weight': 'transformer.resblocks.0.mlp.c_fc.weight',
         'text_model.encoder.layers.0.mlp.fc2.bias': 'transformer.resblocks.0.mlp.c_proj.bias',
         'text_model.encoder.layers.0.mlp.fc2.weight': 'transformer.resblocks.0.mlp.c_proj.weight',
         'text_model.encoder.layers.0.self_attn.out_proj.bias': 'transformer.resblocks.0.attn.out_proj.bias',
         'text_model.encoder.layers.0.self_attn.out_proj.weight': 'transformer.resblocks.0.attn.out_proj.weight',
         'text_model.encoder.layers.1.layer_norm1.bias': 'transformer.resblocks.1.ln_1.bias',
         'text_model.encoder.layers.1.layer_norm1.weight': 'transformer.resblocks.1.ln_1.weight',
         'text_model.encoder.layers.1.layer_norm2.bias': 'transformer.resblocks.1.ln_2.bias',
         'text_model.encoder.layers.1.layer_norm2.weight': 'transformer.resblocks.1.ln_2.weight',
         'text_model.encoder.layers.1.mlp.fc1.bias': 'transformer.resblocks.1.mlp.c_fc.bias',
         'text_model.encoder.layers.1.mlp.fc1.weight': 'transformer.resblocks.1.mlp.c_fc.weight',
         'text_model.encoder.layers.1.mlp.fc2.bias': 'transformer.resblocks.1.mlp.c_proj.bias',
         'text_model.encoder.layers.1.mlp.fc2.weight': 'transformer.resblocks.1.mlp.c_proj.weight',
         'text_model.encoder.layers.1.self_attn.out_proj.bias': 'transformer.resblocks.1.attn.out_proj.bias',
         'text_model.encoder.layers.1.self_attn.out_proj.weight': 'transformer.resblocks.1.attn.out_proj.weight',
         'text_model.encoder.layers.10.layer_norm1.bias': 'transformer.resblocks.10.ln_1.bias',
         'text_model.encoder.layers.10.layer_norm1.weight': 'transformer.resblocks.10.ln_1.weight',
         'text_model.encoder.layers.10.layer_norm2.bias': 'transformer.resblocks.10.ln_2.bias',
         'text_model.encoder.layers.10.layer_norm2.weight': 'transformer.resblocks.10.ln_2.weight',
         'text_model.encoder.layers.10.mlp.fc1.bias': 'transformer.resblocks.10.mlp.c_fc.bias',
         'text_model.encoder.layers.10.mlp.fc1.weight': 'transformer.resblocks.10.mlp.c_fc.weight',
         'text_model.encoder.layers.10.mlp.fc2.bias': 'transformer.resblocks.10.mlp.c_proj.bias',
         'text_model.encoder.layers.10.mlp.fc2.weight': 'transformer.resblocks.10.mlp.c_proj.weight',
         'text_model.encoder.layers.10.self_attn.out_proj.bias': 'transformer.resblocks.10.attn.out_proj.bias',
         'text_model.encoder.layers.10.self_attn.out_proj.weight': 'transformer.resblocks.10.attn.out_proj.weight',
         'text_model.encoder.layers.11.layer_norm1.bias': 'transformer.resblocks.11.ln_1.bias',
         'text_model.encoder.layers.11.layer_norm1.weight': 'transformer.resblocks.11.ln_1.weight',
         'text_model.encoder.layers.11.layer_norm2.bias': 'transformer.resblocks.11.ln_2.bias',
         'text_model.encoder.layers.11.layer_norm2.weight': 'transformer.resblocks.11.ln_2.weight',
         'text_model.encoder.layers.11.mlp.fc1.bias': 'transformer.resblocks.11.mlp.c_fc.bias',
         'text_model.encoder.layers.11.mlp.fc1.weight': 'transformer.resblocks.11.mlp.c_fc.weight',
         'text_model.encoder.layers.11.mlp.fc2.bias': 'transformer.resblocks.11.mlp.c_proj.bias',
         'text_model.encoder.layers.11.mlp.fc2.weight': 'transformer.resblocks.11.mlp.c_proj.weight',
         'text_model.encoder.layers.11.self_attn.out_proj.bias': 'transformer.resblocks.11.attn.out_proj.bias',
         'text_model.encoder.layers.11.self_attn.out_proj.weight': 'transformer.resblocks.11.attn.out_proj.weight',
         'text_model.encoder.layers.12.layer_norm1.bias': 'transformer.resblocks.12.ln_1.bias',
         'text_model.encoder.layers.12.layer_norm1.weight': 'transformer.resblocks.12.ln_1.weight',
         'text_model.encoder.layers.12.layer_norm2.bias': 'transformer.resblocks.12.ln_2.bias',
         'text_model.encoder.layers.12.layer_norm2.weight': 'transformer.resblocks.12.ln_2.weight',
         'text_model.encoder.layers.12.mlp.fc1.bias': 'transformer.resblocks.12.mlp.c_fc.bias',
         'text_model.encoder.layers.12.mlp.fc1.weight': 'transformer.resblocks.12.mlp.c_fc.weight',
         'text_model.encoder.layers.12.mlp.fc2.bias': 'transformer.resblocks.12.mlp.c_proj.bias',
         'text_model.encoder.layers.12.mlp.fc2.weight': 'transformer.resblocks.12.mlp.c_proj.weight',
         'text_model.encoder.layers.12.self_attn.out_proj.bias': 'transformer.resblocks.12.attn.out_proj.bias',
         'text_model.encoder.layers.12.self_attn.out_proj.weight': 'transformer.resblocks.12.attn.out_proj.weight',
         'text_model.encoder.layers.13.layer_norm1.bias': 'transformer.resblocks.13.ln_1.bias',
         'text_model.encoder.layers.13.layer_norm1.weight': 'transformer.resblocks.13.ln_1.weight',
         'text_model.encoder.layers.13.layer_norm2.bias': 'transformer.resblocks.13.ln_2.bias',
         'text_model.encoder.layers.13.layer_norm2.weight': 'transformer.resblocks.13.ln_2.weight',
         'text_model.encoder.layers.13.mlp.fc1.bias': 'transformer.resblocks.13.mlp.c_fc.bias',
         'text_model.encoder.layers.13.mlp.fc1.weight': 'transformer.resblocks.13.mlp.c_fc.weight',
         'text_model.encoder.layers.13.mlp.fc2.bias': 'transformer.resblocks.13.mlp.c_proj.bias',
         'text_model.encoder.layers.13.mlp.fc2.weight': 'transformer.resblocks.13.mlp.c_proj.weight',
         'text_model.encoder.layers.13.self_attn.out_proj.bias': 'transformer.resblocks.13.attn.out_proj.bias',
         'text_model.encoder.layers.13.self_attn.out_proj.weight': 'transformer.resblocks.13.attn.out_proj.weight',
         'text_model.encoder.layers.14.layer_norm1.bias': 'transformer.resblocks.14.ln_1.bias',
         'text_model.encoder.layers.14.layer_norm1.weight': 'transformer.resblocks.14.ln_1.weight',
         'text_model.encoder.layers.14.layer_norm2.bias': 'transformer.resblocks.14.ln_2.bias',
         'text_model.encoder.layers.14.layer_norm2.weight': 'transformer.resblocks.14.ln_2.weight',
         'text_model.encoder.layers.14.mlp.fc1.bias': 'transformer.resblocks.14.mlp.c_fc.bias',
         'text_model.encoder.layers.14.mlp.fc1.weight': 'transformer.resblocks.14.mlp.c_fc.weight',
         'text_model.encoder.layers.14.mlp.fc2.bias': 'transformer.resblocks.14.mlp.c_proj.bias',
         'text_model.encoder.layers.14.mlp.fc2.weight': 'transformer.resblocks.14.mlp.c_proj.weight',
         'text_model.encoder.layers.14.self_attn.out_proj.bias': 'transformer.resblocks.14.attn.out_proj.bias',
         'text_model.encoder.layers.14.self_attn.out_proj.weight': 'transformer.resblocks.14.attn.out_proj.weight',
         'text_model.encoder.layers.15.layer_norm1.bias': 'transformer.resblocks.15.ln_1.bias',
         'text_model.encoder.layers.15.layer_norm1.weight': 'transformer.resblocks.15.ln_1.weight',
         'text_model.encoder.layers.15.layer_norm2.bias': 'transformer.resblocks.15.ln_2.bias',
         'text_model.encoder.layers.15.layer_norm2.weight': 'transformer.resblocks.15.ln_2.weight',
         'text_model.encoder.layers.15.mlp.fc1.bias': 'transformer.resblocks.15.mlp.c_fc.bias',
         'text_model.encoder.layers.15.mlp.fc1.weight': 'transformer.resblocks.15.mlp.c_fc.weight',
         'text_model.encoder.layers.15.mlp.fc2.bias': 'transformer.resblocks.15.mlp.c_proj.bias',
         'text_model.encoder.layers.15.mlp.fc2.weight': 'transformer.resblocks.15.mlp.c_proj.weight',
         'text_model.encoder.layers.15.self_attn.out_proj.bias': 'transformer.resblocks.15.attn.out_proj.bias',
         'text_model.encoder.layers.15.self_attn.out_proj.weight': 'transformer.resblocks.15.attn.out_proj.weight',
         'text_model.encoder.layers.16.layer_norm1.bias': 'transformer.resblocks.16.ln_1.bias',
         'text_model.encoder.layers.16.layer_norm1.weight': 'transformer.resblocks.16.ln_1.weight',
         'text_model.encoder.layers.16.layer_norm2.bias': 'transformer.resblocks.16.ln_2.bias',
         'text_model.encoder.layers.16.layer_norm2.weight': 'transformer.resblocks.16.ln_2.weight',
         'text_model.encoder.layers.16.mlp.fc1.bias': 'transformer.resblocks.16.mlp.c_fc.bias',
         'text_model.encoder.layers.16.mlp.fc1.weight': 'transformer.resblocks.16.mlp.c_fc.weight',
         'text_model.encoder.layers.16.mlp.fc2.bias': 'transformer.resblocks.16.mlp.c_proj.bias',
         'text_model.encoder.layers.16.mlp.fc2.weight': 'transformer.resblocks.16.mlp.c_proj.weight',
         'text_model.encoder.layers.16.self_attn.out_proj.bias': 'transformer.resblocks.16.attn.out_proj.bias',
         'text_model.encoder.layers.16.self_attn.out_proj.weight': 'transformer.resblocks.16.attn.out_proj.weight',
         'text_model.encoder.layers.17.layer_norm1.bias': 'transformer.resblocks.17.ln_1.bias',
         'text_model.encoder.layers.17.layer_norm1.weight': 'transformer.resblocks.17.ln_1.weight',
         'text_model.encoder.layers.17.layer_norm2.bias': 'transformer.resblocks.17.ln_2.bias',
         'text_model.encoder.layers.17.layer_norm2.weight': 'transformer.resblocks.17.ln_2.weight',
         'text_model.encoder.layers.17.mlp.fc1.bias': 'transformer.resblocks.17.mlp.c_fc.bias',
         'text_model.encoder.layers.17.mlp.fc1.weight': 'transformer.resblocks.17.mlp.c_fc.weight',
         'text_model.encoder.layers.17.mlp.fc2.bias': 'transformer.resblocks.17.mlp.c_proj.bias',
         'text_model.encoder.layers.17.mlp.fc2.weight': 'transformer.resblocks.17.mlp.c_proj.weight',
         'text_model.encoder.layers.17.self_attn.out_proj.bias': 'transformer.resblocks.17.attn.out_proj.bias',
         'text_model.encoder.layers.17.self_attn.out_proj.weight': 'transformer.resblocks.17.attn.out_proj.weight',
         'text_model.encoder.layers.18.layer_norm1.bias': 'transformer.resblocks.18.ln_1.bias',
         'text_model.encoder.layers.18.layer_norm1.weight': 'transformer.resblocks.18.ln_1.weight',
         'text_model.encoder.layers.18.layer_norm2.bias': 'transformer.resblocks.18.ln_2.bias',
         'text_model.encoder.layers.18.layer_norm2.weight': 'transformer.resblocks.18.ln_2.weight',
         'text_model.encoder.layers.18.mlp.fc1.bias': 'transformer.resblocks.18.mlp.c_fc.bias',
         'text_model.encoder.layers.18.mlp.fc1.weight': 'transformer.resblocks.18.mlp.c_fc.weight',
         'text_model.encoder.layers.18.mlp.fc2.bias': 'transformer.resblocks.18.mlp.c_proj.bias',
         'text_model.encoder.layers.18.mlp.fc2.weight': 'transformer.resblocks.18.mlp.c_proj.weight',
         'text_model.encoder.layers.18.self_attn.out_proj.bias': 'transformer.resblocks.18.attn.out_proj.bias',
         'text_model.encoder.layers.18.self_attn.out_proj.weight': 'transformer.resblocks.18.attn.out_proj.weight',
         'text_model.encoder.layers.19.layer_norm1.bias': 'transformer.resblocks.19.ln_1.bias',
         'text_model.encoder.layers.19.layer_norm1.weight': 'transformer.resblocks.19.ln_1.weight',
         'text_model.encoder.layers.19.layer_norm2.bias': 'transformer.resblocks.19.ln_2.bias',
         'text_model.encoder.layers.19.layer_norm2.weight': 'transformer.resblocks.19.ln_2.weight',
         'text_model.encoder.layers.19.mlp.fc1.bias': 'transformer.resblocks.19.mlp.c_fc.bias',
         'text_model.encoder.layers.19.mlp.fc1.weight': 'transformer.resblocks.19.mlp.c_fc.weight',
         'text_model.encoder.layers.19.mlp.fc2.bias': 'transformer.resblocks.19.mlp.c_proj.bias',
         'text_model.encoder.layers.19.mlp.fc2.weight': 'transformer.resblocks.19.mlp.c_proj.weight',
         'text_model.encoder.layers.19.self_attn.out_proj.bias': 'transformer.resblocks.19.attn.out_proj.bias',
         'text_model.encoder.layers.19.self_attn.out_proj.weight': 'transformer.resblocks.19.attn.out_proj.weight',
         'text_model.encoder.layers.2.layer_norm1.bias': 'transformer.resblocks.2.ln_1.bias',
         'text_model.encoder.layers.2.layer_norm1.weight': 'transformer.resblocks.2.ln_1.weight',
         'text_model.encoder.layers.2.layer_norm2.bias': 'transformer.resblocks.2.ln_2.bias',
         'text_model.encoder.layers.2.layer_norm2.weight': 'transformer.resblocks.2.ln_2.weight',
         'text_model.encoder.layers.2.mlp.fc1.bias': 'transformer.resblocks.2.mlp.c_fc.bias',
         'text_model.encoder.layers.2.mlp.fc1.weight': 'transformer.resblocks.2.mlp.c_fc.weight',
         'text_model.encoder.layers.2.mlp.fc2.bias': 'transformer.resblocks.2.mlp.c_proj.bias',
         'text_model.encoder.layers.2.mlp.fc2.weight': 'transformer.resblocks.2.mlp.c_proj.weight',
         'text_model.encoder.layers.2.self_attn.out_proj.bias': 'transformer.resblocks.2.attn.out_proj.bias',
         'text_model.encoder.layers.2.self_attn.out_proj.weight': 'transformer.resblocks.2.attn.out_proj.weight',
         'text_model.encoder.layers.20.layer_norm1.bias': 'transformer.resblocks.20.ln_1.bias',
         'text_model.encoder.layers.20.layer_norm1.weight': 'transformer.resblocks.20.ln_1.weight',
         'text_model.encoder.layers.20.layer_norm2.bias': 'transformer.resblocks.20.ln_2.bias',
         'text_model.encoder.layers.20.layer_norm2.weight': 'transformer.resblocks.20.ln_2.weight',
         'text_model.encoder.layers.20.mlp.fc1.bias': 'transformer.resblocks.20.mlp.c_fc.bias',
         'text_model.encoder.layers.20.mlp.fc1.weight': 'transformer.resblocks.20.mlp.c_fc.weight',
         'text_model.encoder.layers.20.mlp.fc2.bias': 'transformer.resblocks.20.mlp.c_proj.bias',
         'text_model.encoder.layers.20.mlp.fc2.weight': 'transformer.resblocks.20.mlp.c_proj.weight',
         'text_model.encoder.layers.20.self_attn.out_proj.bias': 'transformer.resblocks.20.attn.out_proj.bias',
         'text_model.encoder.layers.20.self_attn.out_proj.weight': 'transformer.resblocks.20.attn.out_proj.weight',
         'text_model.encoder.layers.21.layer_norm1.bias': 'transformer.resblocks.21.ln_1.bias',
         'text_model.encoder.layers.21.layer_norm1.weight': 'transformer.resblocks.21.ln_1.weight',
         'text_model.encoder.layers.21.layer_norm2.bias': 'transformer.resblocks.21.ln_2.bias',
         'text_model.encoder.layers.21.layer_norm2.weight': 'transformer.resblocks.21.ln_2.weight',
         'text_model.encoder.layers.21.mlp.fc1.bias': 'transformer.resblocks.21.mlp.c_fc.bias',
         'text_model.encoder.layers.21.mlp.fc1.weight': 'transformer.resblocks.21.mlp.c_fc.weight',
         'text_model.encoder.layers.21.mlp.fc2.bias': 'transformer.resblocks.21.mlp.c_proj.bias',
         'text_model.encoder.layers.21.mlp.fc2.weight': 'transformer.resblocks.21.mlp.c_proj.weight',
         'text_model.encoder.layers.21.self_attn.out_proj.bias': 'transformer.resblocks.21.attn.out_proj.bias',
         'text_model.encoder.layers.21.self_attn.out_proj.weight': 'transformer.resblocks.21.attn.out_proj.weight',
         'text_model.encoder.layers.22.layer_norm1.bias': 'transformer.resblocks.22.ln_1.bias',
         'text_model.encoder.layers.22.layer_norm1.weight': 'transformer.resblocks.22.ln_1.weight',
         'text_model.encoder.layers.22.layer_norm2.bias': 'transformer.resblocks.22.ln_2.bias',
         'text_model.encoder.layers.22.layer_norm2.weight': 'transformer.resblocks.22.ln_2.weight',
         'text_model.encoder.layers.22.mlp.fc1.bias': 'transformer.resblocks.22.mlp.c_fc.bias',
         'text_model.encoder.layers.22.mlp.fc1.weight': 'transformer.resblocks.22.mlp.c_fc.weight',
         'text_model.encoder.layers.22.mlp.fc2.bias': 'transformer.resblocks.22.mlp.c_proj.bias',
         'text_model.encoder.layers.22.mlp.fc2.weight': 'transformer.resblocks.22.mlp.c_proj.weight',
         'text_model.encoder.layers.22.self_attn.out_proj.bias': 'transformer.resblocks.22.attn.out_proj.bias',
         'text_model.encoder.layers.22.self_attn.out_proj.weight': 'transformer.resblocks.22.attn.out_proj.weight',
         'text_model.encoder.layers.23.layer_norm1.bias': 'transformer.resblocks.23.ln_1.bias',
         'text_model.encoder.layers.23.layer_norm1.weight': 'transformer.resblocks.23.ln_1.weight',
         'text_model.encoder.layers.23.layer_norm2.bias': 'transformer.resblocks.23.ln_2.bias',
         'text_model.encoder.layers.23.layer_norm2.weight': 'transformer.resblocks.23.ln_2.weight',
         'text_model.encoder.layers.23.mlp.fc1.bias': 'transformer.resblocks.23.mlp.c_fc.bias',
         'text_model.encoder.layers.23.mlp.fc1.weight': 'transformer.resblocks.23.mlp.c_fc.weight',
         'text_model.encoder.layers.23.mlp.fc2.bias': 'transformer.resblocks.23.mlp.c_proj.bias',
         'text_model.encoder.layers.23.mlp.fc2.weight': 'transformer.resblocks.23.mlp.c_proj.weight',
         'text_model.encoder.layers.23.self_attn.out_proj.bias': 'transformer.resblocks.23.attn.out_proj.bias',
         'text_model.encoder.layers.23.self_attn.out_proj.weight': 'transformer.resblocks.23.attn.out_proj.weight',
         'text_model.encoder.layers.24.layer_norm1.bias': 'transformer.resblocks.24.ln_1.bias',
         'text_model.encoder.layers.24.layer_norm1.weight': 'transformer.resblocks.24.ln_1.weight',
         'text_model.encoder.layers.24.layer_norm2.bias': 'transformer.resblocks.24.ln_2.bias',
         'text_model.encoder.layers.24.layer_norm2.weight': 'transformer.resblocks.24.ln_2.weight',
         'text_model.encoder.layers.24.mlp.fc1.bias': 'transformer.resblocks.24.mlp.c_fc.bias',
         'text_model.encoder.layers.24.mlp.fc1.weight': 'transformer.resblocks.24.mlp.c_fc.weight',
         'text_model.encoder.layers.24.mlp.fc2.bias': 'transformer.resblocks.24.mlp.c_proj.bias',
         'text_model.encoder.layers.24.mlp.fc2.weight': 'transformer.resblocks.24.mlp.c_proj.weight',
         'text_model.encoder.layers.24.self_attn.out_proj.bias': 'transformer.resblocks.24.attn.out_proj.bias',
         'text_model.encoder.layers.24.self_attn.out_proj.weight': 'transformer.resblocks.24.attn.out_proj.weight',
         'text_model.encoder.layers.25.layer_norm1.bias': 'transformer.resblocks.25.ln_1.bias',
         'text_model.encoder.layers.25.layer_norm1.weight': 'transformer.resblocks.25.ln_1.weight',
         'text_model.encoder.layers.25.layer_norm2.bias': 'transformer.resblocks.25.ln_2.bias',
         'text_model.encoder.layers.25.layer_norm2.weight': 'transformer.resblocks.25.ln_2.weight',
         'text_model.encoder.layers.25.mlp.fc1.bias': 'transformer.resblocks.25.mlp.c_fc.bias',
         'text_model.encoder.layers.25.mlp.fc1.weight': 'transformer.resblocks.25.mlp.c_fc.weight',
         'text_model.encoder.layers.25.mlp.fc2.bias': 'transformer.resblocks.25.mlp.c_proj.bias',
         'text_model.encoder.layers.25.mlp.fc2.weight': 'transformer.resblocks.25.mlp.c_proj.weight',
         'text_model.encoder.layers.25.self_attn.out_proj.bias': 'transformer.resblocks.25.attn.out_proj.bias',
         'text_model.encoder.layers.25.self_attn.out_proj.weight': 'transformer.resblocks.25.attn.out_proj.weight',
         'text_model.encoder.layers.26.layer_norm1.bias': 'transformer.resblocks.26.ln_1.bias',
         'text_model.encoder.layers.26.layer_norm1.weight': 'transformer.resblocks.26.ln_1.weight',
         'text_model.encoder.layers.26.layer_norm2.bias': 'transformer.resblocks.26.ln_2.bias',
         'text_model.encoder.layers.26.layer_norm2.weight': 'transformer.resblocks.26.ln_2.weight',
         'text_model.encoder.layers.26.mlp.fc1.bias': 'transformer.resblocks.26.mlp.c_fc.bias',
         'text_model.encoder.layers.26.mlp.fc1.weight': 'transformer.resblocks.26.mlp.c_fc.weight',
         'text_model.encoder.layers.26.mlp.fc2.bias': 'transformer.resblocks.26.mlp.c_proj.bias',
         'text_model.encoder.layers.26.mlp.fc2.weight': 'transformer.resblocks.26.mlp.c_proj.weight',
         'text_model.encoder.layers.26.self_attn.out_proj.bias': 'transformer.resblocks.26.attn.out_proj.bias',
         'text_model.encoder.layers.26.self_attn.out_proj.weight': 'transformer.resblocks.26.attn.out_proj.weight',
         'text_model.encoder.layers.27.layer_norm1.bias': 'transformer.resblocks.27.ln_1.bias',
         'text_model.encoder.layers.27.layer_norm1.weight': 'transformer.resblocks.27.ln_1.weight',
         'text_model.encoder.layers.27.layer_norm2.bias': 'transformer.resblocks.27.ln_2.bias',
         'text_model.encoder.layers.27.layer_norm2.weight': 'transformer.resblocks.27.ln_2.weight',
         'text_model.encoder.layers.27.mlp.fc1.bias': 'transformer.resblocks.27.mlp.c_fc.bias',
         'text_model.encoder.layers.27.mlp.fc1.weight': 'transformer.resblocks.27.mlp.c_fc.weight',
         'text_model.encoder.layers.27.mlp.fc2.bias': 'transformer.resblocks.27.mlp.c_proj.bias',
         'text_model.encoder.layers.27.mlp.fc2.weight': 'transformer.resblocks.27.mlp.c_proj.weight',
         'text_model.encoder.layers.27.self_attn.out_proj.bias': 'transformer.resblocks.27.attn.out_proj.bias',
         'text_model.encoder.layers.27.self_attn.out_proj.weight': 'transformer.resblocks.27.attn.out_proj.weight',
         'text_model.encoder.layers.28.layer_norm1.bias': 'transformer.resblocks.28.ln_1.bias',
         'text_model.encoder.layers.28.layer_norm1.weight': 'transformer.resblocks.28.ln_1.weight',
         'text_model.encoder.layers.28.layer_norm2.bias': 'transformer.resblocks.28.ln_2.bias',
         'text_model.encoder.layers.28.layer_norm2.weight': 'transformer.resblocks.28.ln_2.weight',
         'text_model.encoder.layers.28.mlp.fc1.bias': 'transformer.resblocks.28.mlp.c_fc.bias',
         'text_model.encoder.layers.28.mlp.fc1.weight': 'transformer.resblocks.28.mlp.c_fc.weight',
         'text_model.encoder.layers.28.mlp.fc2.bias': 'transformer.resblocks.28.mlp.c_proj.bias',
         'text_model.encoder.layers.28.mlp.fc2.weight': 'transformer.resblocks.28.mlp.c_proj.weight',
         'text_model.encoder.layers.28.self_attn.out_proj.bias': 'transformer.resblocks.28.attn.out_proj.bias',
         'text_model.encoder.layers.28.self_attn.out_proj.weight': 'transformer.resblocks.28.attn.out_proj.weight',
         'text_model.encoder.layers.29.layer_norm1.bias': 'transformer.resblocks.29.ln_1.bias',
         'text_model.encoder.layers.29.layer_norm1.weight': 'transformer.resblocks.29.ln_1.weight',
         'text_model.encoder.layers.29.layer_norm2.bias': 'transformer.resblocks.29.ln_2.bias',
         'text_model.encoder.layers.29.layer_norm2.weight': 'transformer.resblocks.29.ln_2.weight',
         'text_model.encoder.layers.29.mlp.fc1.bias': 'transformer.resblocks.29.mlp.c_fc.bias',
         'text_model.encoder.layers.29.mlp.fc1.weight': 'transformer.resblocks.29.mlp.c_fc.weight',
         'text_model.encoder.layers.29.mlp.fc2.bias': 'transformer.resblocks.29.mlp.c_proj.bias',
         'text_model.encoder.layers.29.mlp.fc2.weight': 'transformer.resblocks.29.mlp.c_proj.weight',
         'text_model.encoder.layers.29.self_attn.out_proj.bias': 'transformer.resblocks.29.attn.out_proj.bias',
         'text_model.encoder.layers.29.self_attn.out_proj.weight': 'transformer.resblocks.29.attn.out_proj.weight',
         'text_model.encoder.layers.3.layer_norm1.bias': 'transformer.resblocks.3.ln_1.bias',
         'text_model.encoder.layers.3.layer_norm1.weight': 'transformer.resblocks.3.ln_1.weight',
         'text_model.encoder.layers.3.layer_norm2.bias': 'transformer.resblocks.3.ln_2.bias',
         'text_model.encoder.layers.3.layer_norm2.weight': 'transformer.resblocks.3.ln_2.weight',
         'text_model.encoder.layers.3.mlp.fc1.bias': 'transformer.resblocks.3.mlp.c_fc.bias',
         'text_model.encoder.layers.3.mlp.fc1.weight': 'transformer.resblocks.3.mlp.c_fc.weight',
         'text_model.encoder.layers.3.mlp.fc2.bias': 'transformer.resblocks.3.mlp.c_proj.bias',
         'text_model.encoder.layers.3.mlp.fc2.weight': 'transformer.resblocks.3.mlp.c_proj.weight',
         'text_model.encoder.layers.3.self_attn.out_proj.bias': 'transformer.resblocks.3.attn.out_proj.bias',
         'text_model.encoder.layers.3.self_attn.out_proj.weight': 'transformer.resblocks.3.attn.out_proj.weight',
         'text_model.encoder.layers.30.layer_norm1.bias': 'transformer.resblocks.30.ln_1.bias',
         'text_model.encoder.layers.30.layer_norm1.weight': 'transformer.resblocks.30.ln_1.weight',
         'text_model.encoder.layers.30.layer_norm2.bias': 'transformer.resblocks.30.ln_2.bias',
         'text_model.encoder.layers.30.layer_norm2.weight': 'transformer.resblocks.30.ln_2.weight',
         'text_model.encoder.layers.30.mlp.fc1.bias': 'transformer.resblocks.30.mlp.c_fc.bias',
         'text_model.encoder.layers.30.mlp.fc1.weight': 'transformer.resblocks.30.mlp.c_fc.weight',
         'text_model.encoder.layers.30.mlp.fc2.bias': 'transformer.resblocks.30.mlp.c_proj.bias',
         'text_model.encoder.layers.30.mlp.fc2.weight': 'transformer.resblocks.30.mlp.c_proj.weight',
         'text_model.encoder.layers.30.self_attn.out_proj.bias': 'transformer.resblocks.30.attn.out_proj.bias',
         'text_model.encoder.layers.30.self_attn.out_proj.weight': 'transformer.resblocks.30.attn.out_proj.weight',
         'text_model.encoder.layers.31.layer_norm1.bias': 'transformer.resblocks.31.ln_1.bias',
         'text_model.encoder.layers.31.layer_norm1.weight': 'transformer.resblocks.31.ln_1.weight',
         'text_model.encoder.layers.31.layer_norm2.bias': 'transformer.resblocks.31.ln_2.bias',
         'text_model.encoder.layers.31.layer_norm2.weight': 'transformer.resblocks.31.ln_2.weight',
         'text_model.encoder.layers.31.mlp.fc1.bias': 'transformer.resblocks.31.mlp.c_fc.bias',
         'text_model.encoder.layers.31.mlp.fc1.weight': 'transformer.resblocks.31.mlp.c_fc.weight',
         'text_model.encoder.layers.31.mlp.fc2.bias': 'transformer.resblocks.31.mlp.c_proj.bias',
         'text_model.encoder.layers.31.mlp.fc2.weight': 'transformer.resblocks.31.mlp.c_proj.weight',
         'text_model.encoder.layers.31.self_attn.out_proj.bias': 'transformer.resblocks.31.attn.out_proj.bias',
         'text_model.encoder.layers.31.self_attn.out_proj.weight': 'transformer.resblocks.31.attn.out_proj.weight',
         'text_model.encoder.layers.4.layer_norm1.bias': 'transformer.resblocks.4.ln_1.bias',
         'text_model.encoder.layers.4.layer_norm1.weight': 'transformer.resblocks.4.ln_1.weight',
         'text_model.encoder.layers.4.layer_norm2.bias': 'transformer.resblocks.4.ln_2.bias',
         'text_model.encoder.layers.4.layer_norm2.weight': 'transformer.resblocks.4.ln_2.weight',
         'text_model.encoder.layers.4.mlp.fc1.bias': 'transformer.resblocks.4.mlp.c_fc.bias',
         'text_model.encoder.layers.4.mlp.fc1.weight': 'transformer.resblocks.4.mlp.c_fc.weight',
         'text_model.encoder.layers.4.mlp.fc2.bias': 'transformer.resblocks.4.mlp.c_proj.bias',
         'text_model.encoder.layers.4.mlp.fc2.weight': 'transformer.resblocks.4.mlp.c_proj.weight',
         'text_model.encoder.layers.4.self_attn.out_proj.bias': 'transformer.resblocks.4.attn.out_proj.bias',
         'text_model.encoder.layers.4.self_attn.out_proj.weight': 'transformer.resblocks.4.attn.out_proj.weight',
         'text_model.encoder.layers.5.layer_norm1.bias': 'transformer.resblocks.5.ln_1.bias',
         'text_model.encoder.layers.5.layer_norm1.weight': 'transformer.resblocks.5.ln_1.weight',
         'text_model.encoder.layers.5.layer_norm2.bias': 'transformer.resblocks.5.ln_2.bias',
         'text_model.encoder.layers.5.layer_norm2.weight': 'transformer.resblocks.5.ln_2.weight',
         'text_model.encoder.layers.5.mlp.fc1.bias': 'transformer.resblocks.5.mlp.c_fc.bias',
         'text_model.encoder.layers.5.mlp.fc1.weight': 'transformer.resblocks.5.mlp.c_fc.weight',
         'text_model.encoder.layers.5.mlp.fc2.bias': 'transformer.resblocks.5.mlp.c_proj.bias',
         'text_model.encoder.layers.5.mlp.fc2.weight': 'transformer.resblocks.5.mlp.c_proj.weight',
         'text_model.encoder.layers.5.self_attn.out_proj.bias': 'transformer.resblocks.5.attn.out_proj.bias',
         'text_model.encoder.layers.5.self_attn.out_proj.weight': 'transformer.resblocks.5.attn.out_proj.weight',
         'text_model.encoder.layers.6.layer_norm1.bias': 'transformer.resblocks.6.ln_1.bias',
         'text_model.encoder.layers.6.layer_norm1.weight': 'transformer.resblocks.6.ln_1.weight',
         'text_model.encoder.layers.6.layer_norm2.bias': 'transformer.resblocks.6.ln_2.bias',
         'text_model.encoder.layers.6.layer_norm2.weight': 'transformer.resblocks.6.ln_2.weight',
         'text_model.encoder.layers.6.mlp.fc1.bias': 'transformer.resblocks.6.mlp.c_fc.bias',
         'text_model.encoder.layers.6.mlp.fc1.weight': 'transformer.resblocks.6.mlp.c_fc.weight',
         'text_model.encoder.layers.6.mlp.fc2.bias': 'transformer.resblocks.6.mlp.c_proj.bias',
         'text_model.encoder.layers.6.mlp.fc2.weight': 'transformer.resblocks.6.mlp.c_proj.weight',
         'text_model.encoder.layers.6.self_attn.out_proj.bias': 'transformer.resblocks.6.attn.out_proj.bias',
         'text_model.encoder.layers.6.self_attn.out_proj.weight': 'transformer.resblocks.6.attn.out_proj.weight',
         'text_model.encoder.layers.7.layer_norm1.bias': 'transformer.resblocks.7.ln_1.bias',
         'text_model.encoder.layers.7.layer_norm1.weight': 'transformer.resblocks.7.ln_1.weight',
         'text_model.encoder.layers.7.layer_norm2.bias': 'transformer.resblocks.7.ln_2.bias',
         'text_model.encoder.layers.7.layer_norm2.weight': 'transformer.resblocks.7.ln_2.weight',
         'text_model.encoder.layers.7.mlp.fc1.bias': 'transformer.resblocks.7.mlp.c_fc.bias',
         'text_model.encoder.layers.7.mlp.fc1.weight': 'transformer.resblocks.7.mlp.c_fc.weight',
         'text_model.encoder.layers.7.mlp.fc2.bias': 'transformer.resblocks.7.mlp.c_proj.bias',
         'text_model.encoder.layers.7.mlp.fc2.weight': 'transformer.resblocks.7.mlp.c_proj.weight',
         'text_model.encoder.layers.7.self_attn.out_proj.bias': 'transformer.resblocks.7.attn.out_proj.bias',
         'text_model.encoder.layers.7.self_attn.out_proj.weight': 'transformer.resblocks.7.attn.out_proj.weight',
         'text_model.encoder.layers.8.layer_norm1.bias': 'transformer.resblocks.8.ln_1.bias',
         'text_model.encoder.layers.8.layer_norm1.weight': 'transformer.resblocks.8.ln_1.weight',
         'text_model.encoder.layers.8.layer_norm2.bias': 'transformer.resblocks.8.ln_2.bias',
         'text_model.encoder.layers.8.layer_norm2.weight': 'transformer.resblocks.8.ln_2.weight',
         'text_model.encoder.layers.8.mlp.fc1.bias': 'transformer.resblocks.8.mlp.c_fc.bias',
         'text_model.encoder.layers.8.mlp.fc1.weight': 'transformer.resblocks.8.mlp.c_fc.weight',
         'text_model.encoder.layers.8.mlp.fc2.bias': 'transformer.resblocks.8.mlp.c_proj.bias',
         'text_model.encoder.layers.8.mlp.fc2.weight': 'transformer.resblocks.8.mlp.c_proj.weight',
         'text_model.encoder.layers.8.self_attn.out_proj.bias': 'transformer.resblocks.8.attn.out_proj.bias',
         'text_model.encoder.layers.8.self_attn.out_proj.weight': 'transformer.resblocks.8.attn.out_proj.weight',
         'text_model.encoder.layers.9.layer_norm1.bias': 'transformer.resblocks.9.ln_1.bias',
         'text_model.encoder.layers.9.layer_norm1.weight': 'transformer.resblocks.9.ln_1.weight',
         'text_model.encoder.layers.9.layer_norm2.bias': 'transformer.resblocks.9.ln_2.bias',
         'text_model.encoder.layers.9.layer_norm2.weight': 'transformer.resblocks.9.ln_2.weight',
         'text_model.encoder.layers.9.mlp.fc1.bias': 'transformer.resblocks.9.mlp.c_fc.bias',
         'text_model.encoder.layers.9.mlp.fc1.weight': 'transformer.resblocks.9.mlp.c_fc.weight',
         'text_model.encoder.layers.9.mlp.fc2.bias': 'transformer.resblocks.9.mlp.c_proj.bias',
         'text_model.encoder.layers.9.mlp.fc2.weight': 'transformer.resblocks.9.mlp.c_proj.weight',
         'text_model.encoder.layers.9.self_attn.out_proj.bias': 'transformer.resblocks.9.attn.out_proj.bias',
         'text_model.encoder.layers.9.self_attn.out_proj.weight': 'transformer.resblocks.9.attn.out_proj.weight',
         'text_model.final_layer_norm.bias': 'ln_final.bias', 'text_model.final_layer_norm.weight': 'ln_final.weight',
         'text_projection.weight': 'text_projection.weight',
         'text_model.encoder.layers.0.self_attn.q_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
         'text_model.encoder.layers.0.self_attn.k_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
         'text_model.encoder.layers.0.self_attn.v_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
         'text_model.encoder.layers.1.self_attn.q_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
         'text_model.encoder.layers.1.self_attn.k_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
         'text_model.encoder.layers.1.self_attn.v_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
         'text_model.encoder.layers.10.self_attn.q_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
         'text_model.encoder.layers.10.self_attn.k_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
         'text_model.encoder.layers.10.self_attn.v_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
         'text_model.encoder.layers.11.self_attn.q_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
         'text_model.encoder.layers.11.self_attn.k_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
         'text_model.encoder.layers.11.self_attn.v_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
         'text_model.encoder.layers.12.self_attn.q_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
         'text_model.encoder.layers.12.self_attn.k_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
         'text_model.encoder.layers.12.self_attn.v_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
         'text_model.encoder.layers.13.self_attn.q_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
         'text_model.encoder.layers.13.self_attn.k_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
         'text_model.encoder.layers.13.self_attn.v_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
         'text_model.encoder.layers.14.self_attn.q_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
         'text_model.encoder.layers.14.self_attn.k_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
         'text_model.encoder.layers.14.self_attn.v_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
         'text_model.encoder.layers.15.self_attn.q_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
         'text_model.encoder.layers.15.self_attn.k_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
         'text_model.encoder.layers.15.self_attn.v_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
         'text_model.encoder.layers.16.self_attn.q_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
         'text_model.encoder.layers.16.self_attn.k_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
         'text_model.encoder.layers.16.self_attn.v_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
         'text_model.encoder.layers.17.self_attn.q_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
         'text_model.encoder.layers.17.self_attn.k_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
         'text_model.encoder.layers.17.self_attn.v_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
         'text_model.encoder.layers.18.self_attn.q_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
         'text_model.encoder.layers.18.self_attn.k_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
         'text_model.encoder.layers.18.self_attn.v_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
         'text_model.encoder.layers.19.self_attn.q_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
         'text_model.encoder.layers.19.self_attn.k_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
         'text_model.encoder.layers.19.self_attn.v_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
         'text_model.encoder.layers.2.self_attn.q_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
         'text_model.encoder.layers.2.self_attn.k_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
         'text_model.encoder.layers.2.self_attn.v_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
         'text_model.encoder.layers.20.self_attn.q_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
         'text_model.encoder.layers.20.self_attn.k_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
         'text_model.encoder.layers.20.self_attn.v_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
         'text_model.encoder.layers.21.self_attn.q_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
         'text_model.encoder.layers.21.self_attn.k_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
         'text_model.encoder.layers.21.self_attn.v_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
         'text_model.encoder.layers.22.self_attn.q_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
         'text_model.encoder.layers.22.self_attn.k_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
         'text_model.encoder.layers.22.self_attn.v_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
         'text_model.encoder.layers.23.self_attn.q_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
         'text_model.encoder.layers.23.self_attn.k_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
         'text_model.encoder.layers.23.self_attn.v_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
         'text_model.encoder.layers.24.self_attn.q_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
         'text_model.encoder.layers.24.self_attn.k_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
         'text_model.encoder.layers.24.self_attn.v_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
         'text_model.encoder.layers.25.self_attn.q_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
         'text_model.encoder.layers.25.self_attn.k_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
         'text_model.encoder.layers.25.self_attn.v_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
         'text_model.encoder.layers.26.self_attn.q_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
         'text_model.encoder.layers.26.self_attn.k_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
         'text_model.encoder.layers.26.self_attn.v_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
         'text_model.encoder.layers.27.self_attn.q_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
         'text_model.encoder.layers.27.self_attn.k_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
         'text_model.encoder.layers.27.self_attn.v_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
         'text_model.encoder.layers.28.self_attn.q_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
         'text_model.encoder.layers.28.self_attn.k_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
         'text_model.encoder.layers.28.self_attn.v_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
         'text_model.encoder.layers.29.self_attn.q_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
         'text_model.encoder.layers.29.self_attn.k_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
         'text_model.encoder.layers.29.self_attn.v_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
         'text_model.encoder.layers.3.self_attn.q_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
         'text_model.encoder.layers.3.self_attn.k_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
         'text_model.encoder.layers.3.self_attn.v_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
         'text_model.encoder.layers.30.self_attn.q_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
         'text_model.encoder.layers.30.self_attn.k_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
         'text_model.encoder.layers.30.self_attn.v_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
         'text_model.encoder.layers.31.self_attn.q_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
         'text_model.encoder.layers.31.self_attn.k_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
         'text_model.encoder.layers.31.self_attn.v_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
         'text_model.encoder.layers.4.self_attn.q_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
         'text_model.encoder.layers.4.self_attn.k_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
         'text_model.encoder.layers.4.self_attn.v_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
         'text_model.encoder.layers.5.self_attn.q_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
         'text_model.encoder.layers.5.self_attn.k_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
         'text_model.encoder.layers.5.self_attn.v_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
         'text_model.encoder.layers.6.self_attn.q_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
         'text_model.encoder.layers.6.self_attn.k_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
         'text_model.encoder.layers.6.self_attn.v_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
         'text_model.encoder.layers.7.self_attn.q_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
         'text_model.encoder.layers.7.self_attn.k_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
         'text_model.encoder.layers.7.self_attn.v_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
         'text_model.encoder.layers.8.self_attn.q_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
         'text_model.encoder.layers.8.self_attn.k_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
         'text_model.encoder.layers.8.self_attn.v_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
         'text_model.encoder.layers.9.self_attn.q_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
         'text_model.encoder.layers.9.self_attn.k_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
         'text_model.encoder.layers.9.self_attn.v_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
         'text_model.encoder.layers.0.self_attn.q_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
         'text_model.encoder.layers.0.self_attn.k_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
         'text_model.encoder.layers.0.self_attn.v_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
         'text_model.encoder.layers.1.self_attn.q_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
         'text_model.encoder.layers.1.self_attn.k_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
         'text_model.encoder.layers.1.self_attn.v_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
         'text_model.encoder.layers.10.self_attn.q_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
         'text_model.encoder.layers.10.self_attn.k_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
         'text_model.encoder.layers.10.self_attn.v_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
         'text_model.encoder.layers.11.self_attn.q_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
         'text_model.encoder.layers.11.self_attn.k_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
         'text_model.encoder.layers.11.self_attn.v_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
         'text_model.encoder.layers.12.self_attn.q_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
         'text_model.encoder.layers.12.self_attn.k_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
         'text_model.encoder.layers.12.self_attn.v_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
         'text_model.encoder.layers.13.self_attn.q_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
         'text_model.encoder.layers.13.self_attn.k_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
         'text_model.encoder.layers.13.self_attn.v_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
         'text_model.encoder.layers.14.self_attn.q_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
         'text_model.encoder.layers.14.self_attn.k_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
         'text_model.encoder.layers.14.self_attn.v_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
         'text_model.encoder.layers.15.self_attn.q_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
         'text_model.encoder.layers.15.self_attn.k_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
         'text_model.encoder.layers.15.self_attn.v_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
         'text_model.encoder.layers.16.self_attn.q_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
         'text_model.encoder.layers.16.self_attn.k_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
         'text_model.encoder.layers.16.self_attn.v_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
         'text_model.encoder.layers.17.self_attn.q_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
         'text_model.encoder.layers.17.self_attn.k_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
         'text_model.encoder.layers.17.self_attn.v_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
         'text_model.encoder.layers.18.self_attn.q_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
         'text_model.encoder.layers.18.self_attn.k_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
         'text_model.encoder.layers.18.self_attn.v_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
         'text_model.encoder.layers.19.self_attn.q_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
         'text_model.encoder.layers.19.self_attn.k_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
         'text_model.encoder.layers.19.self_attn.v_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
         'text_model.encoder.layers.2.self_attn.q_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
         'text_model.encoder.layers.2.self_attn.k_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
         'text_model.encoder.layers.2.self_attn.v_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
         'text_model.encoder.layers.20.self_attn.q_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
         'text_model.encoder.layers.20.self_attn.k_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
         'text_model.encoder.layers.20.self_attn.v_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
         'text_model.encoder.layers.21.self_attn.q_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
         'text_model.encoder.layers.21.self_attn.k_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
         'text_model.encoder.layers.21.self_attn.v_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
         'text_model.encoder.layers.22.self_attn.q_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
         'text_model.encoder.layers.22.self_attn.k_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
         'text_model.encoder.layers.22.self_attn.v_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
         'text_model.encoder.layers.23.self_attn.q_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
         'text_model.encoder.layers.23.self_attn.k_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
         'text_model.encoder.layers.23.self_attn.v_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
         'text_model.encoder.layers.24.self_attn.q_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
         'text_model.encoder.layers.24.self_attn.k_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
         'text_model.encoder.layers.24.self_attn.v_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
         'text_model.encoder.layers.25.self_attn.q_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
         'text_model.encoder.layers.25.self_attn.k_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
         'text_model.encoder.layers.25.self_attn.v_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
         'text_model.encoder.layers.26.self_attn.q_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
         'text_model.encoder.layers.26.self_attn.k_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
         'text_model.encoder.layers.26.self_attn.v_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
         'text_model.encoder.layers.27.self_attn.q_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
         'text_model.encoder.layers.27.self_attn.k_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
         'text_model.encoder.layers.27.self_attn.v_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
         'text_model.encoder.layers.28.self_attn.q_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
         'text_model.encoder.layers.28.self_attn.k_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
         'text_model.encoder.layers.28.self_attn.v_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
         'text_model.encoder.layers.29.self_attn.q_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
         'text_model.encoder.layers.29.self_attn.k_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
         'text_model.encoder.layers.29.self_attn.v_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
         'text_model.encoder.layers.3.self_attn.q_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
         'text_model.encoder.layers.3.self_attn.k_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
         'text_model.encoder.layers.3.self_attn.v_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
         'text_model.encoder.layers.30.self_attn.q_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
         'text_model.encoder.layers.30.self_attn.k_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
         'text_model.encoder.layers.30.self_attn.v_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
         'text_model.encoder.layers.31.self_attn.q_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
         'text_model.encoder.layers.31.self_attn.k_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
         'text_model.encoder.layers.31.self_attn.v_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
         'text_model.encoder.layers.4.self_attn.q_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
         'text_model.encoder.layers.4.self_attn.k_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
         'text_model.encoder.layers.4.self_attn.v_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
         'text_model.encoder.layers.5.self_attn.q_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
         'text_model.encoder.layers.5.self_attn.k_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
         'text_model.encoder.layers.5.self_attn.v_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
         'text_model.encoder.layers.6.self_attn.q_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
         'text_model.encoder.layers.6.self_attn.k_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
         'text_model.encoder.layers.6.self_attn.v_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
         'text_model.encoder.layers.7.self_attn.q_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
         'text_model.encoder.layers.7.self_attn.k_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
         'text_model.encoder.layers.7.self_attn.v_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
         'text_model.encoder.layers.8.self_attn.q_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
         'text_model.encoder.layers.8.self_attn.k_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
         'text_model.encoder.layers.8.self_attn.v_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
         'text_model.encoder.layers.9.self_attn.q_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias',
         'text_model.encoder.layers.9.self_attn.k_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias',
         'text_model.encoder.layers.9.self_attn.v_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias'}

text1 = ['text_model.embeddings.position_embedding.weight', 'text_model.embeddings.token_embedding.weight',
         'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.0.layer_norm1.weight',
         'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm2.weight',
         'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.0.mlp.fc1.weight',
         'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.0.mlp.fc2.weight',
         'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.0.self_attn.k_proj.weight',
         'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight',
         'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight',
         'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.0.self_attn.v_proj.weight',
         'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.1.layer_norm1.weight',
         'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.1.layer_norm2.weight',
         'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.1.mlp.fc1.weight',
         'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.1.mlp.fc2.weight',
         'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.weight',
         'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.1.self_attn.out_proj.weight',
         'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.q_proj.weight',
         'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight',
         'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.10.layer_norm1.weight',
         'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.10.layer_norm2.weight',
         'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.10.mlp.fc1.weight',
         'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.10.mlp.fc2.weight',
         'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.k_proj.weight',
         'text_model.encoder.layers.10.self_attn.out_proj.bias',
         'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.10.self_attn.q_proj.bias',
         'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias',
         'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias',
         'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.11.layer_norm2.bias',
         'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias',
         'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc2.bias',
         'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias',
         'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias',
         'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.11.self_attn.q_proj.bias',
         'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias',
         'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.2.layer_norm1.bias',
         'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.2.layer_norm2.bias',
         'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc1.bias',
         'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.2.mlp.fc2.bias',
         'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.k_proj.bias',
         'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias',
         'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias',
         'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.bias',
         'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm1.bias',
         'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.3.layer_norm2.bias',
         'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.3.mlp.fc1.bias',
         'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias',
         'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias',
         'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.3.self_attn.out_proj.bias',
         'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.bias',
         'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias',
         'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.4.layer_norm1.bias',
         'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.4.layer_norm2.bias',
         'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.4.mlp.fc1.bias',
         'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.4.mlp.fc2.bias',
         'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.4.self_attn.k_proj.bias',
         'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.out_proj.bias',
         'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias',
         'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.v_proj.bias',
         'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.5.layer_norm1.bias',
         'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.5.layer_norm2.bias',
         'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.5.mlp.fc1.bias',
         'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.5.mlp.fc2.bias',
         'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.5.self_attn.k_proj.bias',
         'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.out_proj.bias',
         'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.bias',
         'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.5.self_attn.v_proj.bias',
         'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.6.layer_norm1.bias',
         'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.6.layer_norm2.bias',
         'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.6.mlp.fc1.bias',
         'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc2.bias',
         'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.6.self_attn.k_proj.bias',
         'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.6.self_attn.out_proj.bias',
         'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.bias',
         'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.6.self_attn.v_proj.bias',
         'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.7.layer_norm1.bias',
         'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.7.layer_norm2.bias',
         'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.7.mlp.fc1.bias',
         'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.7.mlp.fc2.bias',
         'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.7.self_attn.k_proj.bias',
         'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.7.self_attn.out_proj.bias',
         'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.7.self_attn.q_proj.bias',
         'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.7.self_attn.v_proj.bias',
         'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.8.layer_norm1.bias',
         'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.8.layer_norm2.bias',
         'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.8.mlp.fc1.bias',
         'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.8.mlp.fc2.bias',
         'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.k_proj.bias',
         'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias',
         'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias',
         'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias',
         'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.9.layer_norm1.bias',
         'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.9.layer_norm2.bias',
         'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.9.mlp.fc1.bias',
         'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.9.mlp.fc2.bias',
         'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.k_proj.bias',
         'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.bias',
         'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.q_proj.bias',
         'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias',
         'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.final_layer_norm.bias',
         'text_model.final_layer_norm.weight']

origin_text2 = ['positional_embedding', 'token_embedding.weight', 'transformer.resblocks.0.ln_1.bias',
                'transformer.resblocks.0.ln_1.weight', 'transformer.resblocks.0.ln_2.bias',
                'transformer.resblocks.0.ln_2.weight', 'transformer.resblocks.0.mlp.c_fc.bias',
                'transformer.resblocks.0.mlp.c_fc.weight', 'transformer.resblocks.0.mlp.c_proj.bias',
                'transformer.resblocks.0.mlp.c_proj.weight', 'transformer.resblocks.0.attn.out_proj.bias',
                'transformer.resblocks.0.attn.out_proj.weight', 'transformer.resblocks.1.ln_1.bias',
                'transformer.resblocks.1.ln_1.weight', 'transformer.resblocks.1.ln_2.bias',
                'transformer.resblocks.1.ln_2.weight', 'transformer.resblocks.1.mlp.c_fc.bias',
                'transformer.resblocks.1.mlp.c_fc.weight', 'transformer.resblocks.1.mlp.c_proj.bias',
                'transformer.resblocks.1.mlp.c_proj.weight', 'transformer.resblocks.1.attn.out_proj.bias',
                'transformer.resblocks.1.attn.out_proj.weight', 'transformer.resblocks.10.ln_1.bias',
                'transformer.resblocks.10.ln_1.weight', 'transformer.resblocks.10.ln_2.bias',
                'transformer.resblocks.10.ln_2.weight', 'transformer.resblocks.10.mlp.c_fc.bias',
                'transformer.resblocks.10.mlp.c_fc.weight', 'transformer.resblocks.10.mlp.c_proj.bias',
                'transformer.resblocks.10.mlp.c_proj.weight', 'transformer.resblocks.10.attn.out_proj.bias',
                'transformer.resblocks.10.attn.out_proj.weight', 'transformer.resblocks.11.ln_1.bias',
                'transformer.resblocks.11.ln_1.weight', 'transformer.resblocks.11.ln_2.bias',
                'transformer.resblocks.11.ln_2.weight', 'transformer.resblocks.11.mlp.c_fc.bias',
                'transformer.resblocks.11.mlp.c_fc.weight', 'transformer.resblocks.11.mlp.c_proj.bias',
                'transformer.resblocks.11.mlp.c_proj.weight', 'transformer.resblocks.11.attn.out_proj.bias',
                'transformer.resblocks.11.attn.out_proj.weight', 'transformer.resblocks.12.ln_1.bias',
                'transformer.resblocks.12.ln_1.weight', 'transformer.resblocks.12.ln_2.bias',
                'transformer.resblocks.12.ln_2.weight', 'transformer.resblocks.12.mlp.c_fc.bias',
                'transformer.resblocks.12.mlp.c_fc.weight', 'transformer.resblocks.12.mlp.c_proj.bias',
                'transformer.resblocks.12.mlp.c_proj.weight', 'transformer.resblocks.12.attn.out_proj.bias',
                'transformer.resblocks.12.attn.out_proj.weight', 'transformer.resblocks.13.ln_1.bias',
                'transformer.resblocks.13.ln_1.weight', 'transformer.resblocks.13.ln_2.bias',
                'transformer.resblocks.13.ln_2.weight', 'transformer.resblocks.13.mlp.c_fc.bias',
                'transformer.resblocks.13.mlp.c_fc.weight', 'transformer.resblocks.13.mlp.c_proj.bias',
                'transformer.resblocks.13.mlp.c_proj.weight', 'transformer.resblocks.13.attn.out_proj.bias',
                'transformer.resblocks.13.attn.out_proj.weight', 'transformer.resblocks.14.ln_1.bias',
                'transformer.resblocks.14.ln_1.weight', 'transformer.resblocks.14.ln_2.bias',
                'transformer.resblocks.14.ln_2.weight', 'transformer.resblocks.14.mlp.c_fc.bias',
                'transformer.resblocks.14.mlp.c_fc.weight', 'transformer.resblocks.14.mlp.c_proj.bias',
                'transformer.resblocks.14.mlp.c_proj.weight', 'transformer.resblocks.14.attn.out_proj.bias',
                'transformer.resblocks.14.attn.out_proj.weight', 'transformer.resblocks.15.ln_1.bias',
                'transformer.resblocks.15.ln_1.weight', 'transformer.resblocks.15.ln_2.bias',
                'transformer.resblocks.15.ln_2.weight', 'transformer.resblocks.15.mlp.c_fc.bias',
                'transformer.resblocks.15.mlp.c_fc.weight', 'transformer.resblocks.15.mlp.c_proj.bias',
                'transformer.resblocks.15.mlp.c_proj.weight', 'transformer.resblocks.15.attn.out_proj.bias',
                'transformer.resblocks.15.attn.out_proj.weight', 'transformer.resblocks.16.ln_1.bias',
                'transformer.resblocks.16.ln_1.weight', 'transformer.resblocks.16.ln_2.bias',
                'transformer.resblocks.16.ln_2.weight', 'transformer.resblocks.16.mlp.c_fc.bias',
                'transformer.resblocks.16.mlp.c_fc.weight', 'transformer.resblocks.16.mlp.c_proj.bias',
                'transformer.resblocks.16.mlp.c_proj.weight', 'transformer.resblocks.16.attn.out_proj.bias',
                'transformer.resblocks.16.attn.out_proj.weight', 'transformer.resblocks.17.ln_1.bias',
                'transformer.resblocks.17.ln_1.weight', 'transformer.resblocks.17.ln_2.bias',
                'transformer.resblocks.17.ln_2.weight', 'transformer.resblocks.17.mlp.c_fc.bias',
                'transformer.resblocks.17.mlp.c_fc.weight', 'transformer.resblocks.17.mlp.c_proj.bias',
                'transformer.resblocks.17.mlp.c_proj.weight', 'transformer.resblocks.17.attn.out_proj.bias',
                'transformer.resblocks.17.attn.out_proj.weight', 'transformer.resblocks.18.ln_1.bias',
                'transformer.resblocks.18.ln_1.weight', 'transformer.resblocks.18.ln_2.bias',
                'transformer.resblocks.18.ln_2.weight', 'transformer.resblocks.18.mlp.c_fc.bias',
                'transformer.resblocks.18.mlp.c_fc.weight', 'transformer.resblocks.18.mlp.c_proj.bias',
                'transformer.resblocks.18.mlp.c_proj.weight', 'transformer.resblocks.18.attn.out_proj.bias',
                'transformer.resblocks.18.attn.out_proj.weight', 'transformer.resblocks.19.ln_1.bias',
                'transformer.resblocks.19.ln_1.weight', 'transformer.resblocks.19.ln_2.bias',
                'transformer.resblocks.19.ln_2.weight', 'transformer.resblocks.19.mlp.c_fc.bias',
                'transformer.resblocks.19.mlp.c_fc.weight', 'transformer.resblocks.19.mlp.c_proj.bias',
                'transformer.resblocks.19.mlp.c_proj.weight', 'transformer.resblocks.19.attn.out_proj.bias',
                'transformer.resblocks.19.attn.out_proj.weight', 'transformer.resblocks.2.ln_1.bias',
                'transformer.resblocks.2.ln_1.weight', 'transformer.resblocks.2.ln_2.bias',
                'transformer.resblocks.2.ln_2.weight', 'transformer.resblocks.2.mlp.c_fc.bias',
                'transformer.resblocks.2.mlp.c_fc.weight', 'transformer.resblocks.2.mlp.c_proj.bias',
                'transformer.resblocks.2.mlp.c_proj.weight', 'transformer.resblocks.2.attn.out_proj.bias',
                'transformer.resblocks.2.attn.out_proj.weight', 'transformer.resblocks.20.ln_1.bias',
                'transformer.resblocks.20.ln_1.weight', 'transformer.resblocks.20.ln_2.bias',
                'transformer.resblocks.20.ln_2.weight', 'transformer.resblocks.20.mlp.c_fc.bias',
                'transformer.resblocks.20.mlp.c_fc.weight', 'transformer.resblocks.20.mlp.c_proj.bias',
                'transformer.resblocks.20.mlp.c_proj.weight', 'transformer.resblocks.20.attn.out_proj.bias',
                'transformer.resblocks.20.attn.out_proj.weight', 'transformer.resblocks.21.ln_1.bias',
                'transformer.resblocks.21.ln_1.weight', 'transformer.resblocks.21.ln_2.bias',
                'transformer.resblocks.21.ln_2.weight', 'transformer.resblocks.21.mlp.c_fc.bias',
                'transformer.resblocks.21.mlp.c_fc.weight', 'transformer.resblocks.21.mlp.c_proj.bias',
                'transformer.resblocks.21.mlp.c_proj.weight', 'transformer.resblocks.21.attn.out_proj.bias',
                'transformer.resblocks.21.attn.out_proj.weight', 'transformer.resblocks.22.ln_1.bias',
                'transformer.resblocks.22.ln_1.weight', 'transformer.resblocks.22.ln_2.bias',
                'transformer.resblocks.22.ln_2.weight', 'transformer.resblocks.22.mlp.c_fc.bias',
                'transformer.resblocks.22.mlp.c_fc.weight', 'transformer.resblocks.22.mlp.c_proj.bias',
                'transformer.resblocks.22.mlp.c_proj.weight', 'transformer.resblocks.22.attn.out_proj.bias',
                'transformer.resblocks.22.attn.out_proj.weight', 'transformer.resblocks.23.ln_1.bias',
                'transformer.resblocks.23.ln_1.weight', 'transformer.resblocks.23.ln_2.bias',
                'transformer.resblocks.23.ln_2.weight', 'transformer.resblocks.23.mlp.c_fc.bias',
                'transformer.resblocks.23.mlp.c_fc.weight', 'transformer.resblocks.23.mlp.c_proj.bias',
                'transformer.resblocks.23.mlp.c_proj.weight', 'transformer.resblocks.23.attn.out_proj.bias',
                'transformer.resblocks.23.attn.out_proj.weight', 'transformer.resblocks.24.ln_1.bias',
                'transformer.resblocks.24.ln_1.weight', 'transformer.resblocks.24.ln_2.bias',
                'transformer.resblocks.24.ln_2.weight', 'transformer.resblocks.24.mlp.c_fc.bias',
                'transformer.resblocks.24.mlp.c_fc.weight', 'transformer.resblocks.24.mlp.c_proj.bias',
                'transformer.resblocks.24.mlp.c_proj.weight', 'transformer.resblocks.24.attn.out_proj.bias',
                'transformer.resblocks.24.attn.out_proj.weight', 'transformer.resblocks.25.ln_1.bias',
                'transformer.resblocks.25.ln_1.weight', 'transformer.resblocks.25.ln_2.bias',
                'transformer.resblocks.25.ln_2.weight', 'transformer.resblocks.25.mlp.c_fc.bias',
                'transformer.resblocks.25.mlp.c_fc.weight', 'transformer.resblocks.25.mlp.c_proj.bias',
                'transformer.resblocks.25.mlp.c_proj.weight', 'transformer.resblocks.25.attn.out_proj.bias',
                'transformer.resblocks.25.attn.out_proj.weight', 'transformer.resblocks.26.ln_1.bias',
                'transformer.resblocks.26.ln_1.weight', 'transformer.resblocks.26.ln_2.bias',
                'transformer.resblocks.26.ln_2.weight', 'transformer.resblocks.26.mlp.c_fc.bias',
                'transformer.resblocks.26.mlp.c_fc.weight', 'transformer.resblocks.26.mlp.c_proj.bias',
                'transformer.resblocks.26.mlp.c_proj.weight', 'transformer.resblocks.26.attn.out_proj.bias',
                'transformer.resblocks.26.attn.out_proj.weight', 'transformer.resblocks.27.ln_1.bias',
                'transformer.resblocks.27.ln_1.weight', 'transformer.resblocks.27.ln_2.bias',
                'transformer.resblocks.27.ln_2.weight', 'transformer.resblocks.27.mlp.c_fc.bias',
                'transformer.resblocks.27.mlp.c_fc.weight', 'transformer.resblocks.27.mlp.c_proj.bias',
                'transformer.resblocks.27.mlp.c_proj.weight', 'transformer.resblocks.27.attn.out_proj.bias',
                'transformer.resblocks.27.attn.out_proj.weight', 'transformer.resblocks.28.ln_1.bias',
                'transformer.resblocks.28.ln_1.weight', 'transformer.resblocks.28.ln_2.bias',
                'transformer.resblocks.28.ln_2.weight', 'transformer.resblocks.28.mlp.c_fc.bias',
                'transformer.resblocks.28.mlp.c_fc.weight', 'transformer.resblocks.28.mlp.c_proj.bias',
                'transformer.resblocks.28.mlp.c_proj.weight', 'transformer.resblocks.28.attn.out_proj.bias',
                'transformer.resblocks.28.attn.out_proj.weight', 'transformer.resblocks.29.ln_1.bias',
                'transformer.resblocks.29.ln_1.weight', 'transformer.resblocks.29.ln_2.bias',
                'transformer.resblocks.29.ln_2.weight', 'transformer.resblocks.29.mlp.c_fc.bias',
                'transformer.resblocks.29.mlp.c_fc.weight', 'transformer.resblocks.29.mlp.c_proj.bias',
                'transformer.resblocks.29.mlp.c_proj.weight', 'transformer.resblocks.29.attn.out_proj.bias',
                'transformer.resblocks.29.attn.out_proj.weight', 'transformer.resblocks.3.ln_1.bias',
                'transformer.resblocks.3.ln_1.weight', 'transformer.resblocks.3.ln_2.bias',
                'transformer.resblocks.3.ln_2.weight', 'transformer.resblocks.3.mlp.c_fc.bias',
                'transformer.resblocks.3.mlp.c_fc.weight', 'transformer.resblocks.3.mlp.c_proj.bias',
                'transformer.resblocks.3.mlp.c_proj.weight', 'transformer.resblocks.3.attn.out_proj.bias',
                'transformer.resblocks.3.attn.out_proj.weight', 'transformer.resblocks.30.ln_1.bias',
                'transformer.resblocks.30.ln_1.weight', 'transformer.resblocks.30.ln_2.bias',
                'transformer.resblocks.30.ln_2.weight', 'transformer.resblocks.30.mlp.c_fc.bias',
                'transformer.resblocks.30.mlp.c_fc.weight', 'transformer.resblocks.30.mlp.c_proj.bias',
                'transformer.resblocks.30.mlp.c_proj.weight', 'transformer.resblocks.30.attn.out_proj.bias',
                'transformer.resblocks.30.attn.out_proj.weight', 'transformer.resblocks.31.ln_1.bias',
                'transformer.resblocks.31.ln_1.weight', 'transformer.resblocks.31.ln_2.bias',
                'transformer.resblocks.31.ln_2.weight', 'transformer.resblocks.31.mlp.c_fc.bias',
                'transformer.resblocks.31.mlp.c_fc.weight', 'transformer.resblocks.31.mlp.c_proj.bias',
                'transformer.resblocks.31.mlp.c_proj.weight', 'transformer.resblocks.31.attn.out_proj.bias',
                'transformer.resblocks.31.attn.out_proj.weight', 'transformer.resblocks.4.ln_1.bias',
                'transformer.resblocks.4.ln_1.weight', 'transformer.resblocks.4.ln_2.bias',
                'transformer.resblocks.4.ln_2.weight', 'transformer.resblocks.4.mlp.c_fc.bias',
                'transformer.resblocks.4.mlp.c_fc.weight', 'transformer.resblocks.4.mlp.c_proj.bias',
                'transformer.resblocks.4.mlp.c_proj.weight', 'transformer.resblocks.4.attn.out_proj.bias',
                'transformer.resblocks.4.attn.out_proj.weight', 'transformer.resblocks.5.ln_1.bias',
                'transformer.resblocks.5.ln_1.weight', 'transformer.resblocks.5.ln_2.bias',
                'transformer.resblocks.5.ln_2.weight', 'transformer.resblocks.5.mlp.c_fc.bias',
                'transformer.resblocks.5.mlp.c_fc.weight', 'transformer.resblocks.5.mlp.c_proj.bias',
                'transformer.resblocks.5.mlp.c_proj.weight', 'transformer.resblocks.5.attn.out_proj.bias',
                'transformer.resblocks.5.attn.out_proj.weight', 'transformer.resblocks.6.ln_1.bias',
                'transformer.resblocks.6.ln_1.weight', 'transformer.resblocks.6.ln_2.bias',
                'transformer.resblocks.6.ln_2.weight', 'transformer.resblocks.6.mlp.c_fc.bias',
                'transformer.resblocks.6.mlp.c_fc.weight', 'transformer.resblocks.6.mlp.c_proj.bias',
                'transformer.resblocks.6.mlp.c_proj.weight', 'transformer.resblocks.6.attn.out_proj.bias',
                'transformer.resblocks.6.attn.out_proj.weight', 'transformer.resblocks.7.ln_1.bias',
                'transformer.resblocks.7.ln_1.weight', 'transformer.resblocks.7.ln_2.bias',
                'transformer.resblocks.7.ln_2.weight', 'transformer.resblocks.7.mlp.c_fc.bias',
                'transformer.resblocks.7.mlp.c_fc.weight', 'transformer.resblocks.7.mlp.c_proj.bias',
                'transformer.resblocks.7.mlp.c_proj.weight', 'transformer.resblocks.7.attn.out_proj.bias',
                'transformer.resblocks.7.attn.out_proj.weight', 'transformer.resblocks.8.ln_1.bias',
                'transformer.resblocks.8.ln_1.weight', 'transformer.resblocks.8.ln_2.bias',
                'transformer.resblocks.8.ln_2.weight', 'transformer.resblocks.8.mlp.c_fc.bias',
                'transformer.resblocks.8.mlp.c_fc.weight', 'transformer.resblocks.8.mlp.c_proj.bias',
                'transformer.resblocks.8.mlp.c_proj.weight', 'transformer.resblocks.8.attn.out_proj.bias',
                'transformer.resblocks.8.attn.out_proj.weight', 'transformer.resblocks.9.ln_1.bias',
                'transformer.resblocks.9.ln_1.weight', 'transformer.resblocks.9.ln_2.bias',
                'transformer.resblocks.9.ln_2.weight', 'transformer.resblocks.9.mlp.c_fc.bias',
                'transformer.resblocks.9.mlp.c_fc.weight', 'transformer.resblocks.9.mlp.c_proj.bias',
                'transformer.resblocks.9.mlp.c_proj.weight', 'transformer.resblocks.9.attn.out_proj.bias',
                'transformer.resblocks.9.attn.out_proj.weight', 'ln_final.bias', 'ln_final.weight',
                'text_projection.weight', 'transformer.resblocks.0.attn.in_proj_weight',
                'transformer.resblocks.1.attn.in_proj_weight', 'transformer.resblocks.10.attn.in_proj_weight',
                'transformer.resblocks.11.attn.in_proj_weight', 'transformer.resblocks.12.attn.in_proj_weight',
                'transformer.resblocks.13.attn.in_proj_weight', 'transformer.resblocks.14.attn.in_proj_weight',
                'transformer.resblocks.15.attn.in_proj_weight', 'transformer.resblocks.16.attn.in_proj_weight',
                'transformer.resblocks.17.attn.in_proj_weight', 'transformer.resblocks.18.attn.in_proj_weight',
                'transformer.resblocks.19.attn.in_proj_weight', 'transformer.resblocks.2.attn.in_proj_weight',
                'transformer.resblocks.20.attn.in_proj_weight', 'transformer.resblocks.21.attn.in_proj_weight',
                'transformer.resblocks.22.attn.in_proj_weight', 'transformer.resblocks.23.attn.in_proj_weight',
                'transformer.resblocks.24.attn.in_proj_weight', 'transformer.resblocks.25.attn.in_proj_weight',
                'transformer.resblocks.26.attn.in_proj_weight', 'transformer.resblocks.27.attn.in_proj_weight',
                'transformer.resblocks.28.attn.in_proj_weight', 'transformer.resblocks.29.attn.in_proj_weight',
                'transformer.resblocks.3.attn.in_proj_weight', 'transformer.resblocks.30.attn.in_proj_weight',
                'transformer.resblocks.31.attn.in_proj_weight', 'transformer.resblocks.4.attn.in_proj_weight',
                'transformer.resblocks.5.attn.in_proj_weight', 'transformer.resblocks.6.attn.in_proj_weight',
                'transformer.resblocks.7.attn.in_proj_weight', 'transformer.resblocks.8.attn.in_proj_weight',
                'transformer.resblocks.9.attn.in_proj_weight', 'transformer.resblocks.0.attn.in_proj_bias',
                'transformer.resblocks.1.attn.in_proj_bias', 'transformer.resblocks.10.attn.in_proj_bias',
                'transformer.resblocks.11.attn.in_proj_bias', 'transformer.resblocks.12.attn.in_proj_bias',
                'transformer.resblocks.13.attn.in_proj_bias', 'transformer.resblocks.14.attn.in_proj_bias',
                'transformer.resblocks.15.attn.in_proj_bias', 'transformer.resblocks.16.attn.in_proj_bias',
                'transformer.resblocks.17.attn.in_proj_bias', 'transformer.resblocks.18.attn.in_proj_bias',
                'transformer.resblocks.19.attn.in_proj_bias', 'transformer.resblocks.2.attn.in_proj_bias',
                'transformer.resblocks.20.attn.in_proj_bias', 'transformer.resblocks.21.attn.in_proj_bias',
                'transformer.resblocks.22.attn.in_proj_bias', 'transformer.resblocks.23.attn.in_proj_bias',
                'transformer.resblocks.24.attn.in_proj_bias', 'transformer.resblocks.25.attn.in_proj_bias',
                'transformer.resblocks.26.attn.in_proj_bias', 'transformer.resblocks.27.attn.in_proj_bias',
                'transformer.resblocks.28.attn.in_proj_bias', 'transformer.resblocks.29.attn.in_proj_bias',
                'transformer.resblocks.3.attn.in_proj_bias', 'transformer.resblocks.30.attn.in_proj_bias',
                'transformer.resblocks.31.attn.in_proj_bias', 'transformer.resblocks.4.attn.in_proj_bias',
                'transformer.resblocks.5.attn.in_proj_bias', 'transformer.resblocks.6.attn.in_proj_bias',
                'transformer.resblocks.7.attn.in_proj_bias', 'transformer.resblocks.8.attn.in_proj_bias',
                'transformer.resblocks.9.attn.in_proj_bias']

hf_text2 = ['text_model.embeddings.position_embedding.weight', 'text_model.embeddings.token_embedding.weight',
            'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.0.layer_norm1.weight',
            'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm2.weight',
            'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.0.mlp.fc1.weight',
            'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.0.mlp.fc2.weight',
            'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.0.self_attn.k_proj.weight',
            'text_model.encoder.layers.0.self_attn.out_proj.bias',
            'text_model.encoder.layers.0.self_attn.out_proj.weight',
            'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.weight',
            'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.0.self_attn.v_proj.weight',
            'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.1.layer_norm1.weight',
            'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.1.layer_norm2.weight',
            'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.1.mlp.fc1.weight',
            'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.1.mlp.fc2.weight',
            'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.weight',
            'text_model.encoder.layers.1.self_attn.out_proj.bias',
            'text_model.encoder.layers.1.self_attn.out_proj.weight',
            'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.q_proj.weight',
            'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.weight',
            'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.10.layer_norm1.weight',
            'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.10.layer_norm2.weight',
            'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.10.mlp.fc1.weight',
            'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.10.mlp.fc2.weight',
            'text_model.encoder.layers.10.self_attn.k_proj.bias',
            'text_model.encoder.layers.10.self_attn.k_proj.weight',
            'text_model.encoder.layers.10.self_attn.out_proj.bias',
            'text_model.encoder.layers.10.self_attn.out_proj.weight',
            'text_model.encoder.layers.10.self_attn.q_proj.bias',
            'text_model.encoder.layers.10.self_attn.q_proj.weight',
            'text_model.encoder.layers.10.self_attn.v_proj.bias',
            'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias',
            'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.11.layer_norm2.bias',
            'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc1.bias',
            'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.11.mlp.fc2.bias',
            'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.k_proj.bias',
            'text_model.encoder.layers.11.self_attn.k_proj.weight',
            'text_model.encoder.layers.11.self_attn.out_proj.bias',
            'text_model.encoder.layers.11.self_attn.out_proj.weight',
            'text_model.encoder.layers.11.self_attn.q_proj.bias',
            'text_model.encoder.layers.11.self_attn.q_proj.weight',
            'text_model.encoder.layers.11.self_attn.v_proj.bias',
            'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.12.layer_norm1.bias',
            'text_model.encoder.layers.12.layer_norm1.weight', 'text_model.encoder.layers.12.layer_norm2.bias',
            'text_model.encoder.layers.12.layer_norm2.weight', 'text_model.encoder.layers.12.mlp.fc1.bias',
            'text_model.encoder.layers.12.mlp.fc1.weight', 'text_model.encoder.layers.12.mlp.fc2.bias',
            'text_model.encoder.layers.12.mlp.fc2.weight', 'text_model.encoder.layers.12.self_attn.k_proj.bias',
            'text_model.encoder.layers.12.self_attn.k_proj.weight',
            'text_model.encoder.layers.12.self_attn.out_proj.bias',
            'text_model.encoder.layers.12.self_attn.out_proj.weight',
            'text_model.encoder.layers.12.self_attn.q_proj.bias',
            'text_model.encoder.layers.12.self_attn.q_proj.weight',
            'text_model.encoder.layers.12.self_attn.v_proj.bias',
            'text_model.encoder.layers.12.self_attn.v_proj.weight', 'text_model.encoder.layers.13.layer_norm1.bias',
            'text_model.encoder.layers.13.layer_norm1.weight', 'text_model.encoder.layers.13.layer_norm2.bias',
            'text_model.encoder.layers.13.layer_norm2.weight', 'text_model.encoder.layers.13.mlp.fc1.bias',
            'text_model.encoder.layers.13.mlp.fc1.weight', 'text_model.encoder.layers.13.mlp.fc2.bias',
            'text_model.encoder.layers.13.mlp.fc2.weight', 'text_model.encoder.layers.13.self_attn.k_proj.bias',
            'text_model.encoder.layers.13.self_attn.k_proj.weight',
            'text_model.encoder.layers.13.self_attn.out_proj.bias',
            'text_model.encoder.layers.13.self_attn.out_proj.weight',
            'text_model.encoder.layers.13.self_attn.q_proj.bias',
            'text_model.encoder.layers.13.self_attn.q_proj.weight',
            'text_model.encoder.layers.13.self_attn.v_proj.bias',
            'text_model.encoder.layers.13.self_attn.v_proj.weight', 'text_model.encoder.layers.14.layer_norm1.bias',
            'text_model.encoder.layers.14.layer_norm1.weight', 'text_model.encoder.layers.14.layer_norm2.bias',
            'text_model.encoder.layers.14.layer_norm2.weight', 'text_model.encoder.layers.14.mlp.fc1.bias',
            'text_model.encoder.layers.14.mlp.fc1.weight', 'text_model.encoder.layers.14.mlp.fc2.bias',
            'text_model.encoder.layers.14.mlp.fc2.weight', 'text_model.encoder.layers.14.self_attn.k_proj.bias',
            'text_model.encoder.layers.14.self_attn.k_proj.weight',
            'text_model.encoder.layers.14.self_attn.out_proj.bias',
            'text_model.encoder.layers.14.self_attn.out_proj.weight',
            'text_model.encoder.layers.14.self_attn.q_proj.bias',
            'text_model.encoder.layers.14.self_attn.q_proj.weight',
            'text_model.encoder.layers.14.self_attn.v_proj.bias',
            'text_model.encoder.layers.14.self_attn.v_proj.weight', 'text_model.encoder.layers.15.layer_norm1.bias',
            'text_model.encoder.layers.15.layer_norm1.weight', 'text_model.encoder.layers.15.layer_norm2.bias',
            'text_model.encoder.layers.15.layer_norm2.weight', 'text_model.encoder.layers.15.mlp.fc1.bias',
            'text_model.encoder.layers.15.mlp.fc1.weight', 'text_model.encoder.layers.15.mlp.fc2.bias',
            'text_model.encoder.layers.15.mlp.fc2.weight', 'text_model.encoder.layers.15.self_attn.k_proj.bias',
            'text_model.encoder.layers.15.self_attn.k_proj.weight',
            'text_model.encoder.layers.15.self_attn.out_proj.bias',
            'text_model.encoder.layers.15.self_attn.out_proj.weight',
            'text_model.encoder.layers.15.self_attn.q_proj.bias',
            'text_model.encoder.layers.15.self_attn.q_proj.weight',
            'text_model.encoder.layers.15.self_attn.v_proj.bias',
            'text_model.encoder.layers.15.self_attn.v_proj.weight', 'text_model.encoder.layers.16.layer_norm1.bias',
            'text_model.encoder.layers.16.layer_norm1.weight', 'text_model.encoder.layers.16.layer_norm2.bias',
            'text_model.encoder.layers.16.layer_norm2.weight', 'text_model.encoder.layers.16.mlp.fc1.bias',
            'text_model.encoder.layers.16.mlp.fc1.weight', 'text_model.encoder.layers.16.mlp.fc2.bias',
            'text_model.encoder.layers.16.mlp.fc2.weight', 'text_model.encoder.layers.16.self_attn.k_proj.bias',
            'text_model.encoder.layers.16.self_attn.k_proj.weight',
            'text_model.encoder.layers.16.self_attn.out_proj.bias',
            'text_model.encoder.layers.16.self_attn.out_proj.weight',
            'text_model.encoder.layers.16.self_attn.q_proj.bias',
            'text_model.encoder.layers.16.self_attn.q_proj.weight',
            'text_model.encoder.layers.16.self_attn.v_proj.bias',
            'text_model.encoder.layers.16.self_attn.v_proj.weight', 'text_model.encoder.layers.17.layer_norm1.bias',
            'text_model.encoder.layers.17.layer_norm1.weight', 'text_model.encoder.layers.17.layer_norm2.bias',
            'text_model.encoder.layers.17.layer_norm2.weight', 'text_model.encoder.layers.17.mlp.fc1.bias',
            'text_model.encoder.layers.17.mlp.fc1.weight', 'text_model.encoder.layers.17.mlp.fc2.bias',
            'text_model.encoder.layers.17.mlp.fc2.weight', 'text_model.encoder.layers.17.self_attn.k_proj.bias',
            'text_model.encoder.layers.17.self_attn.k_proj.weight',
            'text_model.encoder.layers.17.self_attn.out_proj.bias',
            'text_model.encoder.layers.17.self_attn.out_proj.weight',
            'text_model.encoder.layers.17.self_attn.q_proj.bias',
            'text_model.encoder.layers.17.self_attn.q_proj.weight',
            'text_model.encoder.layers.17.self_attn.v_proj.bias',
            'text_model.encoder.layers.17.self_attn.v_proj.weight', 'text_model.encoder.layers.18.layer_norm1.bias',
            'text_model.encoder.layers.18.layer_norm1.weight', 'text_model.encoder.layers.18.layer_norm2.bias',
            'text_model.encoder.layers.18.layer_norm2.weight', 'text_model.encoder.layers.18.mlp.fc1.bias',
            'text_model.encoder.layers.18.mlp.fc1.weight', 'text_model.encoder.layers.18.mlp.fc2.bias',
            'text_model.encoder.layers.18.mlp.fc2.weight', 'text_model.encoder.layers.18.self_attn.k_proj.bias',
            'text_model.encoder.layers.18.self_attn.k_proj.weight',
            'text_model.encoder.layers.18.self_attn.out_proj.bias',
            'text_model.encoder.layers.18.self_attn.out_proj.weight',
            'text_model.encoder.layers.18.self_attn.q_proj.bias',
            'text_model.encoder.layers.18.self_attn.q_proj.weight',
            'text_model.encoder.layers.18.self_attn.v_proj.bias',
            'text_model.encoder.layers.18.self_attn.v_proj.weight', 'text_model.encoder.layers.19.layer_norm1.bias',
            'text_model.encoder.layers.19.layer_norm1.weight', 'text_model.encoder.layers.19.layer_norm2.bias',
            'text_model.encoder.layers.19.layer_norm2.weight', 'text_model.encoder.layers.19.mlp.fc1.bias',
            'text_model.encoder.layers.19.mlp.fc1.weight', 'text_model.encoder.layers.19.mlp.fc2.bias',
            'text_model.encoder.layers.19.mlp.fc2.weight', 'text_model.encoder.layers.19.self_attn.k_proj.bias',
            'text_model.encoder.layers.19.self_attn.k_proj.weight',
            'text_model.encoder.layers.19.self_attn.out_proj.bias',
            'text_model.encoder.layers.19.self_attn.out_proj.weight',
            'text_model.encoder.layers.19.self_attn.q_proj.bias',
            'text_model.encoder.layers.19.self_attn.q_proj.weight',
            'text_model.encoder.layers.19.self_attn.v_proj.bias',
            'text_model.encoder.layers.19.self_attn.v_proj.weight', 'text_model.encoder.layers.2.layer_norm1.bias',
            'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.2.layer_norm2.bias',
            'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc1.bias',
            'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.2.mlp.fc2.bias',
            'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.k_proj.bias',
            'text_model.encoder.layers.2.self_attn.k_proj.weight',
            'text_model.encoder.layers.2.self_attn.out_proj.bias',
            'text_model.encoder.layers.2.self_attn.out_proj.weight',
            'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.2.self_attn.q_proj.weight',
            'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.2.self_attn.v_proj.weight',
            'text_model.encoder.layers.20.layer_norm1.bias', 'text_model.encoder.layers.20.layer_norm1.weight',
            'text_model.encoder.layers.20.layer_norm2.bias', 'text_model.encoder.layers.20.layer_norm2.weight',
            'text_model.encoder.layers.20.mlp.fc1.bias', 'text_model.encoder.layers.20.mlp.fc1.weight',
            'text_model.encoder.layers.20.mlp.fc2.bias', 'text_model.encoder.layers.20.mlp.fc2.weight',
            'text_model.encoder.layers.20.self_attn.k_proj.bias',
            'text_model.encoder.layers.20.self_attn.k_proj.weight',
            'text_model.encoder.layers.20.self_attn.out_proj.bias',
            'text_model.encoder.layers.20.self_attn.out_proj.weight',
            'text_model.encoder.layers.20.self_attn.q_proj.bias',
            'text_model.encoder.layers.20.self_attn.q_proj.weight',
            'text_model.encoder.layers.20.self_attn.v_proj.bias',
            'text_model.encoder.layers.20.self_attn.v_proj.weight', 'text_model.encoder.layers.21.layer_norm1.bias',
            'text_model.encoder.layers.21.layer_norm1.weight', 'text_model.encoder.layers.21.layer_norm2.bias',
            'text_model.encoder.layers.21.layer_norm2.weight', 'text_model.encoder.layers.21.mlp.fc1.bias',
            'text_model.encoder.layers.21.mlp.fc1.weight', 'text_model.encoder.layers.21.mlp.fc2.bias',
            'text_model.encoder.layers.21.mlp.fc2.weight', 'text_model.encoder.layers.21.self_attn.k_proj.bias',
            'text_model.encoder.layers.21.self_attn.k_proj.weight',
            'text_model.encoder.layers.21.self_attn.out_proj.bias',
            'text_model.encoder.layers.21.self_attn.out_proj.weight',
            'text_model.encoder.layers.21.self_attn.q_proj.bias',
            'text_model.encoder.layers.21.self_attn.q_proj.weight',
            'text_model.encoder.layers.21.self_attn.v_proj.bias',
            'text_model.encoder.layers.21.self_attn.v_proj.weight', 'text_model.encoder.layers.22.layer_norm1.bias',
            'text_model.encoder.layers.22.layer_norm1.weight', 'text_model.encoder.layers.22.layer_norm2.bias',
            'text_model.encoder.layers.22.layer_norm2.weight', 'text_model.encoder.layers.22.mlp.fc1.bias',
            'text_model.encoder.layers.22.mlp.fc1.weight', 'text_model.encoder.layers.22.mlp.fc2.bias',
            'text_model.encoder.layers.22.mlp.fc2.weight', 'text_model.encoder.layers.22.self_attn.k_proj.bias',
            'text_model.encoder.layers.22.self_attn.k_proj.weight',
            'text_model.encoder.layers.22.self_attn.out_proj.bias',
            'text_model.encoder.layers.22.self_attn.out_proj.weight',
            'text_model.encoder.layers.22.self_attn.q_proj.bias',
            'text_model.encoder.layers.22.self_attn.q_proj.weight',
            'text_model.encoder.layers.22.self_attn.v_proj.bias',
            'text_model.encoder.layers.22.self_attn.v_proj.weight', 'text_model.encoder.layers.23.layer_norm1.bias',
            'text_model.encoder.layers.23.layer_norm1.weight', 'text_model.encoder.layers.23.layer_norm2.bias',
            'text_model.encoder.layers.23.layer_norm2.weight', 'text_model.encoder.layers.23.mlp.fc1.bias',
            'text_model.encoder.layers.23.mlp.fc1.weight', 'text_model.encoder.layers.23.mlp.fc2.bias',
            'text_model.encoder.layers.23.mlp.fc2.weight', 'text_model.encoder.layers.23.self_attn.k_proj.bias',
            'text_model.encoder.layers.23.self_attn.k_proj.weight',
            'text_model.encoder.layers.23.self_attn.out_proj.bias',
            'text_model.encoder.layers.23.self_attn.out_proj.weight',
            'text_model.encoder.layers.23.self_attn.q_proj.bias',
            'text_model.encoder.layers.23.self_attn.q_proj.weight',
            'text_model.encoder.layers.23.self_attn.v_proj.bias',
            'text_model.encoder.layers.23.self_attn.v_proj.weight', 'text_model.encoder.layers.24.layer_norm1.bias',
            'text_model.encoder.layers.24.layer_norm1.weight', 'text_model.encoder.layers.24.layer_norm2.bias',
            'text_model.encoder.layers.24.layer_norm2.weight', 'text_model.encoder.layers.24.mlp.fc1.bias',
            'text_model.encoder.layers.24.mlp.fc1.weight', 'text_model.encoder.layers.24.mlp.fc2.bias',
            'text_model.encoder.layers.24.mlp.fc2.weight', 'text_model.encoder.layers.24.self_attn.k_proj.bias',
            'text_model.encoder.layers.24.self_attn.k_proj.weight',
            'text_model.encoder.layers.24.self_attn.out_proj.bias',
            'text_model.encoder.layers.24.self_attn.out_proj.weight',
            'text_model.encoder.layers.24.self_attn.q_proj.bias',
            'text_model.encoder.layers.24.self_attn.q_proj.weight',
            'text_model.encoder.layers.24.self_attn.v_proj.bias',
            'text_model.encoder.layers.24.self_attn.v_proj.weight', 'text_model.encoder.layers.25.layer_norm1.bias',
            'text_model.encoder.layers.25.layer_norm1.weight', 'text_model.encoder.layers.25.layer_norm2.bias',
            'text_model.encoder.layers.25.layer_norm2.weight', 'text_model.encoder.layers.25.mlp.fc1.bias',
            'text_model.encoder.layers.25.mlp.fc1.weight', 'text_model.encoder.layers.25.mlp.fc2.bias',
            'text_model.encoder.layers.25.mlp.fc2.weight', 'text_model.encoder.layers.25.self_attn.k_proj.bias',
            'text_model.encoder.layers.25.self_attn.k_proj.weight',
            'text_model.encoder.layers.25.self_attn.out_proj.bias',
            'text_model.encoder.layers.25.self_attn.out_proj.weight',
            'text_model.encoder.layers.25.self_attn.q_proj.bias',
            'text_model.encoder.layers.25.self_attn.q_proj.weight',
            'text_model.encoder.layers.25.self_attn.v_proj.bias',
            'text_model.encoder.layers.25.self_attn.v_proj.weight', 'text_model.encoder.layers.26.layer_norm1.bias',
            'text_model.encoder.layers.26.layer_norm1.weight', 'text_model.encoder.layers.26.layer_norm2.bias',
            'text_model.encoder.layers.26.layer_norm2.weight', 'text_model.encoder.layers.26.mlp.fc1.bias',
            'text_model.encoder.layers.26.mlp.fc1.weight', 'text_model.encoder.layers.26.mlp.fc2.bias',
            'text_model.encoder.layers.26.mlp.fc2.weight', 'text_model.encoder.layers.26.self_attn.k_proj.bias',
            'text_model.encoder.layers.26.self_attn.k_proj.weight',
            'text_model.encoder.layers.26.self_attn.out_proj.bias',
            'text_model.encoder.layers.26.self_attn.out_proj.weight',
            'text_model.encoder.layers.26.self_attn.q_proj.bias',
            'text_model.encoder.layers.26.self_attn.q_proj.weight',
            'text_model.encoder.layers.26.self_attn.v_proj.bias',
            'text_model.encoder.layers.26.self_attn.v_proj.weight', 'text_model.encoder.layers.27.layer_norm1.bias',
            'text_model.encoder.layers.27.layer_norm1.weight', 'text_model.encoder.layers.27.layer_norm2.bias',
            'text_model.encoder.layers.27.layer_norm2.weight', 'text_model.encoder.layers.27.mlp.fc1.bias',
            'text_model.encoder.layers.27.mlp.fc1.weight', 'text_model.encoder.layers.27.mlp.fc2.bias',
            'text_model.encoder.layers.27.mlp.fc2.weight', 'text_model.encoder.layers.27.self_attn.k_proj.bias',
            'text_model.encoder.layers.27.self_attn.k_proj.weight',
            'text_model.encoder.layers.27.self_attn.out_proj.bias',
            'text_model.encoder.layers.27.self_attn.out_proj.weight',
            'text_model.encoder.layers.27.self_attn.q_proj.bias',
            'text_model.encoder.layers.27.self_attn.q_proj.weight',
            'text_model.encoder.layers.27.self_attn.v_proj.bias',
            'text_model.encoder.layers.27.self_attn.v_proj.weight', 'text_model.encoder.layers.28.layer_norm1.bias',
            'text_model.encoder.layers.28.layer_norm1.weight', 'text_model.encoder.layers.28.layer_norm2.bias',
            'text_model.encoder.layers.28.layer_norm2.weight', 'text_model.encoder.layers.28.mlp.fc1.bias',
            'text_model.encoder.layers.28.mlp.fc1.weight', 'text_model.encoder.layers.28.mlp.fc2.bias',
            'text_model.encoder.layers.28.mlp.fc2.weight', 'text_model.encoder.layers.28.self_attn.k_proj.bias',
            'text_model.encoder.layers.28.self_attn.k_proj.weight',
            'text_model.encoder.layers.28.self_attn.out_proj.bias',
            'text_model.encoder.layers.28.self_attn.out_proj.weight',
            'text_model.encoder.layers.28.self_attn.q_proj.bias',
            'text_model.encoder.layers.28.self_attn.q_proj.weight',
            'text_model.encoder.layers.28.self_attn.v_proj.bias',
            'text_model.encoder.layers.28.self_attn.v_proj.weight', 'text_model.encoder.layers.29.layer_norm1.bias',
            'text_model.encoder.layers.29.layer_norm1.weight', 'text_model.encoder.layers.29.layer_norm2.bias',
            'text_model.encoder.layers.29.layer_norm2.weight', 'text_model.encoder.layers.29.mlp.fc1.bias',
            'text_model.encoder.layers.29.mlp.fc1.weight', 'text_model.encoder.layers.29.mlp.fc2.bias',
            'text_model.encoder.layers.29.mlp.fc2.weight', 'text_model.encoder.layers.29.self_attn.k_proj.bias',
            'text_model.encoder.layers.29.self_attn.k_proj.weight',
            'text_model.encoder.layers.29.self_attn.out_proj.bias',
            'text_model.encoder.layers.29.self_attn.out_proj.weight',
            'text_model.encoder.layers.29.self_attn.q_proj.bias',
            'text_model.encoder.layers.29.self_attn.q_proj.weight',
            'text_model.encoder.layers.29.self_attn.v_proj.bias',
            'text_model.encoder.layers.29.self_attn.v_proj.weight', 'text_model.encoder.layers.3.layer_norm1.bias',
            'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.3.layer_norm2.bias',
            'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.3.mlp.fc1.bias',
            'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias',
            'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias',
            'text_model.encoder.layers.3.self_attn.k_proj.weight',
            'text_model.encoder.layers.3.self_attn.out_proj.bias',
            'text_model.encoder.layers.3.self_attn.out_proj.weight',
            'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.3.self_attn.q_proj.weight',
            'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.v_proj.weight',
            'text_model.encoder.layers.30.layer_norm1.bias', 'text_model.encoder.layers.30.layer_norm1.weight',
            'text_model.encoder.layers.30.layer_norm2.bias', 'text_model.encoder.layers.30.layer_norm2.weight',
            'text_model.encoder.layers.30.mlp.fc1.bias', 'text_model.encoder.layers.30.mlp.fc1.weight',
            'text_model.encoder.layers.30.mlp.fc2.bias', 'text_model.encoder.layers.30.mlp.fc2.weight',
            'text_model.encoder.layers.30.self_attn.k_proj.bias',
            'text_model.encoder.layers.30.self_attn.k_proj.weight',
            'text_model.encoder.layers.30.self_attn.out_proj.bias',
            'text_model.encoder.layers.30.self_attn.out_proj.weight',
            'text_model.encoder.layers.30.self_attn.q_proj.bias',
            'text_model.encoder.layers.30.self_attn.q_proj.weight',
            'text_model.encoder.layers.30.self_attn.v_proj.bias',
            'text_model.encoder.layers.30.self_attn.v_proj.weight', 'text_model.encoder.layers.31.layer_norm1.bias',
            'text_model.encoder.layers.31.layer_norm1.weight', 'text_model.encoder.layers.31.layer_norm2.bias',
            'text_model.encoder.layers.31.layer_norm2.weight', 'text_model.encoder.layers.31.mlp.fc1.bias',
            'text_model.encoder.layers.31.mlp.fc1.weight', 'text_model.encoder.layers.31.mlp.fc2.bias',
            'text_model.encoder.layers.31.mlp.fc2.weight', 'text_model.encoder.layers.31.self_attn.k_proj.bias',
            'text_model.encoder.layers.31.self_attn.k_proj.weight',
            'text_model.encoder.layers.31.self_attn.out_proj.bias',
            'text_model.encoder.layers.31.self_attn.out_proj.weight',
            'text_model.encoder.layers.31.self_attn.q_proj.bias',
            'text_model.encoder.layers.31.self_attn.q_proj.weight',
            'text_model.encoder.layers.31.self_attn.v_proj.bias',
            'text_model.encoder.layers.31.self_attn.v_proj.weight', 'text_model.encoder.layers.4.layer_norm1.bias',
            'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.4.layer_norm2.bias',
            'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.4.mlp.fc1.bias',
            'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.4.mlp.fc2.bias',
            'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.4.self_attn.k_proj.bias',
            'text_model.encoder.layers.4.self_attn.k_proj.weight',
            'text_model.encoder.layers.4.self_attn.out_proj.bias',
            'text_model.encoder.layers.4.self_attn.out_proj.weight',
            'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.q_proj.weight',
            'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.weight',
            'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.5.layer_norm1.weight',
            'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.5.layer_norm2.weight',
            'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.5.mlp.fc1.weight',
            'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.5.mlp.fc2.weight',
            'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.5.self_attn.k_proj.weight',
            'text_model.encoder.layers.5.self_attn.out_proj.bias',
            'text_model.encoder.layers.5.self_attn.out_proj.weight',
            'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.q_proj.weight',
            'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.weight',
            'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.6.layer_norm1.weight',
            'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.6.layer_norm2.weight',
            'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.6.mlp.fc1.weight',
            'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.6.mlp.fc2.weight',
            'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.6.self_attn.k_proj.weight',
            'text_model.encoder.layers.6.self_attn.out_proj.bias',
            'text_model.encoder.layers.6.self_attn.out_proj.weight',
            'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.6.self_attn.q_proj.weight',
            'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.weight',
            'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.7.layer_norm1.weight',
            'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.7.layer_norm2.weight',
            'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.7.mlp.fc1.weight',
            'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.7.mlp.fc2.weight',
            'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight',
            'text_model.encoder.layers.7.self_attn.out_proj.bias',
            'text_model.encoder.layers.7.self_attn.out_proj.weight',
            'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight',
            'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight',
            'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.8.layer_norm1.weight',
            'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.8.layer_norm2.weight',
            'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.8.mlp.fc1.weight',
            'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.8.mlp.fc2.weight',
            'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.k_proj.weight',
            'text_model.encoder.layers.8.self_attn.out_proj.bias',
            'text_model.encoder.layers.8.self_attn.out_proj.weight',
            'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.8.self_attn.q_proj.weight',
            'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight',
            'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.9.layer_norm1.weight',
            'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.9.layer_norm2.weight',
            'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.9.mlp.fc1.weight',
            'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.9.mlp.fc2.weight',
            'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.weight',
            'text_model.encoder.layers.9.self_attn.out_proj.bias',
            'text_model.encoder.layers.9.self_attn.out_proj.weight',
            'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.q_proj.weight',
            'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.9.self_attn.v_proj.weight',
            'text_model.final_layer_norm.bias', 'text_model.final_layer_norm.weight', 'text_projection.weight']

text2map = {'text_model.embeddings.position_embedding.weight': 'positional_embedding',
            'text_model.embeddings.token_embedding.weight': 'token_embedding.weight',
            'text_model.encoder.layers.0.layer_norm1.bias': 'transformer.resblocks.0.ln_1.bias',
            'text_model.encoder.layers.0.layer_norm1.weight': 'transformer.resblocks.0.ln_1.weight',
            'text_model.encoder.layers.0.layer_norm2.bias': 'transformer.resblocks.0.ln_2.bias',
            'text_model.encoder.layers.0.layer_norm2.weight': 'transformer.resblocks.0.ln_2.weight',
            'text_model.encoder.layers.0.mlp.fc1.bias': 'transformer.resblocks.0.mlp.c_fc.bias',
            'text_model.encoder.layers.0.mlp.fc1.weight': 'transformer.resblocks.0.mlp.c_fc.weight',
            'text_model.encoder.layers.0.mlp.fc2.bias': 'transformer.resblocks.0.mlp.c_proj.bias',
            'text_model.encoder.layers.0.mlp.fc2.weight': 'transformer.resblocks.0.mlp.c_proj.weight',
            'text_model.encoder.layers.0.self_attn.out_proj.bias': 'transformer.resblocks.0.attn.out_proj.bias',
            'text_model.encoder.layers.0.self_attn.out_proj.weight': 'transformer.resblocks.0.attn.out_proj.weight',
            'text_model.encoder.layers.1.layer_norm1.bias': 'transformer.resblocks.1.ln_1.bias',
            'text_model.encoder.layers.1.layer_norm1.weight': 'transformer.resblocks.1.ln_1.weight',
            'text_model.encoder.layers.1.layer_norm2.bias': 'transformer.resblocks.1.ln_2.bias',
            'text_model.encoder.layers.1.layer_norm2.weight': 'transformer.resblocks.1.ln_2.weight',
            'text_model.encoder.layers.1.mlp.fc1.bias': 'transformer.resblocks.1.mlp.c_fc.bias',
            'text_model.encoder.layers.1.mlp.fc1.weight': 'transformer.resblocks.1.mlp.c_fc.weight',
            'text_model.encoder.layers.1.mlp.fc2.bias': 'transformer.resblocks.1.mlp.c_proj.bias',
            'text_model.encoder.layers.1.mlp.fc2.weight': 'transformer.resblocks.1.mlp.c_proj.weight',
            'text_model.encoder.layers.1.self_attn.out_proj.bias': 'transformer.resblocks.1.attn.out_proj.bias',
            'text_model.encoder.layers.1.self_attn.out_proj.weight': 'transformer.resblocks.1.attn.out_proj.weight',
            'text_model.encoder.layers.10.layer_norm1.bias': 'transformer.resblocks.10.ln_1.bias',
            'text_model.encoder.layers.10.layer_norm1.weight': 'transformer.resblocks.10.ln_1.weight',
            'text_model.encoder.layers.10.layer_norm2.bias': 'transformer.resblocks.10.ln_2.bias',
            'text_model.encoder.layers.10.layer_norm2.weight': 'transformer.resblocks.10.ln_2.weight',
            'text_model.encoder.layers.10.mlp.fc1.bias': 'transformer.resblocks.10.mlp.c_fc.bias',
            'text_model.encoder.layers.10.mlp.fc1.weight': 'transformer.resblocks.10.mlp.c_fc.weight',
            'text_model.encoder.layers.10.mlp.fc2.bias': 'transformer.resblocks.10.mlp.c_proj.bias',
            'text_model.encoder.layers.10.mlp.fc2.weight': 'transformer.resblocks.10.mlp.c_proj.weight',
            'text_model.encoder.layers.10.self_attn.out_proj.bias': 'transformer.resblocks.10.attn.out_proj.bias',
            'text_model.encoder.layers.10.self_attn.out_proj.weight': 'transformer.resblocks.10.attn.out_proj.weight',
            'text_model.encoder.layers.11.layer_norm1.bias': 'transformer.resblocks.11.ln_1.bias',
            'text_model.encoder.layers.11.layer_norm1.weight': 'transformer.resblocks.11.ln_1.weight',
            'text_model.encoder.layers.11.layer_norm2.bias': 'transformer.resblocks.11.ln_2.bias',
            'text_model.encoder.layers.11.layer_norm2.weight': 'transformer.resblocks.11.ln_2.weight',
            'text_model.encoder.layers.11.mlp.fc1.bias': 'transformer.resblocks.11.mlp.c_fc.bias',
            'text_model.encoder.layers.11.mlp.fc1.weight': 'transformer.resblocks.11.mlp.c_fc.weight',
            'text_model.encoder.layers.11.mlp.fc2.bias': 'transformer.resblocks.11.mlp.c_proj.bias',
            'text_model.encoder.layers.11.mlp.fc2.weight': 'transformer.resblocks.11.mlp.c_proj.weight',
            'text_model.encoder.layers.11.self_attn.out_proj.bias': 'transformer.resblocks.11.attn.out_proj.bias',
            'text_model.encoder.layers.11.self_attn.out_proj.weight': 'transformer.resblocks.11.attn.out_proj.weight',
            'text_model.encoder.layers.12.layer_norm1.bias': 'transformer.resblocks.12.ln_1.bias',
            'text_model.encoder.layers.12.layer_norm1.weight': 'transformer.resblocks.12.ln_1.weight',
            'text_model.encoder.layers.12.layer_norm2.bias': 'transformer.resblocks.12.ln_2.bias',
            'text_model.encoder.layers.12.layer_norm2.weight': 'transformer.resblocks.12.ln_2.weight',
            'text_model.encoder.layers.12.mlp.fc1.bias': 'transformer.resblocks.12.mlp.c_fc.bias',
            'text_model.encoder.layers.12.mlp.fc1.weight': 'transformer.resblocks.12.mlp.c_fc.weight',
            'text_model.encoder.layers.12.mlp.fc2.bias': 'transformer.resblocks.12.mlp.c_proj.bias',
            'text_model.encoder.layers.12.mlp.fc2.weight': 'transformer.resblocks.12.mlp.c_proj.weight',
            'text_model.encoder.layers.12.self_attn.out_proj.bias': 'transformer.resblocks.12.attn.out_proj.bias',
            'text_model.encoder.layers.12.self_attn.out_proj.weight': 'transformer.resblocks.12.attn.out_proj.weight',
            'text_model.encoder.layers.13.layer_norm1.bias': 'transformer.resblocks.13.ln_1.bias',
            'text_model.encoder.layers.13.layer_norm1.weight': 'transformer.resblocks.13.ln_1.weight',
            'text_model.encoder.layers.13.layer_norm2.bias': 'transformer.resblocks.13.ln_2.bias',
            'text_model.encoder.layers.13.layer_norm2.weight': 'transformer.resblocks.13.ln_2.weight',
            'text_model.encoder.layers.13.mlp.fc1.bias': 'transformer.resblocks.13.mlp.c_fc.bias',
            'text_model.encoder.layers.13.mlp.fc1.weight': 'transformer.resblocks.13.mlp.c_fc.weight',
            'text_model.encoder.layers.13.mlp.fc2.bias': 'transformer.resblocks.13.mlp.c_proj.bias',
            'text_model.encoder.layers.13.mlp.fc2.weight': 'transformer.resblocks.13.mlp.c_proj.weight',
            'text_model.encoder.layers.13.self_attn.out_proj.bias': 'transformer.resblocks.13.attn.out_proj.bias',
            'text_model.encoder.layers.13.self_attn.out_proj.weight': 'transformer.resblocks.13.attn.out_proj.weight',
            'text_model.encoder.layers.14.layer_norm1.bias': 'transformer.resblocks.14.ln_1.bias',
            'text_model.encoder.layers.14.layer_norm1.weight': 'transformer.resblocks.14.ln_1.weight',
            'text_model.encoder.layers.14.layer_norm2.bias': 'transformer.resblocks.14.ln_2.bias',
            'text_model.encoder.layers.14.layer_norm2.weight': 'transformer.resblocks.14.ln_2.weight',
            'text_model.encoder.layers.14.mlp.fc1.bias': 'transformer.resblocks.14.mlp.c_fc.bias',
            'text_model.encoder.layers.14.mlp.fc1.weight': 'transformer.resblocks.14.mlp.c_fc.weight',
            'text_model.encoder.layers.14.mlp.fc2.bias': 'transformer.resblocks.14.mlp.c_proj.bias',
            'text_model.encoder.layers.14.mlp.fc2.weight': 'transformer.resblocks.14.mlp.c_proj.weight',
            'text_model.encoder.layers.14.self_attn.out_proj.bias': 'transformer.resblocks.14.attn.out_proj.bias',
            'text_model.encoder.layers.14.self_attn.out_proj.weight': 'transformer.resblocks.14.attn.out_proj.weight',
            'text_model.encoder.layers.15.layer_norm1.bias': 'transformer.resblocks.15.ln_1.bias',
            'text_model.encoder.layers.15.layer_norm1.weight': 'transformer.resblocks.15.ln_1.weight',
            'text_model.encoder.layers.15.layer_norm2.bias': 'transformer.resblocks.15.ln_2.bias',
            'text_model.encoder.layers.15.layer_norm2.weight': 'transformer.resblocks.15.ln_2.weight',
            'text_model.encoder.layers.15.mlp.fc1.bias': 'transformer.resblocks.15.mlp.c_fc.bias',
            'text_model.encoder.layers.15.mlp.fc1.weight': 'transformer.resblocks.15.mlp.c_fc.weight',
            'text_model.encoder.layers.15.mlp.fc2.bias': 'transformer.resblocks.15.mlp.c_proj.bias',
            'text_model.encoder.layers.15.mlp.fc2.weight': 'transformer.resblocks.15.mlp.c_proj.weight',
            'text_model.encoder.layers.15.self_attn.out_proj.bias': 'transformer.resblocks.15.attn.out_proj.bias',
            'text_model.encoder.layers.15.self_attn.out_proj.weight': 'transformer.resblocks.15.attn.out_proj.weight',
            'text_model.encoder.layers.16.layer_norm1.bias': 'transformer.resblocks.16.ln_1.bias',
            'text_model.encoder.layers.16.layer_norm1.weight': 'transformer.resblocks.16.ln_1.weight',
            'text_model.encoder.layers.16.layer_norm2.bias': 'transformer.resblocks.16.ln_2.bias',
            'text_model.encoder.layers.16.layer_norm2.weight': 'transformer.resblocks.16.ln_2.weight',
            'text_model.encoder.layers.16.mlp.fc1.bias': 'transformer.resblocks.16.mlp.c_fc.bias',
            'text_model.encoder.layers.16.mlp.fc1.weight': 'transformer.resblocks.16.mlp.c_fc.weight',
            'text_model.encoder.layers.16.mlp.fc2.bias': 'transformer.resblocks.16.mlp.c_proj.bias',
            'text_model.encoder.layers.16.mlp.fc2.weight': 'transformer.resblocks.16.mlp.c_proj.weight',
            'text_model.encoder.layers.16.self_attn.out_proj.bias': 'transformer.resblocks.16.attn.out_proj.bias',
            'text_model.encoder.layers.16.self_attn.out_proj.weight': 'transformer.resblocks.16.attn.out_proj.weight',
            'text_model.encoder.layers.17.layer_norm1.bias': 'transformer.resblocks.17.ln_1.bias',
            'text_model.encoder.layers.17.layer_norm1.weight': 'transformer.resblocks.17.ln_1.weight',
            'text_model.encoder.layers.17.layer_norm2.bias': 'transformer.resblocks.17.ln_2.bias',
            'text_model.encoder.layers.17.layer_norm2.weight': 'transformer.resblocks.17.ln_2.weight',
            'text_model.encoder.layers.17.mlp.fc1.bias': 'transformer.resblocks.17.mlp.c_fc.bias',
            'text_model.encoder.layers.17.mlp.fc1.weight': 'transformer.resblocks.17.mlp.c_fc.weight',
            'text_model.encoder.layers.17.mlp.fc2.bias': 'transformer.resblocks.17.mlp.c_proj.bias',
            'text_model.encoder.layers.17.mlp.fc2.weight': 'transformer.resblocks.17.mlp.c_proj.weight',
            'text_model.encoder.layers.17.self_attn.out_proj.bias': 'transformer.resblocks.17.attn.out_proj.bias',
            'text_model.encoder.layers.17.self_attn.out_proj.weight': 'transformer.resblocks.17.attn.out_proj.weight',
            'text_model.encoder.layers.18.layer_norm1.bias': 'transformer.resblocks.18.ln_1.bias',
            'text_model.encoder.layers.18.layer_norm1.weight': 'transformer.resblocks.18.ln_1.weight',
            'text_model.encoder.layers.18.layer_norm2.bias': 'transformer.resblocks.18.ln_2.bias',
            'text_model.encoder.layers.18.layer_norm2.weight': 'transformer.resblocks.18.ln_2.weight',
            'text_model.encoder.layers.18.mlp.fc1.bias': 'transformer.resblocks.18.mlp.c_fc.bias',
            'text_model.encoder.layers.18.mlp.fc1.weight': 'transformer.resblocks.18.mlp.c_fc.weight',
            'text_model.encoder.layers.18.mlp.fc2.bias': 'transformer.resblocks.18.mlp.c_proj.bias',
            'text_model.encoder.layers.18.mlp.fc2.weight': 'transformer.resblocks.18.mlp.c_proj.weight',
            'text_model.encoder.layers.18.self_attn.out_proj.bias': 'transformer.resblocks.18.attn.out_proj.bias',
            'text_model.encoder.layers.18.self_attn.out_proj.weight': 'transformer.resblocks.18.attn.out_proj.weight',
            'text_model.encoder.layers.19.layer_norm1.bias': 'transformer.resblocks.19.ln_1.bias',
            'text_model.encoder.layers.19.layer_norm1.weight': 'transformer.resblocks.19.ln_1.weight',
            'text_model.encoder.layers.19.layer_norm2.bias': 'transformer.resblocks.19.ln_2.bias',
            'text_model.encoder.layers.19.layer_norm2.weight': 'transformer.resblocks.19.ln_2.weight',
            'text_model.encoder.layers.19.mlp.fc1.bias': 'transformer.resblocks.19.mlp.c_fc.bias',
            'text_model.encoder.layers.19.mlp.fc1.weight': 'transformer.resblocks.19.mlp.c_fc.weight',
            'text_model.encoder.layers.19.mlp.fc2.bias': 'transformer.resblocks.19.mlp.c_proj.bias',
            'text_model.encoder.layers.19.mlp.fc2.weight': 'transformer.resblocks.19.mlp.c_proj.weight',
            'text_model.encoder.layers.19.self_attn.out_proj.bias': 'transformer.resblocks.19.attn.out_proj.bias',
            'text_model.encoder.layers.19.self_attn.out_proj.weight': 'transformer.resblocks.19.attn.out_proj.weight',
            'text_model.encoder.layers.2.layer_norm1.bias': 'transformer.resblocks.2.ln_1.bias',
            'text_model.encoder.layers.2.layer_norm1.weight': 'transformer.resblocks.2.ln_1.weight',
            'text_model.encoder.layers.2.layer_norm2.bias': 'transformer.resblocks.2.ln_2.bias',
            'text_model.encoder.layers.2.layer_norm2.weight': 'transformer.resblocks.2.ln_2.weight',
            'text_model.encoder.layers.2.mlp.fc1.bias': 'transformer.resblocks.2.mlp.c_fc.bias',
            'text_model.encoder.layers.2.mlp.fc1.weight': 'transformer.resblocks.2.mlp.c_fc.weight',
            'text_model.encoder.layers.2.mlp.fc2.bias': 'transformer.resblocks.2.mlp.c_proj.bias',
            'text_model.encoder.layers.2.mlp.fc2.weight': 'transformer.resblocks.2.mlp.c_proj.weight',
            'text_model.encoder.layers.2.self_attn.out_proj.bias': 'transformer.resblocks.2.attn.out_proj.bias',
            'text_model.encoder.layers.2.self_attn.out_proj.weight': 'transformer.resblocks.2.attn.out_proj.weight',
            'text_model.encoder.layers.20.layer_norm1.bias': 'transformer.resblocks.20.ln_1.bias',
            'text_model.encoder.layers.20.layer_norm1.weight': 'transformer.resblocks.20.ln_1.weight',
            'text_model.encoder.layers.20.layer_norm2.bias': 'transformer.resblocks.20.ln_2.bias',
            'text_model.encoder.layers.20.layer_norm2.weight': 'transformer.resblocks.20.ln_2.weight',
            'text_model.encoder.layers.20.mlp.fc1.bias': 'transformer.resblocks.20.mlp.c_fc.bias',
            'text_model.encoder.layers.20.mlp.fc1.weight': 'transformer.resblocks.20.mlp.c_fc.weight',
            'text_model.encoder.layers.20.mlp.fc2.bias': 'transformer.resblocks.20.mlp.c_proj.bias',
            'text_model.encoder.layers.20.mlp.fc2.weight': 'transformer.resblocks.20.mlp.c_proj.weight',
            'text_model.encoder.layers.20.self_attn.out_proj.bias': 'transformer.resblocks.20.attn.out_proj.bias',
            'text_model.encoder.layers.20.self_attn.out_proj.weight': 'transformer.resblocks.20.attn.out_proj.weight',
            'text_model.encoder.layers.21.layer_norm1.bias': 'transformer.resblocks.21.ln_1.bias',
            'text_model.encoder.layers.21.layer_norm1.weight': 'transformer.resblocks.21.ln_1.weight',
            'text_model.encoder.layers.21.layer_norm2.bias': 'transformer.resblocks.21.ln_2.bias',
            'text_model.encoder.layers.21.layer_norm2.weight': 'transformer.resblocks.21.ln_2.weight',
            'text_model.encoder.layers.21.mlp.fc1.bias': 'transformer.resblocks.21.mlp.c_fc.bias',
            'text_model.encoder.layers.21.mlp.fc1.weight': 'transformer.resblocks.21.mlp.c_fc.weight',
            'text_model.encoder.layers.21.mlp.fc2.bias': 'transformer.resblocks.21.mlp.c_proj.bias',
            'text_model.encoder.layers.21.mlp.fc2.weight': 'transformer.resblocks.21.mlp.c_proj.weight',
            'text_model.encoder.layers.21.self_attn.out_proj.bias': 'transformer.resblocks.21.attn.out_proj.bias',
            'text_model.encoder.layers.21.self_attn.out_proj.weight': 'transformer.resblocks.21.attn.out_proj.weight',
            'text_model.encoder.layers.22.layer_norm1.bias': 'transformer.resblocks.22.ln_1.bias',
            'text_model.encoder.layers.22.layer_norm1.weight': 'transformer.resblocks.22.ln_1.weight',
            'text_model.encoder.layers.22.layer_norm2.bias': 'transformer.resblocks.22.ln_2.bias',
            'text_model.encoder.layers.22.layer_norm2.weight': 'transformer.resblocks.22.ln_2.weight',
            'text_model.encoder.layers.22.mlp.fc1.bias': 'transformer.resblocks.22.mlp.c_fc.bias',
            'text_model.encoder.layers.22.mlp.fc1.weight': 'transformer.resblocks.22.mlp.c_fc.weight',
            'text_model.encoder.layers.22.mlp.fc2.bias': 'transformer.resblocks.22.mlp.c_proj.bias',
            'text_model.encoder.layers.22.mlp.fc2.weight': 'transformer.resblocks.22.mlp.c_proj.weight',
            'text_model.encoder.layers.22.self_attn.out_proj.bias': 'transformer.resblocks.22.attn.out_proj.bias',
            'text_model.encoder.layers.22.self_attn.out_proj.weight': 'transformer.resblocks.22.attn.out_proj.weight',
            'text_model.encoder.layers.23.layer_norm1.bias': 'transformer.resblocks.23.ln_1.bias',
            'text_model.encoder.layers.23.layer_norm1.weight': 'transformer.resblocks.23.ln_1.weight',
            'text_model.encoder.layers.23.layer_norm2.bias': 'transformer.resblocks.23.ln_2.bias',
            'text_model.encoder.layers.23.layer_norm2.weight': 'transformer.resblocks.23.ln_2.weight',
            'text_model.encoder.layers.23.mlp.fc1.bias': 'transformer.resblocks.23.mlp.c_fc.bias',
            'text_model.encoder.layers.23.mlp.fc1.weight': 'transformer.resblocks.23.mlp.c_fc.weight',
            'text_model.encoder.layers.23.mlp.fc2.bias': 'transformer.resblocks.23.mlp.c_proj.bias',
            'text_model.encoder.layers.23.mlp.fc2.weight': 'transformer.resblocks.23.mlp.c_proj.weight',
            'text_model.encoder.layers.23.self_attn.out_proj.bias': 'transformer.resblocks.23.attn.out_proj.bias',
            'text_model.encoder.layers.23.self_attn.out_proj.weight': 'transformer.resblocks.23.attn.out_proj.weight',
            'text_model.encoder.layers.24.layer_norm1.bias': 'transformer.resblocks.24.ln_1.bias',
            'text_model.encoder.layers.24.layer_norm1.weight': 'transformer.resblocks.24.ln_1.weight',
            'text_model.encoder.layers.24.layer_norm2.bias': 'transformer.resblocks.24.ln_2.bias',
            'text_model.encoder.layers.24.layer_norm2.weight': 'transformer.resblocks.24.ln_2.weight',
            'text_model.encoder.layers.24.mlp.fc1.bias': 'transformer.resblocks.24.mlp.c_fc.bias',
            'text_model.encoder.layers.24.mlp.fc1.weight': 'transformer.resblocks.24.mlp.c_fc.weight',
            'text_model.encoder.layers.24.mlp.fc2.bias': 'transformer.resblocks.24.mlp.c_proj.bias',
            'text_model.encoder.layers.24.mlp.fc2.weight': 'transformer.resblocks.24.mlp.c_proj.weight',
            'text_model.encoder.layers.24.self_attn.out_proj.bias': 'transformer.resblocks.24.attn.out_proj.bias',
            'text_model.encoder.layers.24.self_attn.out_proj.weight': 'transformer.resblocks.24.attn.out_proj.weight',
            'text_model.encoder.layers.25.layer_norm1.bias': 'transformer.resblocks.25.ln_1.bias',
            'text_model.encoder.layers.25.layer_norm1.weight': 'transformer.resblocks.25.ln_1.weight',
            'text_model.encoder.layers.25.layer_norm2.bias': 'transformer.resblocks.25.ln_2.bias',
            'text_model.encoder.layers.25.layer_norm2.weight': 'transformer.resblocks.25.ln_2.weight',
            'text_model.encoder.layers.25.mlp.fc1.bias': 'transformer.resblocks.25.mlp.c_fc.bias',
            'text_model.encoder.layers.25.mlp.fc1.weight': 'transformer.resblocks.25.mlp.c_fc.weight',
            'text_model.encoder.layers.25.mlp.fc2.bias': 'transformer.resblocks.25.mlp.c_proj.bias',
            'text_model.encoder.layers.25.mlp.fc2.weight': 'transformer.resblocks.25.mlp.c_proj.weight',
            'text_model.encoder.layers.25.self_attn.out_proj.bias': 'transformer.resblocks.25.attn.out_proj.bias',
            'text_model.encoder.layers.25.self_attn.out_proj.weight': 'transformer.resblocks.25.attn.out_proj.weight',
            'text_model.encoder.layers.26.layer_norm1.bias': 'transformer.resblocks.26.ln_1.bias',
            'text_model.encoder.layers.26.layer_norm1.weight': 'transformer.resblocks.26.ln_1.weight',
            'text_model.encoder.layers.26.layer_norm2.bias': 'transformer.resblocks.26.ln_2.bias',
            'text_model.encoder.layers.26.layer_norm2.weight': 'transformer.resblocks.26.ln_2.weight',
            'text_model.encoder.layers.26.mlp.fc1.bias': 'transformer.resblocks.26.mlp.c_fc.bias',
            'text_model.encoder.layers.26.mlp.fc1.weight': 'transformer.resblocks.26.mlp.c_fc.weight',
            'text_model.encoder.layers.26.mlp.fc2.bias': 'transformer.resblocks.26.mlp.c_proj.bias',
            'text_model.encoder.layers.26.mlp.fc2.weight': 'transformer.resblocks.26.mlp.c_proj.weight',
            'text_model.encoder.layers.26.self_attn.out_proj.bias': 'transformer.resblocks.26.attn.out_proj.bias',
            'text_model.encoder.layers.26.self_attn.out_proj.weight': 'transformer.resblocks.26.attn.out_proj.weight',
            'text_model.encoder.layers.27.layer_norm1.bias': 'transformer.resblocks.27.ln_1.bias',
            'text_model.encoder.layers.27.layer_norm1.weight': 'transformer.resblocks.27.ln_1.weight',
            'text_model.encoder.layers.27.layer_norm2.bias': 'transformer.resblocks.27.ln_2.bias',
            'text_model.encoder.layers.27.layer_norm2.weight': 'transformer.resblocks.27.ln_2.weight',
            'text_model.encoder.layers.27.mlp.fc1.bias': 'transformer.resblocks.27.mlp.c_fc.bias',
            'text_model.encoder.layers.27.mlp.fc1.weight': 'transformer.resblocks.27.mlp.c_fc.weight',
            'text_model.encoder.layers.27.mlp.fc2.bias': 'transformer.resblocks.27.mlp.c_proj.bias',
            'text_model.encoder.layers.27.mlp.fc2.weight': 'transformer.resblocks.27.mlp.c_proj.weight',
            'text_model.encoder.layers.27.self_attn.out_proj.bias': 'transformer.resblocks.27.attn.out_proj.bias',
            'text_model.encoder.layers.27.self_attn.out_proj.weight': 'transformer.resblocks.27.attn.out_proj.weight',
            'text_model.encoder.layers.28.layer_norm1.bias': 'transformer.resblocks.28.ln_1.bias',
            'text_model.encoder.layers.28.layer_norm1.weight': 'transformer.resblocks.28.ln_1.weight',
            'text_model.encoder.layers.28.layer_norm2.bias': 'transformer.resblocks.28.ln_2.bias',
            'text_model.encoder.layers.28.layer_norm2.weight': 'transformer.resblocks.28.ln_2.weight',
            'text_model.encoder.layers.28.mlp.fc1.bias': 'transformer.resblocks.28.mlp.c_fc.bias',
            'text_model.encoder.layers.28.mlp.fc1.weight': 'transformer.resblocks.28.mlp.c_fc.weight',
            'text_model.encoder.layers.28.mlp.fc2.bias': 'transformer.resblocks.28.mlp.c_proj.bias',
            'text_model.encoder.layers.28.mlp.fc2.weight': 'transformer.resblocks.28.mlp.c_proj.weight',
            'text_model.encoder.layers.28.self_attn.out_proj.bias': 'transformer.resblocks.28.attn.out_proj.bias',
            'text_model.encoder.layers.28.self_attn.out_proj.weight': 'transformer.resblocks.28.attn.out_proj.weight',
            'text_model.encoder.layers.29.layer_norm1.bias': 'transformer.resblocks.29.ln_1.bias',
            'text_model.encoder.layers.29.layer_norm1.weight': 'transformer.resblocks.29.ln_1.weight',
            'text_model.encoder.layers.29.layer_norm2.bias': 'transformer.resblocks.29.ln_2.bias',
            'text_model.encoder.layers.29.layer_norm2.weight': 'transformer.resblocks.29.ln_2.weight',
            'text_model.encoder.layers.29.mlp.fc1.bias': 'transformer.resblocks.29.mlp.c_fc.bias',
            'text_model.encoder.layers.29.mlp.fc1.weight': 'transformer.resblocks.29.mlp.c_fc.weight',
            'text_model.encoder.layers.29.mlp.fc2.bias': 'transformer.resblocks.29.mlp.c_proj.bias',
            'text_model.encoder.layers.29.mlp.fc2.weight': 'transformer.resblocks.29.mlp.c_proj.weight',
            'text_model.encoder.layers.29.self_attn.out_proj.bias': 'transformer.resblocks.29.attn.out_proj.bias',
            'text_model.encoder.layers.29.self_attn.out_proj.weight': 'transformer.resblocks.29.attn.out_proj.weight',
            'text_model.encoder.layers.3.layer_norm1.bias': 'transformer.resblocks.3.ln_1.bias',
            'text_model.encoder.layers.3.layer_norm1.weight': 'transformer.resblocks.3.ln_1.weight',
            'text_model.encoder.layers.3.layer_norm2.bias': 'transformer.resblocks.3.ln_2.bias',
            'text_model.encoder.layers.3.layer_norm2.weight': 'transformer.resblocks.3.ln_2.weight',
            'text_model.encoder.layers.3.mlp.fc1.bias': 'transformer.resblocks.3.mlp.c_fc.bias',
            'text_model.encoder.layers.3.mlp.fc1.weight': 'transformer.resblocks.3.mlp.c_fc.weight',
            'text_model.encoder.layers.3.mlp.fc2.bias': 'transformer.resblocks.3.mlp.c_proj.bias',
            'text_model.encoder.layers.3.mlp.fc2.weight': 'transformer.resblocks.3.mlp.c_proj.weight',
            'text_model.encoder.layers.3.self_attn.out_proj.bias': 'transformer.resblocks.3.attn.out_proj.bias',
            'text_model.encoder.layers.3.self_attn.out_proj.weight': 'transformer.resblocks.3.attn.out_proj.weight',
            'text_model.encoder.layers.30.layer_norm1.bias': 'transformer.resblocks.30.ln_1.bias',
            'text_model.encoder.layers.30.layer_norm1.weight': 'transformer.resblocks.30.ln_1.weight',
            'text_model.encoder.layers.30.layer_norm2.bias': 'transformer.resblocks.30.ln_2.bias',
            'text_model.encoder.layers.30.layer_norm2.weight': 'transformer.resblocks.30.ln_2.weight',
            'text_model.encoder.layers.30.mlp.fc1.bias': 'transformer.resblocks.30.mlp.c_fc.bias',
            'text_model.encoder.layers.30.mlp.fc1.weight': 'transformer.resblocks.30.mlp.c_fc.weight',
            'text_model.encoder.layers.30.mlp.fc2.bias': 'transformer.resblocks.30.mlp.c_proj.bias',
            'text_model.encoder.layers.30.mlp.fc2.weight': 'transformer.resblocks.30.mlp.c_proj.weight',
            'text_model.encoder.layers.30.self_attn.out_proj.bias': 'transformer.resblocks.30.attn.out_proj.bias',
            'text_model.encoder.layers.30.self_attn.out_proj.weight': 'transformer.resblocks.30.attn.out_proj.weight',
            'text_model.encoder.layers.31.layer_norm1.bias': 'transformer.resblocks.31.ln_1.bias',
            'text_model.encoder.layers.31.layer_norm1.weight': 'transformer.resblocks.31.ln_1.weight',
            'text_model.encoder.layers.31.layer_norm2.bias': 'transformer.resblocks.31.ln_2.bias',
            'text_model.encoder.layers.31.layer_norm2.weight': 'transformer.resblocks.31.ln_2.weight',
            'text_model.encoder.layers.31.mlp.fc1.bias': 'transformer.resblocks.31.mlp.c_fc.bias',
            'text_model.encoder.layers.31.mlp.fc1.weight': 'transformer.resblocks.31.mlp.c_fc.weight',
            'text_model.encoder.layers.31.mlp.fc2.bias': 'transformer.resblocks.31.mlp.c_proj.bias',
            'text_model.encoder.layers.31.mlp.fc2.weight': 'transformer.resblocks.31.mlp.c_proj.weight',
            'text_model.encoder.layers.31.self_attn.out_proj.bias': 'transformer.resblocks.31.attn.out_proj.bias',
            'text_model.encoder.layers.31.self_attn.out_proj.weight': 'transformer.resblocks.31.attn.out_proj.weight',
            'text_model.encoder.layers.4.layer_norm1.bias': 'transformer.resblocks.4.ln_1.bias',
            'text_model.encoder.layers.4.layer_norm1.weight': 'transformer.resblocks.4.ln_1.weight',
            'text_model.encoder.layers.4.layer_norm2.bias': 'transformer.resblocks.4.ln_2.bias',
            'text_model.encoder.layers.4.layer_norm2.weight': 'transformer.resblocks.4.ln_2.weight',
            'text_model.encoder.layers.4.mlp.fc1.bias': 'transformer.resblocks.4.mlp.c_fc.bias',
            'text_model.encoder.layers.4.mlp.fc1.weight': 'transformer.resblocks.4.mlp.c_fc.weight',
            'text_model.encoder.layers.4.mlp.fc2.bias': 'transformer.resblocks.4.mlp.c_proj.bias',
            'text_model.encoder.layers.4.mlp.fc2.weight': 'transformer.resblocks.4.mlp.c_proj.weight',
            'text_model.encoder.layers.4.self_attn.out_proj.bias': 'transformer.resblocks.4.attn.out_proj.bias',
            'text_model.encoder.layers.4.self_attn.out_proj.weight': 'transformer.resblocks.4.attn.out_proj.weight',
            'text_model.encoder.layers.5.layer_norm1.bias': 'transformer.resblocks.5.ln_1.bias',
            'text_model.encoder.layers.5.layer_norm1.weight': 'transformer.resblocks.5.ln_1.weight',
            'text_model.encoder.layers.5.layer_norm2.bias': 'transformer.resblocks.5.ln_2.bias',
            'text_model.encoder.layers.5.layer_norm2.weight': 'transformer.resblocks.5.ln_2.weight',
            'text_model.encoder.layers.5.mlp.fc1.bias': 'transformer.resblocks.5.mlp.c_fc.bias',
            'text_model.encoder.layers.5.mlp.fc1.weight': 'transformer.resblocks.5.mlp.c_fc.weight',
            'text_model.encoder.layers.5.mlp.fc2.bias': 'transformer.resblocks.5.mlp.c_proj.bias',
            'text_model.encoder.layers.5.mlp.fc2.weight': 'transformer.resblocks.5.mlp.c_proj.weight',
            'text_model.encoder.layers.5.self_attn.out_proj.bias': 'transformer.resblocks.5.attn.out_proj.bias',
            'text_model.encoder.layers.5.self_attn.out_proj.weight': 'transformer.resblocks.5.attn.out_proj.weight',
            'text_model.encoder.layers.6.layer_norm1.bias': 'transformer.resblocks.6.ln_1.bias',
            'text_model.encoder.layers.6.layer_norm1.weight': 'transformer.resblocks.6.ln_1.weight',
            'text_model.encoder.layers.6.layer_norm2.bias': 'transformer.resblocks.6.ln_2.bias',
            'text_model.encoder.layers.6.layer_norm2.weight': 'transformer.resblocks.6.ln_2.weight',
            'text_model.encoder.layers.6.mlp.fc1.bias': 'transformer.resblocks.6.mlp.c_fc.bias',
            'text_model.encoder.layers.6.mlp.fc1.weight': 'transformer.resblocks.6.mlp.c_fc.weight',
            'text_model.encoder.layers.6.mlp.fc2.bias': 'transformer.resblocks.6.mlp.c_proj.bias',
            'text_model.encoder.layers.6.mlp.fc2.weight': 'transformer.resblocks.6.mlp.c_proj.weight',
            'text_model.encoder.layers.6.self_attn.out_proj.bias': 'transformer.resblocks.6.attn.out_proj.bias',
            'text_model.encoder.layers.6.self_attn.out_proj.weight': 'transformer.resblocks.6.attn.out_proj.weight',
            'text_model.encoder.layers.7.layer_norm1.bias': 'transformer.resblocks.7.ln_1.bias',
            'text_model.encoder.layers.7.layer_norm1.weight': 'transformer.resblocks.7.ln_1.weight',
            'text_model.encoder.layers.7.layer_norm2.bias': 'transformer.resblocks.7.ln_2.bias',
            'text_model.encoder.layers.7.layer_norm2.weight': 'transformer.resblocks.7.ln_2.weight',
            'text_model.encoder.layers.7.mlp.fc1.bias': 'transformer.resblocks.7.mlp.c_fc.bias',
            'text_model.encoder.layers.7.mlp.fc1.weight': 'transformer.resblocks.7.mlp.c_fc.weight',
            'text_model.encoder.layers.7.mlp.fc2.bias': 'transformer.resblocks.7.mlp.c_proj.bias',
            'text_model.encoder.layers.7.mlp.fc2.weight': 'transformer.resblocks.7.mlp.c_proj.weight',
            'text_model.encoder.layers.7.self_attn.out_proj.bias': 'transformer.resblocks.7.attn.out_proj.bias',
            'text_model.encoder.layers.7.self_attn.out_proj.weight': 'transformer.resblocks.7.attn.out_proj.weight',
            'text_model.encoder.layers.8.layer_norm1.bias': 'transformer.resblocks.8.ln_1.bias',
            'text_model.encoder.layers.8.layer_norm1.weight': 'transformer.resblocks.8.ln_1.weight',
            'text_model.encoder.layers.8.layer_norm2.bias': 'transformer.resblocks.8.ln_2.bias',
            'text_model.encoder.layers.8.layer_norm2.weight': 'transformer.resblocks.8.ln_2.weight',
            'text_model.encoder.layers.8.mlp.fc1.bias': 'transformer.resblocks.8.mlp.c_fc.bias',
            'text_model.encoder.layers.8.mlp.fc1.weight': 'transformer.resblocks.8.mlp.c_fc.weight',
            'text_model.encoder.layers.8.mlp.fc2.bias': 'transformer.resblocks.8.mlp.c_proj.bias',
            'text_model.encoder.layers.8.mlp.fc2.weight': 'transformer.resblocks.8.mlp.c_proj.weight',
            'text_model.encoder.layers.8.self_attn.out_proj.bias': 'transformer.resblocks.8.attn.out_proj.bias',
            'text_model.encoder.layers.8.self_attn.out_proj.weight': 'transformer.resblocks.8.attn.out_proj.weight',
            'text_model.encoder.layers.9.layer_norm1.bias': 'transformer.resblocks.9.ln_1.bias',
            'text_model.encoder.layers.9.layer_norm1.weight': 'transformer.resblocks.9.ln_1.weight',
            'text_model.encoder.layers.9.layer_norm2.bias': 'transformer.resblocks.9.ln_2.bias',
            'text_model.encoder.layers.9.layer_norm2.weight': 'transformer.resblocks.9.ln_2.weight',
            'text_model.encoder.layers.9.mlp.fc1.bias': 'transformer.resblocks.9.mlp.c_fc.bias',
            'text_model.encoder.layers.9.mlp.fc1.weight': 'transformer.resblocks.9.mlp.c_fc.weight',
            'text_model.encoder.layers.9.mlp.fc2.bias': 'transformer.resblocks.9.mlp.c_proj.bias',
            'text_model.encoder.layers.9.mlp.fc2.weight': 'transformer.resblocks.9.mlp.c_proj.weight',
            'text_model.encoder.layers.9.self_attn.out_proj.bias': 'transformer.resblocks.9.attn.out_proj.bias',
            'text_model.encoder.layers.9.self_attn.out_proj.weight': 'transformer.resblocks.9.attn.out_proj.weight',
            'text_model.final_layer_norm.bias': 'ln_final.bias',
            'text_model.final_layer_norm.weight': 'ln_final.weight', 'text_projection.weight': 'text_projection.weight',
            'text_model.encoder.layers.0.self_attn.q_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
            'text_model.encoder.layers.0.self_attn.k_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
            'text_model.encoder.layers.0.self_attn.v_proj.weight': 'transformer.resblocks.0.attn.in_proj_weight',
            'text_model.encoder.layers.1.self_attn.q_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
            'text_model.encoder.layers.1.self_attn.k_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
            'text_model.encoder.layers.1.self_attn.v_proj.weight': 'transformer.resblocks.1.attn.in_proj_weight',
            'text_model.encoder.layers.10.self_attn.q_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
            'text_model.encoder.layers.10.self_attn.k_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
            'text_model.encoder.layers.10.self_attn.v_proj.weight': 'transformer.resblocks.10.attn.in_proj_weight',
            'text_model.encoder.layers.11.self_attn.q_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
            'text_model.encoder.layers.11.self_attn.k_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
            'text_model.encoder.layers.11.self_attn.v_proj.weight': 'transformer.resblocks.11.attn.in_proj_weight',
            'text_model.encoder.layers.12.self_attn.q_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
            'text_model.encoder.layers.12.self_attn.k_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
            'text_model.encoder.layers.12.self_attn.v_proj.weight': 'transformer.resblocks.12.attn.in_proj_weight',
            'text_model.encoder.layers.13.self_attn.q_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
            'text_model.encoder.layers.13.self_attn.k_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
            'text_model.encoder.layers.13.self_attn.v_proj.weight': 'transformer.resblocks.13.attn.in_proj_weight',
            'text_model.encoder.layers.14.self_attn.q_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
            'text_model.encoder.layers.14.self_attn.k_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
            'text_model.encoder.layers.14.self_attn.v_proj.weight': 'transformer.resblocks.14.attn.in_proj_weight',
            'text_model.encoder.layers.15.self_attn.q_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
            'text_model.encoder.layers.15.self_attn.k_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
            'text_model.encoder.layers.15.self_attn.v_proj.weight': 'transformer.resblocks.15.attn.in_proj_weight',
            'text_model.encoder.layers.16.self_attn.q_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
            'text_model.encoder.layers.16.self_attn.k_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
            'text_model.encoder.layers.16.self_attn.v_proj.weight': 'transformer.resblocks.16.attn.in_proj_weight',
            'text_model.encoder.layers.17.self_attn.q_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
            'text_model.encoder.layers.17.self_attn.k_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
            'text_model.encoder.layers.17.self_attn.v_proj.weight': 'transformer.resblocks.17.attn.in_proj_weight',
            'text_model.encoder.layers.18.self_attn.q_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
            'text_model.encoder.layers.18.self_attn.k_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
            'text_model.encoder.layers.18.self_attn.v_proj.weight': 'transformer.resblocks.18.attn.in_proj_weight',
            'text_model.encoder.layers.19.self_attn.q_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
            'text_model.encoder.layers.19.self_attn.k_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
            'text_model.encoder.layers.19.self_attn.v_proj.weight': 'transformer.resblocks.19.attn.in_proj_weight',
            'text_model.encoder.layers.2.self_attn.q_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
            'text_model.encoder.layers.2.self_attn.k_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
            'text_model.encoder.layers.2.self_attn.v_proj.weight': 'transformer.resblocks.2.attn.in_proj_weight',
            'text_model.encoder.layers.20.self_attn.q_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
            'text_model.encoder.layers.20.self_attn.k_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
            'text_model.encoder.layers.20.self_attn.v_proj.weight': 'transformer.resblocks.20.attn.in_proj_weight',
            'text_model.encoder.layers.21.self_attn.q_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
            'text_model.encoder.layers.21.self_attn.k_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
            'text_model.encoder.layers.21.self_attn.v_proj.weight': 'transformer.resblocks.21.attn.in_proj_weight',
            'text_model.encoder.layers.22.self_attn.q_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
            'text_model.encoder.layers.22.self_attn.k_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
            'text_model.encoder.layers.22.self_attn.v_proj.weight': 'transformer.resblocks.22.attn.in_proj_weight',
            'text_model.encoder.layers.23.self_attn.q_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
            'text_model.encoder.layers.23.self_attn.k_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
            'text_model.encoder.layers.23.self_attn.v_proj.weight': 'transformer.resblocks.23.attn.in_proj_weight',
            'text_model.encoder.layers.24.self_attn.q_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
            'text_model.encoder.layers.24.self_attn.k_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
            'text_model.encoder.layers.24.self_attn.v_proj.weight': 'transformer.resblocks.24.attn.in_proj_weight',
            'text_model.encoder.layers.25.self_attn.q_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
            'text_model.encoder.layers.25.self_attn.k_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
            'text_model.encoder.layers.25.self_attn.v_proj.weight': 'transformer.resblocks.25.attn.in_proj_weight',
            'text_model.encoder.layers.26.self_attn.q_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
            'text_model.encoder.layers.26.self_attn.k_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
            'text_model.encoder.layers.26.self_attn.v_proj.weight': 'transformer.resblocks.26.attn.in_proj_weight',
            'text_model.encoder.layers.27.self_attn.q_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
            'text_model.encoder.layers.27.self_attn.k_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
            'text_model.encoder.layers.27.self_attn.v_proj.weight': 'transformer.resblocks.27.attn.in_proj_weight',
            'text_model.encoder.layers.28.self_attn.q_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
            'text_model.encoder.layers.28.self_attn.k_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
            'text_model.encoder.layers.28.self_attn.v_proj.weight': 'transformer.resblocks.28.attn.in_proj_weight',
            'text_model.encoder.layers.29.self_attn.q_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
            'text_model.encoder.layers.29.self_attn.k_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
            'text_model.encoder.layers.29.self_attn.v_proj.weight': 'transformer.resblocks.29.attn.in_proj_weight',
            'text_model.encoder.layers.3.self_attn.q_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
            'text_model.encoder.layers.3.self_attn.k_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
            'text_model.encoder.layers.3.self_attn.v_proj.weight': 'transformer.resblocks.3.attn.in_proj_weight',
            'text_model.encoder.layers.30.self_attn.q_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
            'text_model.encoder.layers.30.self_attn.k_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
            'text_model.encoder.layers.30.self_attn.v_proj.weight': 'transformer.resblocks.30.attn.in_proj_weight',
            'text_model.encoder.layers.31.self_attn.q_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
            'text_model.encoder.layers.31.self_attn.k_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
            'text_model.encoder.layers.31.self_attn.v_proj.weight': 'transformer.resblocks.31.attn.in_proj_weight',
            'text_model.encoder.layers.4.self_attn.q_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
            'text_model.encoder.layers.4.self_attn.k_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
            'text_model.encoder.layers.4.self_attn.v_proj.weight': 'transformer.resblocks.4.attn.in_proj_weight',
            'text_model.encoder.layers.5.self_attn.q_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
            'text_model.encoder.layers.5.self_attn.k_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
            'text_model.encoder.layers.5.self_attn.v_proj.weight': 'transformer.resblocks.5.attn.in_proj_weight',
            'text_model.encoder.layers.6.self_attn.q_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
            'text_model.encoder.layers.6.self_attn.k_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
            'text_model.encoder.layers.6.self_attn.v_proj.weight': 'transformer.resblocks.6.attn.in_proj_weight',
            'text_model.encoder.layers.7.self_attn.q_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
            'text_model.encoder.layers.7.self_attn.k_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
            'text_model.encoder.layers.7.self_attn.v_proj.weight': 'transformer.resblocks.7.attn.in_proj_weight',
            'text_model.encoder.layers.8.self_attn.q_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
            'text_model.encoder.layers.8.self_attn.k_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
            'text_model.encoder.layers.8.self_attn.v_proj.weight': 'transformer.resblocks.8.attn.in_proj_weight',
            'text_model.encoder.layers.9.self_attn.q_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
            'text_model.encoder.layers.9.self_attn.k_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
            'text_model.encoder.layers.9.self_attn.v_proj.weight': 'transformer.resblocks.9.attn.in_proj_weight',
            'text_model.encoder.layers.0.self_attn.q_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
            'text_model.encoder.layers.0.self_attn.k_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
            'text_model.encoder.layers.0.self_attn.v_proj.bias': 'transformer.resblocks.0.attn.in_proj_bias',
            'text_model.encoder.layers.1.self_attn.q_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
            'text_model.encoder.layers.1.self_attn.k_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
            'text_model.encoder.layers.1.self_attn.v_proj.bias': 'transformer.resblocks.1.attn.in_proj_bias',
            'text_model.encoder.layers.10.self_attn.q_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
            'text_model.encoder.layers.10.self_attn.k_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
            'text_model.encoder.layers.10.self_attn.v_proj.bias': 'transformer.resblocks.10.attn.in_proj_bias',
            'text_model.encoder.layers.11.self_attn.q_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
            'text_model.encoder.layers.11.self_attn.k_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
            'text_model.encoder.layers.11.self_attn.v_proj.bias': 'transformer.resblocks.11.attn.in_proj_bias',
            'text_model.encoder.layers.12.self_attn.q_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
            'text_model.encoder.layers.12.self_attn.k_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
            'text_model.encoder.layers.12.self_attn.v_proj.bias': 'transformer.resblocks.12.attn.in_proj_bias',
            'text_model.encoder.layers.13.self_attn.q_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
            'text_model.encoder.layers.13.self_attn.k_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
            'text_model.encoder.layers.13.self_attn.v_proj.bias': 'transformer.resblocks.13.attn.in_proj_bias',
            'text_model.encoder.layers.14.self_attn.q_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
            'text_model.encoder.layers.14.self_attn.k_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
            'text_model.encoder.layers.14.self_attn.v_proj.bias': 'transformer.resblocks.14.attn.in_proj_bias',
            'text_model.encoder.layers.15.self_attn.q_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
            'text_model.encoder.layers.15.self_attn.k_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
            'text_model.encoder.layers.15.self_attn.v_proj.bias': 'transformer.resblocks.15.attn.in_proj_bias',
            'text_model.encoder.layers.16.self_attn.q_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
            'text_model.encoder.layers.16.self_attn.k_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
            'text_model.encoder.layers.16.self_attn.v_proj.bias': 'transformer.resblocks.16.attn.in_proj_bias',
            'text_model.encoder.layers.17.self_attn.q_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
            'text_model.encoder.layers.17.self_attn.k_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
            'text_model.encoder.layers.17.self_attn.v_proj.bias': 'transformer.resblocks.17.attn.in_proj_bias',
            'text_model.encoder.layers.18.self_attn.q_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
            'text_model.encoder.layers.18.self_attn.k_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
            'text_model.encoder.layers.18.self_attn.v_proj.bias': 'transformer.resblocks.18.attn.in_proj_bias',
            'text_model.encoder.layers.19.self_attn.q_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
            'text_model.encoder.layers.19.self_attn.k_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
            'text_model.encoder.layers.19.self_attn.v_proj.bias': 'transformer.resblocks.19.attn.in_proj_bias',
            'text_model.encoder.layers.2.self_attn.q_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
            'text_model.encoder.layers.2.self_attn.k_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
            'text_model.encoder.layers.2.self_attn.v_proj.bias': 'transformer.resblocks.2.attn.in_proj_bias',
            'text_model.encoder.layers.20.self_attn.q_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
            'text_model.encoder.layers.20.self_attn.k_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
            'text_model.encoder.layers.20.self_attn.v_proj.bias': 'transformer.resblocks.20.attn.in_proj_bias',
            'text_model.encoder.layers.21.self_attn.q_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
            'text_model.encoder.layers.21.self_attn.k_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
            'text_model.encoder.layers.21.self_attn.v_proj.bias': 'transformer.resblocks.21.attn.in_proj_bias',
            'text_model.encoder.layers.22.self_attn.q_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
            'text_model.encoder.layers.22.self_attn.k_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
            'text_model.encoder.layers.22.self_attn.v_proj.bias': 'transformer.resblocks.22.attn.in_proj_bias',
            'text_model.encoder.layers.23.self_attn.q_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
            'text_model.encoder.layers.23.self_attn.k_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
            'text_model.encoder.layers.23.self_attn.v_proj.bias': 'transformer.resblocks.23.attn.in_proj_bias',
            'text_model.encoder.layers.24.self_attn.q_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
            'text_model.encoder.layers.24.self_attn.k_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
            'text_model.encoder.layers.24.self_attn.v_proj.bias': 'transformer.resblocks.24.attn.in_proj_bias',
            'text_model.encoder.layers.25.self_attn.q_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
            'text_model.encoder.layers.25.self_attn.k_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
            'text_model.encoder.layers.25.self_attn.v_proj.bias': 'transformer.resblocks.25.attn.in_proj_bias',
            'text_model.encoder.layers.26.self_attn.q_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
            'text_model.encoder.layers.26.self_attn.k_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
            'text_model.encoder.layers.26.self_attn.v_proj.bias': 'transformer.resblocks.26.attn.in_proj_bias',
            'text_model.encoder.layers.27.self_attn.q_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
            'text_model.encoder.layers.27.self_attn.k_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
            'text_model.encoder.layers.27.self_attn.v_proj.bias': 'transformer.resblocks.27.attn.in_proj_bias',
            'text_model.encoder.layers.28.self_attn.q_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
            'text_model.encoder.layers.28.self_attn.k_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
            'text_model.encoder.layers.28.self_attn.v_proj.bias': 'transformer.resblocks.28.attn.in_proj_bias',
            'text_model.encoder.layers.29.self_attn.q_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
            'text_model.encoder.layers.29.self_attn.k_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
            'text_model.encoder.layers.29.self_attn.v_proj.bias': 'transformer.resblocks.29.attn.in_proj_bias',
            'text_model.encoder.layers.3.self_attn.q_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
            'text_model.encoder.layers.3.self_attn.k_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
            'text_model.encoder.layers.3.self_attn.v_proj.bias': 'transformer.resblocks.3.attn.in_proj_bias',
            'text_model.encoder.layers.30.self_attn.q_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
            'text_model.encoder.layers.30.self_attn.k_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
            'text_model.encoder.layers.30.self_attn.v_proj.bias': 'transformer.resblocks.30.attn.in_proj_bias',
            'text_model.encoder.layers.31.self_attn.q_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
            'text_model.encoder.layers.31.self_attn.k_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
            'text_model.encoder.layers.31.self_attn.v_proj.bias': 'transformer.resblocks.31.attn.in_proj_bias',
            'text_model.encoder.layers.4.self_attn.q_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
            'text_model.encoder.layers.4.self_attn.k_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
            'text_model.encoder.layers.4.self_attn.v_proj.bias': 'transformer.resblocks.4.attn.in_proj_bias',
            'text_model.encoder.layers.5.self_attn.q_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
            'text_model.encoder.layers.5.self_attn.k_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
            'text_model.encoder.layers.5.self_attn.v_proj.bias': 'transformer.resblocks.5.attn.in_proj_bias',
            'text_model.encoder.layers.6.self_attn.q_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
            'text_model.encoder.layers.6.self_attn.k_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
            'text_model.encoder.layers.6.self_attn.v_proj.bias': 'transformer.resblocks.6.attn.in_proj_bias',
            'text_model.encoder.layers.7.self_attn.q_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
            'text_model.encoder.layers.7.self_attn.k_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
            'text_model.encoder.layers.7.self_attn.v_proj.bias': 'transformer.resblocks.7.attn.in_proj_bias',
            'text_model.encoder.layers.8.self_attn.q_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
            'text_model.encoder.layers.8.self_attn.k_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
            'text_model.encoder.layers.8.self_attn.v_proj.bias': 'transformer.resblocks.8.attn.in_proj_bias',
            'text_model.encoder.layers.9.self_attn.q_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias',
            'text_model.encoder.layers.9.self_attn.k_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias',
            'text_model.encoder.layers.9.self_attn.v_proj.bias': 'transformer.resblocks.9.attn.in_proj_bias'}

# import yaml
#
#
# prefix = "model.diffusion_model."
# unet = {prefix + k: v for k, v in unet.items()}
# with open('torch_key_unet.yaml', 'w') as file:
#     yaml.dump(list(unet.keys()), file, default_flow_style=False)
# with open('hf_key_unet.yaml', 'w') as file:
#     yaml.dump(list(unet.values()), file, default_flow_style=False)

# -----------------important --------------------------------
prefix = "model.diffusion_model."
unet = { k: prefix +v for k, v in unet.items()}
with open("hf_key_unet.yaml", "w") as file:
    for key in unet.keys():
        file.write(str(key) + "\n")
with open("torch_key_unet.yaml", "w") as file:
    for value in unet.values():
        file.write(str(value) + "\n")


prefix = "first_stage_model."
vae = { k: prefix +v for k, v in vae.items()}
with open("hf_key_vae.yaml", "w") as file:
    for key in vae.keys():
        file.write(str(key) + "\n")
with open("torch_key_vae.yaml", "w") as file:
    for value in vae.values():
        file.write(str(value) + "\n")

prefix = "conditioner.embedders.0.transformer."
# text1 = { k: prefix +v for k, v in text1.items()}
with open("hf_key_text1.yaml", "w") as file:
    for key in text1:
        file.write(str(key) + "\n")
with open("torch_key_text1.yaml", "w") as file:
    for value in text1:
        file.write((prefix+str(value)) + "\n")


prefix = "conditioner.embedders.1.model."
text2 = { k: prefix +v for k, v in text2.items()}
with open("hf_key_text2.yaml", "w") as file:
    for key in text2.keys():
        file.write(str(key) + "\n")
with open("torch_key_text2.yaml", "w") as file:
    for value in text2.values():
        file.write(str(value) + "\n")


#
#
# print(len(vae))
# print(len(text1))
# print(type(text1))
# print(type(unet))
# print(type(vae))
#
#
#
#
# print(len(text2))
#
#
#
# prefix = "conditioner.embedders.1.model."
# text2map = {prefix + k: v for k, v in text2map.items()}
# torch_key= []
# with open('torch_key_base.yaml', 'r') as file:
#     for line in file:
#         torch_key.append(line.strip())
#
# text2list = list(text2map.keys())
# print((text2list)[:50])
#
# print(len(set(text2list)-set(torch_key)))
# print(len(set(torch_key)-set(text2list)))


# unet 的key加上"model.diffusion_model."
# vae的key加上"first_stage_model."
# text1 加上"conditioner.embedders.0.transformer."
# text2 加上"conditioner.embedders.1.model."

# 不用对换key和value值 刚好就是 直接查询

# def get_map(key_file, value_file):
#     key_map = {}
#     with open(key_file, 'r') as key_file, open(value_file, 'r') as value_file:
#         keys = key_file.readlines()
#         values = value_file.readlines()
#
#         for key, value in zip(keys, values):
#             key = key.strip()
#             value = value.strip()
#             key_map[key] = value
#     return key_map
#
#
# def convert(state_dict, module_map):
#     mapping = module_map
#     new_state_dict = {hf_name: state_dict[sd_name] for sd_name, hf_name in mapping.items()}
#     return new_state_dict
#
#
# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--model_path", default=None, type=str, required=True, help="Path to the model to convert.")
#     parser.add_argument("--checkpoint_path", default=None, type=str, required=True, help="Path to the output model.")
#     parser.add_argument("--use_safetensors", action="store_true", help="Save weights use safetensors, default is ckpt.")
#     parser.add_argument("--half", action="store_true", help="Save weights in half precision.")
#     args = parser.parse_args()
#
#     key_file = 'torch_key_unet.yaml'  # 替换为实际的键文件名
#     value_file = 'hf_key_unet.yaml'  # 替换为实际的值文件名
#     unet_map = get_map('torch_key_unet.yaml', 'hf_key_unet.yaml')
#     vae_map = get_map('torch_key_vae.yaml', 'hf_key_vae.yaml')
#     text1_map = get_map('torch_key_text1.yaml', 'hf_key_text1.yaml')
#     text2_map = get_map('torch_key_text2.yaml', 'hf_key_text2.yaml')
#
#     unet = convert(args.model_path, unet_map)
#     vae = convert(args.model_path, vae_map)
#     text1 = convert(args.model_path, text1_map)
#     text2 = convert(args.model_path, text2_map)
#
#     if args.half:
#         unet = {k: v.half() for k, v in unet.items()}
#         vae = {k: v.half() for k, v in vae.items()}
#         text1 = {k: v.half() for k, v in text1.items()}
#         text2 = {k: v.half() for k, v in text2.items()}
#
#     if args.use_safetensors:
#         save_file(unet, args.output_path + "/unet.safetensors")
#         save_file(vae, args.output_path + "/vae.safetensors")
#         save_file(text1, args.output_path + "/text1.safetensors")
#         save_file(text2, args.output_path + "/text2.safetensors")
#     else:
#         torch.save({"state_dict": unet}, args.output_path + "/unet.pth")
#         torch.save({"state_dict": vae}, args.output_path + "/vae.pth")
#         torch.save({"state_dict": text1}, args.output_path + "/text1.pth")
#         torch.save({"state_dict": text2}, args.output_path + "/text2.pth")

#
#
#
#     args = parser.parse_args()
#
#     assert args.model_path is not None, "Must provide a model path!"
#
#     assert args.checkpoint_path is not None, "Must provide a checkpoint path!"
#
#
#     # Convert the UNet model
#     unet_state_dict = convert_unet_state_dict(unet_state_dict)
#     unet_state_dict = {"model.diffusion_model." + k: v for k, v in unet_state_dict.items()}
#
#     # Convert the VAE model
#     vae_state_dict = convert_vae_state_dict(vae_state_dict)
#     vae_state_dict = {"first_stage_model." + k: v for k, v in vae_state_dict.items()}
#
#     text_enc_dict = convert_openai_text_enc_state_dict(text_enc_dict)
#     text_enc_dict = {"conditioner.embedders.0.transformer." + k: v for k, v in text_enc_dict.items()}
#
#     text_enc_2_dict = convert_openclip_text_enc_state_dict(text_enc_2_dict)
#     text_enc_2_dict = {"conditioner.embedders.1.model." + k: v for k, v in text_enc_2_dict.items()}
#
#
#     # Put together new checkpoint
#     state_dict = {**unet_state_dict, **vae_state_dict, **text_enc_dict, **text_enc_2_dict}
#
#     if args.half:
#         state_dict = {k: v.half() for k, v in state_dict.items()}
#
#     if args.use_safetensors:
#         save_file(state_dict, args.checkpoint_path)
#     else:
#         state_dict = {"state_dict": state_dict}
#         torch.save(state_dict, "torch_part.ckpt")
#
#     # Convert the torch ckpt to mindspore ckpt and return mindspore key list
#     key_list = convert_weight("torch_part.ckpt", "mindspore_part.ckpt")
#
#     if osp.exists("mindspore_key_base.yaml"):
#         with open("mindspore_key_base.yaml", "r") as file:
#             line_count = len(file.readlines())
#     else:
#         line_count = 2514
#
#     # If you have obtained all the keys, you do not need to run the insertion operation
#     if len(key_list) < line_count:
#         print("mindspore_part.ckpt has ", str(len(key_list)), "keys.")
#         print(str(line_count - len(key_list)), " fewer parameters than sdxl base ckpt")
#         if osp.exists("mindspore_key_base.yaml"):
#             missing_key_list = compare_missing_key(key_list)
#             print("The first 20 missing parameters are: ", str(missing_key_list[:20]))
#         if not args.sdxl_base_ckpt:
#             print(
#                 "you didn't add sdxl_base_ckpt argument,so it will not run merge operation. the mindspore_part.ckpt is your final result"
#             )
#
#         # insert these ckpt to mindspore sdxl base ckpt
#         else:
#             print(
#                 "you have added sdxl_base_ckpt argument,so it will run merge operation(merge mindspore_part.ckpt to sdxl_base_ckpt)"
#             )
#             merge_weight("mindspore_part.ckpt", args.sdxl_base_ckpt)
#     if len(state_dict["state_dict"].keys()) > line_count:
#         raise ValueError("The number of keys is greater than mindspore sd xl base checkpoint. Insertion not allowed.")
